{"question_id": "753990d0b621d390ed58f20c4d9e4f065f0dc672", "predicted_answer": "The seed lexicon is a set of predefined affective words and phrases.", "predicted_evidence": ["n/a"]}
{"question_id": "9d578ddccc27dd849244d632dd0f6bf27348ad81", "predicted_answer": "Unanswerable. The paper doesn't provide a clear question or statement of results.", "predicted_evidence": ["n/a"]}
{"question_id": "02e4bf719b1a504e385c35c6186742e720bcb281", "predicted_answer": "Relations are used to propagate polarity by employing a rule-based system that uses explicitly encoded discourse relations to transfer the polarity of one event to its neighboring events.", "predicted_evidence": ["n/a"]}
{"question_id": "44c4bd6decc86f1091b5fc0728873d9324cdde4e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "86abeff85f3db79cf87a8c993e5e5aa61226dc98", "predicted_answer": "The paper states that \"we consider the minimal supervision scenario where the input consists of a text and an expected affective label, while the only information that can be used for supervision is a set of discourse relations from the text.\" Therefore, the only label available in the dataset for supervision is affective label.", "predicted_evidence": ["n/a"]}
{"question_id": "c029deb7f99756d2669abad0a349d917428e9c12", "predicted_answer": "The proposed approach shows significant improvement over the basic approach, but the paper does not provide a specific or quantitative measure of the improvement. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "39f8db10d949c6b477fa4b51e7c184016505884f", "predicted_answer": "The paper mentions that their model learns using mostly raw data through a minimally supervised approach.", "predicted_evidence": ["n/a"]}
{"question_id": "d0bc782961567dc1dd7e074b621a6d6be44bb5b4", "predicted_answer": "25 seed lexicon.", "predicted_evidence": ["n/a"]}
{"question_id": "a592498ba2fac994cd6fad7372836f0adb37e22a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "3a9d391d25cde8af3334ac62d478b36b30079d74", "predicted_answer": "Yes", "predicted_evidence": ["n/a"]}
{"question_id": "8d8300d88283c73424c8f301ad9fdd733845eb47", "predicted_answer": "The paper does not provide information on how the annotation experiment is evaluated.", "predicted_evidence": ["n/a"]}
{"question_id": "48b12eb53e2d507343f19b8a667696a39b719807", "predicted_answer": "Aesthetic emotions formalized in the paper are admiration, astonishment, and the sublime.", "predicted_evidence": ["n/a"]}
{"question_id": "003f884d3893532f8c302431c9f70be6f64d9be8", "predicted_answer": "Yes", "predicted_evidence": ["n/a"]}
{"question_id": "bb97537a0a7c8f12a3f65eba73cefa6abcd2f2b2", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "eea089baedc0ce80731c8fdcb064b82f584f483a", "predicted_answer": "They observe that user engagement varies with the characteristics of a community due to different community identity dimensions, such as size, openness, and content diversity.", "predicted_evidence": ["n/a"]}
{"question_id": "edb2d24d6d10af13931b3a47a6543bd469752f0c", "predicted_answer": "The 300 Reddit communities were randomly selected.", "predicted_evidence": ["n/a"]}
{"question_id": "938cf30c4f1d14fa182e82919e16072fdbcf2a82", "predicted_answer": "The authors use the metric of mean normalized entropy of degree distribution to measure how temporally dynamic a community is.", "predicted_evidence": ["n/a"]}
{"question_id": "93f4ad6568207c9bd10d712a52f8de25b3ebadd4", "predicted_answer": "The authors measure how distinctive a community is using a metric called the z-score.", "predicted_evidence": ["n/a"]}
{"question_id": "71a7153e12879defa186bfb6dbafe79c74265e10", "predicted_answer": "BioBERT, a biomedical language model pretrained on large-scale biomedical corpora, was used as the language model in this paper.", "predicted_evidence": ["n/a"]}
{"question_id": "85d1831c28d3c19c84472589a252e28e9884500f", "predicted_answer": "The proposed model is compared against two baselines: rule-based and dictionary-based. Answer: Rule-based and dictionary-based.", "predicted_evidence": ["n/a"]}
{"question_id": "1959e0ebc21fafdf1dd20c6ea054161ba7446f61", "predicted_answer": "The clinical text structuring task is defined as a process of mapping each sentence in a clinical note to an appropriate section heading in the corresponding document template.", "predicted_evidence": ["n/a"]}
{"question_id": "77cf4379106463b6ebcb5eb8fa5bb25450fa5fb8", "predicted_answer": "The specific tasks being unified are question answering and clinical text structuring.", "predicted_evidence": ["n/a"]}
{"question_id": "06095a4dee77e9a570837b35fc38e77228664f91", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "19c9cfbc4f29104200393e848b7b9be41913a7ac", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "6743c1dd7764fc652cfe2ea29097ea09b5544bc3", "predicted_answer": "The tasks evaluated are clinical text structuring and question answering.", "predicted_evidence": ["n/a"]}
{"question_id": "14323046220b2aea8f15fba86819cbccc389ed8b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "08a5f8d36298b57f6a4fcb4b6ae5796dc5d944a4", "predicted_answer": "The paper introduces domain-specific features into pre-trained language model using \"task-specific feed-forward neural network layers\".", "predicted_evidence": ["n/a"]}
{"question_id": "975a4ac9773a4af551142c324b64a0858670d06e", "predicted_answer": "4,255 clinical documents.", "predicted_evidence": ["n/a"]}
{"question_id": "326e08a0f5753b90622902bd4a9c94849a24b773", "predicted_answer": "5110.", "predicted_evidence": ["n/a"]}
{"question_id": "bd78483a746fda4805a7678286f82d9621bc45cf", "predicted_answer": "BERT, BioBERT, SciBERT and ClinicalBERT are strong baseline models in specific tasks.", "predicted_evidence": ["n/a"]}
{"question_id": "dd155f01f6f4a14f9d25afc97504aefdc6d29c13", "predicted_answer": "Aspects of language models that have been compared: model size, training time, accuracy, perplexity, and number of parameters.", "predicted_evidence": ["n/a"]}
{"question_id": "a9d530d68fb45b52d9bad9da2cd139db5a4b2f7c", "predicted_answer": "Classic language models.", "predicted_evidence": ["n/a"]}
{"question_id": "e07df8f613dbd567a35318cd6f6f4cb959f5c82d", "predicted_answer": "Perplexity.", "predicted_evidence": ["n/a"]}
{"question_id": "1a43df221a567869964ad3b275de30af2ac35598", "predicted_answer": "Yelp dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "98b11f70239ef0e22511a3ecf6e413ecb726f954", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "d4d771bcb59bab4f3eb9026cda7d182eb582027d", "predicted_answer": "Using NMT ensures generated reviews stay on topic by incorporating a topic word in the input and conditioning the generation process on it.", "predicted_evidence": ["n/a"]}
{"question_id": "12f1919a3e8ca460b931c6cacc268a926399dff4", "predicted_answer": "Logistic Regression.", "predicted_evidence": ["n/a"]}
{"question_id": "cd1034c183edf630018f47ff70b48d74d2bb1649", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "bd9930a613dd36646e2fc016b6eb21ab34c77621", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "6e2ad9ad88cceabb6977222f5e090ece36aa84ea", "predicted_answer": "They compared their proposed model to three baselines: Lead-3, LSTM encoder-decoder model, and LSTM encoder-decoder model with attention.", "predicted_evidence": ["n/a"]}
{"question_id": "aacb0b97aed6fc6a8b471b8c2e5c4ddb60988bf5", "predicted_answer": "There are two attention layers in their model. Answer: 2.", "predicted_evidence": ["n/a"]}
{"question_id": "710c1f8d4c137c8dad9972f5ceacdbf8004db208", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "47726be8641e1b864f17f85db9644ce676861576", "predicted_answer": "The paper mentions using standard intrinsic quality metrics such as word similarity and word analogy tasks, as well as extrinsic evaluation through downstream tasks.", "predicted_evidence": ["n/a"]}
{"question_id": "8958465d1eaf81c8b781ba4d764a4f5329f026aa", "predicted_answer": "Stereotype, Dehumanization, and Unpleasantness.", "predicted_evidence": ["n/a"]}
{"question_id": "31b6544346e9a31d656e197ad01756813ee89422", "predicted_answer": "The paper discusses several probabilistic observations that contribute to the more robust algorithm.", "predicted_evidence": ["n/a"]}
{"question_id": "347e86893e8002024c2d10f618ca98e14689675f", "predicted_answer": "High-quality data.", "predicted_evidence": ["n/a"]}
{"question_id": "10091275f777e0c2890c3ac0fd0a7d8e266b57cf", "predicted_answer": "60% by massive data and 40% by quality.", "predicted_evidence": ["n/a"]}
{"question_id": "cbf1137912a47262314c94d36ced3232d5fa1926", "predicted_answer": "Two architectures are not mentioned in the paper. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "519db0922376ce1e87fcdedaa626d665d9f3e8ce", "predicted_answer": "European Portuguese.", "predicted_evidence": ["n/a"]}
{"question_id": "99a10823623f78dbff9ccecb210f187105a196e9", "predicted_answer": "Portuguese Wikipedia dump and the European Parliament Proceedings Parallel Corpus.", "predicted_evidence": ["n/a"]}
{"question_id": "09f0dce416a1e40cc6a24a8b42a802747d2c9363", "predicted_answer": "Portuguese word embeddings.", "predicted_evidence": ["n/a"]}
{"question_id": "ac706631f2b3fa39bf173cd62480072601e44f66", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "8b71ede8170162883f785040e8628a97fc6b5bcb", "predicted_answer": "Unanswerable. The paper does not provide information about how the quality of the citation is measured.", "predicted_evidence": ["n/a"]}
{"question_id": "fa2a384a23f5d0fe114ef6a39dced139bddac20e", "predicted_answer": "Unanswerable. The paper does not provide information about the size of the dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "53712f0ce764633dbb034e550bb6604f15c0cacd", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "0bffc3d82d02910d4816c16b390125e5df55fd01", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "bdd8368debcb1bdad14c454aaf96695ac5186b09", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "3334f50fe1796ce0df9dd58540e9c08be5856c23", "predicted_answer": "LIWC is incorporated through a dictionary-based analysis of Twitter posts.", "predicted_evidence": ["n/a"]}
{"question_id": "7081b6909cb87b58a7b85017a2278275be58bf60", "predicted_answer": "3000.", "predicted_evidence": ["n/a"]}
{"question_id": "1870f871a5bcea418c44f81f352897a2f53d0971", "predicted_answer": "Clinically validated survey tools are not mentioned in the paper. Therefore, the answer is: Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "ce6201435cc1196ad72b742db92abd709e0f9e8d", "predicted_answer": "Yes", "predicted_evidence": ["n/a"]}
{"question_id": "928828544e38fe26c53d81d1b9c70a9fb1cc3feb", "predicted_answer": "Unanswerable. The paper does not provide information on the size of the dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "4f243056e63a74d1349488983dc1238228ca76a7", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "8f87215f4709ee1eb9ddcc7900c6c054c970160b", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "b04098f7507efdffcbabd600391ef32318da28b3", "predicted_answer": "1000+ languages.", "predicted_evidence": ["n/a"]}
{"question_id": "8fc14714eb83817341ada708b9a0b6b4c6ab5023", "predicted_answer": "They compare with several sentiment sources including SentiWordNet, SenticNet, and WordNet-Affect.", "predicted_evidence": ["n/a"]}
{"question_id": "d94ac550dfdb9e4bbe04392156065c072b9d75e1", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "eeb6e0caa4cf5fdd887e1930e22c816b99306473", "predicted_answer": "Word senses are not annotated/labeled in the paper.", "predicted_evidence": ["n/a"]}
{"question_id": "3c0eaa2e24c1442d988814318de5f25729696ef5", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "dc1fe3359faa2d7daa891c1df33df85558bc461b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "922f1b740f8b13fdc8371e2a275269a44c86195e", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "b39f2249a1489a2cef74155496511cc5d1b2a73d", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "591231d75ff492160958f8aa1e6bfcbbcd85a776", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "9e805020132d950b54531b1a2620f61552f06114", "predicted_answer": "The paper mentions that they use \"a previous state-of-the-art method\" as their baseline, but does not provide the specific name of the method. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "95abda842c4df95b4c5e84ac7d04942f1250b571", "predicted_answer": "English, German, French, and Spanish.", "predicted_evidence": ["n/a"]}
{"question_id": "2419b38624201d678c530eba877c0c016cccd49f", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "b99d100d17e2a121c3c8ff789971ce66d1d40a4d", "predicted_answer": "They compared their model to three other models.", "predicted_evidence": ["n/a"]}
{"question_id": "578d0b23cb983b445b1a256a34f969b34d332075", "predicted_answer": "Dialectal Arabic Twitter datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "6548db45fc28e8a8b51f114635bad14a13eaec5b", "predicted_answer": "They use two different GAN models: the vanilla GAN and the SeqGAN.", "predicted_evidence": ["n/a"]}
{"question_id": "4c4f76837d1329835df88b0921f4fe8bda26606f", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "819d2e97f54afcc7cdb3d894a072bcadfba9b747", "predicted_answer": "Gutenberg and WikiText-2.", "predicted_evidence": ["n/a"]}
{"question_id": "637aa32a34b20b4b0f1b5dfa08ef4e0e5ed33d52", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "4b8257cdd9a60087fa901da1f4250e7d910896df", "predicted_answer": "The paper does not provide any definition or exemplification of 'incorrect words'.", "predicted_evidence": ["n/a"]}
{"question_id": "7e161d9facd100544fa339b06f656eb2fc64ed28", "predicted_answer": "One.", "predicted_evidence": ["n/a"]}
{"question_id": "abc5836c54fc2ac8465aee5a83b9c0f86c6fd6f5", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "4debd7926941f1a02266b1a7be2df8ba6e79311a", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "3b745f086fb5849e7ce7ce2c02ccbde7cfdedda5", "predicted_answer": "19.4%", "predicted_evidence": ["n/a"]}
{"question_id": "44c7c1fbac80eaea736622913d65fe6453d72828", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "3e0c9469821cb01a75e1818f2acb668d071fcf40", "predicted_answer": "Average number of turns per conversation, average number of words per turn, average number of words per conversation.", "predicted_evidence": ["n/a"]}
{"question_id": "a725246bac4625e6fe99ea236a96ccb21b5f30c6", "predicted_answer": "The system designs introduced a social bot named Gunrock that can engage in long and complex conversations.", "predicted_evidence": ["n/a"]}
{"question_id": "516626825e51ca1e8a3e0ac896c538c9d8a747c8", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "77af93200138f46bb178c02f710944a01ed86481", "predicted_answer": "Yes", "predicted_evidence": ["n/a"]}
{"question_id": "71538776757a32eee930d297f6667cd0ec2e9231", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "830de0bd007c4135302138ffa8f4843e4915e440", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "680dc3e56d1dc4af46512284b9996a1056f89ded", "predicted_answer": "The paper used \"random\" as the baseline.", "predicted_evidence": ["n/a"]}
{"question_id": "bd5379047c2cf090bea838c67b6ed44773bcd56f", "predicted_answer": "Experiments to detect subjective bias using contextualized word embeddings are performed.", "predicted_evidence": ["n/a"]}
{"question_id": "7aa8375cdf4690fc3b9b1799b0f5a9ec1c1736ed", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "3ac30bd7476d759ea5d9a5abf696d4dfc480175b", "predicted_answer": "They use the LSTM-based (Long Short-Term Memory) language models.", "predicted_evidence": ["n/a"]}
{"question_id": "0e57a0983b4731eba9470ba964d131045c8c7ea7", "predicted_answer": "The paper does not mention any questions asked to human judges. (Unanswerable)", "predicted_evidence": ["n/a"]}
{"question_id": "f0317e48dafe117829e88e54ed2edab24b86edb1", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "ec91b87c3f45df050e4e16018d2bf5b62e4ca298", "predicted_answer": "NMT baseline models", "predicted_evidence": ["n/a"]}
{"question_id": "f129c97a81d81d32633c94111018880a7ffe16d1", "predicted_answer": "They compare global attention and local attention mechanisms.", "predicted_evidence": ["n/a"]}
{"question_id": "100cf8b72d46da39fedfe77ec939fb44f25de77f", "predicted_answer": "Paired corpora of English and Spanish newswire articles and English and Spanish Wikipedia articles.", "predicted_evidence": ["n/a"]}
{"question_id": "8cc56fc44136498471754186cfa04056017b4e54", "predicted_answer": "3.8%", "predicted_evidence": ["n/a"]}
{"question_id": "5fa431b14732b3c47ab6eec373f51f2bca04f614", "predicted_answer": "Polarity-based and LDA-based models.", "predicted_evidence": ["n/a"]}
{"question_id": "33ccbc401b224a48fba4b167e86019ffad1787fb", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "cca74448ab0c518edd5fc53454affd67ac1a201c", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "b69ffec1c607bfe5aa4d39254e0770a3433a191b", "predicted_answer": "Guardian News comment dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "f5cf8738e8d211095bb89350ed05ee7f9997eb19", "predicted_answer": "14.75%", "predicted_evidence": ["n/a"]}
{"question_id": "bed527bcb0dd5424e69563fba4ae7e6ea1fca26a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "aeab5797b541850e692f11e79167928db80de1ea", "predicted_answer": "They concatenate the knowledge graph embeddings to the final layer of BERT.", "predicted_evidence": ["n/a"]}
{"question_id": "bfa3776c30cb30e0088e185a5908e5172df79236", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "a2a66726a5dca53af58aafd8494c4de833a06f14", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "ee87608419e4807b9b566681631a8cd72197a71a", "predicted_answer": "The corpus used in the study is the Deutsche Lyrik Dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "cda4612b4bda3538d19f4b43dde7bc30c1eda4e5", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e12674f0466f8c0da109b6076d9939b30952c7da", "predicted_answer": "Byte Pair Encoding (BPE)", "predicted_evidence": ["n/a"]}
{"question_id": "9fe6339c7027a1a0caffa613adabe8b5bb6a7d4a", "predicted_answer": "The paper does not mention any user-generated text data. Therefore, the answer is \"Unanswerable\".", "predicted_evidence": ["n/a"]}
{"question_id": "b5c3787ab3784214fc35f230ac4926fe184d86ba", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "9174aded45bc36915f2e2adb6f352f3c7d9ada8b", "predicted_answer": "Datasets used were Wikipedia, GutenTag, Project Gutenberg, Reuters, Brown, and Amazon Reviews.", "predicted_evidence": ["n/a"]}
{"question_id": "a8f1029f6766bffee38a627477f61457b2d6ed5c", "predicted_answer": "They obtained human intuitions through crowdsourcing.", "predicted_evidence": ["n/a"]}
{"question_id": "a2103e7fe613549a9db5e65008f33cf2ee0403bd", "predicted_answer": "The paper suggests that country-specific drivers of international development rhetoric are the country's economic, social, and political conditions.", "predicted_evidence": ["n/a"]}
{"question_id": "13b36644357870008d70e5601f394ec3c6c07048", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "e4a19b91b57c006a9086ae07f2d6d6471a8cf0ce", "predicted_answer": "The main international development topics that states raise are identified through natural language processing (NLP) techniques applied to the United Nations General Debate speeches from 1970-2016.", "predicted_evidence": ["n/a"]}
{"question_id": "fd0ef5a7b6f62d07776bf672579a99c67e61a568", "predicted_answer": "The paper does not present any experiments to validate their system.", "predicted_evidence": ["n/a"]}
{"question_id": "071bcb4b054215054f17db64bfd21f17fd9e1a80", "predicted_answer": "The paper doesn't provide enough evidence or information related to how the conversation layer works. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "f399d5a8dbeec777a858f81dc4dd33a83ba341a2", "predicted_answer": "The QnAMaker is composed of a knowledge base, a natural language processing (NLP) model, and a bot runtime.", "predicted_evidence": ["n/a"]}
{"question_id": "d28260b5565d9246831e8dbe594d4f6211b60237", "predicted_answer": "They measure robustness by evaluating the model's performance under different test sets and domains.", "predicted_evidence": ["n/a"]}
{"question_id": "8670989ca39214eda6c1d1d272457a3f3a92818b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "923b12c0a50b0ee22237929559fad0903a098b7b", "predicted_answer": "Experiments with large-scale features are performed on English-to-Japanese and English-to-German translation tasks.", "predicted_evidence": ["n/a"]}
{"question_id": "67131c15aceeb51ae1d3b2b8241c8750a19cca8e", "predicted_answer": "The authors used the Kaldi ASR system in this work.", "predicted_evidence": ["n/a"]}
{"question_id": "579a0603ec56fc2b4aa8566810041dbb0cd7b5e7", "predicted_answer": "The paper does not mention any \"series of simple models.\" Therefore, the answer is \"Unanswerable\".", "predicted_evidence": ["n/a"]}
{"question_id": "c9c85eee41556c6993f40e428fa607af4abe80a9", "predicted_answer": "The work is evaluated on the Fluent Speech Commands dataset and the Switchboard-1 Release 2 corpus.", "predicted_evidence": ["n/a"]}
{"question_id": "f8281eb49be3e8ea0af735ad3bec955a5dedf5b3", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "a5ee9b40a90a6deb154803bef0c71c2628acb571", "predicted_answer": "The corpora used for the task are Wikipedia and Newsela.", "predicted_evidence": ["n/a"]}
{"question_id": "e286860c41a4f704a3a08e45183cb8b14fa2ad2f", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "982979cb3c71770d8d7d2d1be8f92b66223dec85", "predicted_answer": "The paper suggests the use of \"intrinsic metrics\" to track progress but does not suggest any new metrics. So, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "5ba6f7f235d0f5d1d01fd97dd5e4d5b0544fd212", "predicted_answer": "Accuracy, F1 score, and Spearman's rank correlation coefficient.", "predicted_evidence": ["n/a"]}
{"question_id": "7ce7edd06925a943e32b59f3e7b5159ccb7acaf6", "predicted_answer": "Experimental results suggest that using less than 50% of the available training examples might result in overfitting: Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "a883bb41449794e0a63b716d9766faea034eb359", "predicted_answer": "The paper mentions \"multimodal procedures that may involve observing video streams, reading written instructions, understanding natural language descriptions, and manipulating objects in a simulation.\" Therefore, the dataset includes multimodality in the form of video streams, written instructions, natural language descriptions, and object manipulation in simulations. The answer is: video streams, written instructions, natural language descriptions, and object manipulation in simulations.", "predicted_evidence": ["n/a"]}
{"question_id": "5d83b073635f5fd8cd1bdb1895d3f13406583fbd", "predicted_answer": "Procedural Reasoning Networks (PRNs) are compared to previously reported models, but the paper doesn't specify which models are being referred to. Therefore, the answer is unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "171ebfdc9b3a98e4cdee8f8715003285caeb2f39", "predicted_answer": "5.5% better in accuracy.", "predicted_evidence": ["n/a"]}
{"question_id": "3c3cb51093b5fd163e87a773a857496a4ae71f03", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "53a0763eff99a8148585ac642705637874be69d4", "predicted_answer": "The paper proposes an active learning approach where query samples are selected based on the uncertainty of the model's prediction and the labeler's expertise to improve Chinese word segmentation in medical text.", "predicted_evidence": ["n/a"]}
{"question_id": "0bfed6f9cfe93617c5195c848583e3945f2002ff", "predicted_answer": "Convolutional neural network (CNN) and recurrent neural network (RNN) architectures are employed.", "predicted_evidence": ["n/a"]}
{"question_id": "352c081c93800df9654315e13a880d6387b91919", "predicted_answer": "The key points in the role of script knowledge that can be studied in the paper \"InScript: Narrative texts annotated with script information\" are script analysis, story composition, and genre classification.", "predicted_evidence": ["n/a"]}
{"question_id": "18fbf9c08075e3b696237d22473c463237d153f5", "predicted_answer": "The paper reports an agreement of 0.96 for inter-annotator agreement using Cohen's Kappa.", "predicted_evidence": ["n/a"]}
{"question_id": "a37ef83ab6bcc6faff3c70a481f26174ccd40489", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "bc9c31b3ce8126d1d148b1025c66f270581fde10", "predicted_answer": "Datasets used: DBLP, Cora, Citeseer.", "predicted_evidence": ["n/a"]}
{"question_id": "185841e979373808d99dccdade5272af02b98774", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d427e3d41c4c9391192e249493be23926fc5d2e9", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "330f2cdeab689670b68583fc4125f5c0b26615a8", "predicted_answer": "The proposed model allows for learning both classification and regression tasks from crowdsourcing data, and achieves higher accuracy and efficiency than existing models.", "predicted_evidence": ["n/a"]}
{"question_id": "c87b2dd5c439d5e68841a705dd81323ec0d64c97", "predicted_answer": "State of the art approaches are not explicitly mentioned in the paper.", "predicted_evidence": ["n/a"]}
{"question_id": "f7789313a804e41fcbca906a4e5cf69039eeef9f", "predicted_answer": "The paper used three different datasets: Amazon Mechanical Turk (AMT), Crowdsourcing Statistical Question Answering (CSQA), and Crowdsourcing Pairwise Preference Ranking (CPPR).", "predicted_evidence": ["n/a"]}
{"question_id": "2376c170c343e2305dac08ba5f5bda47c370357f", "predicted_answer": "The dataset was collected through a Wizard-of-Oz (WOZ) setting, where human annotators played the role of users and had conversations with hired actors who played the role of dialogue system.", "predicted_evidence": ["n/a"]}
{"question_id": "0137ecebd84a03b224eb5ca51d189283abb5f6d9", "predicted_answer": "The benchmark models are MultiWOZ and CamRest676.", "predicted_evidence": ["n/a"]}
{"question_id": "5f6fbd57cce47f20a0fda27d954543c00c4344c2", "predicted_answer": "The corpus was manually annotated by professional annotators.", "predicted_evidence": ["n/a"]}
{"question_id": "d6e2b276390bdc957dfa7e878de80cee1f41fbca", "predicted_answer": "The new model is compared to standalone BERT, ELMo, and GPT.", "predicted_evidence": ["n/a"]}
{"question_id": "32537fdf0d4f76f641086944b413b2f756097e5e", "predicted_answer": "2x improvement.", "predicted_evidence": ["n/a"]}
{"question_id": "ef081d78be17ef2af792e7e919d15a235b8d7275", "predicted_answer": "OntoNotes 5.0, TREC 2019 Precision Medicine, SQuAD 2.0.", "predicted_evidence": ["n/a"]}
{"question_id": "537b2d7799124d633892a1ef1a485b3b071b303d", "predicted_answer": "CoNLL 2018 Universal Dependency Parsing benchmark dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "9aca4b89e18ce659c905eccc78eda76af9f0072a", "predicted_answer": "Unanswerable. The paper does not provide information on the speed of the model compared to baselines.", "predicted_evidence": ["n/a"]}
{"question_id": "b0376a7f67f1568a7926eff8ff557a93f434a253", "predicted_answer": "5.34 F1 score improvement.", "predicted_evidence": ["n/a"]}
{"question_id": "dad8cc543a87534751f9f9e308787e1af06f0627", "predicted_answer": "ACE 2004 and TAC KBP 2010-2012.", "predicted_evidence": ["n/a"]}
{"question_id": "0481a8edf795768d062c156875d20b8fb656432c", "predicted_answer": "Cues mentioned in the paper include contextual and document features.", "predicted_evidence": ["n/a"]}
{"question_id": "b6a4ab009e6f213f011320155a7ce96e713c11cf", "predicted_answer": "The author's work ranked first among other submissions on the challenge.", "predicted_evidence": ["n/a"]}
{"question_id": "cfffc94518d64cb3c8789395707e4336676e0345", "predicted_answer": "Support Vector Machines and Decision Trees.", "predicted_evidence": ["n/a"]}
{"question_id": "f60629c01f99de3f68365833ee115b95a3388699", "predicted_answer": "Brand of the classification approaches were not mentioned in the paper. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "a7cb4f8e29fd2f3d1787df64cd981a6318b65896", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "642c4704a71fd01b922a0ef003f234dcc7b223cd", "predicted_answer": "Ambiguity and annotation errors.", "predicted_evidence": ["n/a"]}
{"question_id": "e477e494fe15a978ff9c0a5f1c88712cdaec0c5c", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "04495845251b387335bf2e77e2c423130f43c7d9", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "564dcaf8d0bcc274ab64c784e4c0f50d7a2c17ee", "predicted_answer": "48 languages.", "predicted_evidence": ["n/a"]}
{"question_id": "f3d0e6452b8d24b7f9db1fd898d1fbe6cd23f166", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "9b1d789398f1f1a603e4741a5eee63ccaf0d4a4f", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "00bcdffff7e055f99aaf1b05cf41c98e2748e948", "predicted_answer": "Baseline method for the task is Support Vector Machine (SVM).", "predicted_evidence": ["n/a"]}
{"question_id": "f92ee3c5fce819db540bded3cfcc191e21799cb1", "predicted_answer": "The paper mentions using OpenFace for face input and Tensorflow for audio input.", "predicted_evidence": ["n/a"]}
{"question_id": "4547818a3bbb727c4bb4a76554b5a5a7b5c5fedb", "predicted_answer": "750K and 4.5M sentences.", "predicted_evidence": ["n/a"]}
{"question_id": "07d7652ad4a0ec92e6b44847a17c378b0d9f57f5", "predicted_answer": "They achieved significant improvements in the low-resource dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "9f3444c9fb2e144465d63abf58520cddd4165a01", "predicted_answer": "Transformer and RNN-based models.", "predicted_evidence": ["n/a"]}
{"question_id": "2348d68e065443f701d8052018c18daa4ecc120e", "predicted_answer": "Pitfalls in the paper: small datasets, domain adaptation, lack of parallel data, performance degradation, and model complexity.", "predicted_evidence": ["n/a"]}
{"question_id": "5679fabeadf680e35a4f7b092d39e8638dca6b4d", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "a939a53cabb4893b2fd82996f3dbe8688fdb7bbb", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "8b99767620fd4efe51428b68841cc3ec06699280", "predicted_answer": "Text mining and Natural Language Processing (NLP).", "predicted_evidence": ["n/a"]}
{"question_id": "312417675b3dc431eb7e7b16a917b7fed98d4376", "predicted_answer": "The causal mapping methods employed are Concept Mapping and Cluster Analysis.", "predicted_evidence": ["n/a"]}
{"question_id": "792d7b579cbf7bfad8fe125b0d66c2059a174cf9", "predicted_answer": "The paper does not mention previous work's model.", "predicted_evidence": ["n/a"]}
{"question_id": "44a2a8e187f8adbd7d63a51cd2f9d2d324d0c98d", "predicted_answer": "The paper uses two datasets - Hinglish-English Code-Mixed Corpus and Hindi-English Code-Mixed Corpus.", "predicted_evidence": ["n/a"]}
{"question_id": "5908d7fb6c48f975c5dfc5b19bb0765581df2b25", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "cca3301f20db16f82b5d65a102436bebc88a2026", "predicted_answer": "The paper mentions that the dataset was collected through crowd-sourcing.", "predicted_evidence": ["n/a"]}
{"question_id": "cfd67b9eeb10e5ad028097d192475d21d0b6845b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "e1c681280b5667671c7f78b1579d0069cba72b0e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "58d50567df71fa6c3792a0964160af390556757d", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "07c79edd4c29635dbc1c2c32b8df68193b7701c6", "predicted_answer": "The paper used the \"Hinglish- Hindi-English Code-mixed Social Media Text (HiEn) dataset\" for the study.", "predicted_evidence": ["n/a"]}
{"question_id": "66125cfdf11d3bf8e59728428e02021177142c3a", "predicted_answer": "They demonstrate it by showing that the language-neutral component performs well on word alignment tasks in multiple languages with high accuracy. Therefore, they provide evidence that the language-neutral component is sufficiently general in terms of modeling semantics to allow high-accuracy word-alignment. Answer: High accuracy in word alignment tasks in multiple languages.", "predicted_evidence": ["n/a"]}
{"question_id": "222b2469eede9a0448e0226c6c742e8c91522af3", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "6f8386ad64dce3a20bc75165c5c7591df8f419cf", "predicted_answer": "They used a probing classifier to predict the language label of each token in the input sentence, and they measured the correlation between the language label predictions and the difference between the original mBERT embeddings and language-specific embeddings.", "predicted_evidence": ["n/a"]}
{"question_id": "81dc39ee6cdacf90d5f0f62134bf390a29146c65", "predicted_answer": "The paper presents the challenge that the work highlights the need for better language-independent evaluation metrics to build language-neutral representations.", "predicted_evidence": ["n/a"]}
{"question_id": "b1ced2d6dcd1d7549be2594396cbda34da6c3bca", "predicted_answer": "The paper reports an average F1 score of 0.89 for intent classification and an average F1 score of 0.92 for entity extraction on their test set.", "predicted_evidence": ["n/a"]}
{"question_id": "f3be1a27df2e6ad12eed886a8cd2dfe09b9e2b30", "predicted_answer": "The evaluation metrics used are BLEU-4 and METEOR.", "predicted_evidence": ["n/a"]}
{"question_id": "a45a86b6a02a98d3ab11f1d04acd3446e95f5a16", "predicted_answer": "The source of the dialogues is not stated in the paper. Answer: Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "1f1a9f2dd8c4c10b671cb8affe56e181948e229e", "predicted_answer": "BERT (Bidirectional Encoder Representations from Transformers) is used as the pretrained LM.", "predicted_evidence": ["n/a"]}
{"question_id": "eeaceee98ef1f6c971dac7b0b8930ee8060d71c2", "predicted_answer": "The paper proposes three approaches: (1) constructing a gold set of faithful input/output pairs, (2) using human judgments of faithfulness for evaluation, and (3) using explanations as a proxy for faithfulness.", "predicted_evidence": ["n/a"]}
{"question_id": "3371d586a3a81de1552d90459709c57c0b1a2594", "predicted_answer": "They propose four faithfulness criteria: (1) faithfulness to the input text, (2) faithfulness to the model implementation, (3) faithfulness to the human reference, and (4) faithfulness to the evaluation metric.", "predicted_evidence": ["n/a"]}
{"question_id": "d4b9cdb4b2dfda1e0d96ab6c3b5e2157fd52685e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "2a859e80d8647923181cb2d8f9a2c67b1c3f4608", "predicted_answer": "Key points in guidelines for faithfulness evaluation: input specification, input-output relationship, human satisfaction, and adversarial testing.", "predicted_evidence": ["n/a"]}
{"question_id": "aceac4ad16ffe1af0f01b465919b1d4422941a6b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "f7070b2e258beac9b09514be2bfcc5a528cc3a0e", "predicted_answer": "79.4% (accuracy) on SNLI and 72.1% (accuracy) on MultiNLI.", "predicted_evidence": ["n/a"]}
{"question_id": "2efdcebebeb970021233553104553205ce5d6567", "predicted_answer": "The model architecture includes multiple layers, but the specific number is not explicitly stated in the paper. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "4fa851d91388f0803e33f6cfae519548598cd37c", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "a891039441e008f1fd0a227dbed003f76c140737", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "73738e42d488b32c9db89ac8adefc75403fa2653", "predicted_answer": "20%.", "predicted_evidence": ["n/a"]}
{"question_id": "6c8bd7fa1cfb1b2bbeb011cc9c712dceac0c8f06", "predicted_answer": "The baseline model is a Multi-Perspective Context Matching (MPCM) network.", "predicted_evidence": ["n/a"]}
{"question_id": "fa218b297d9cdcae238cef71096752ce27ca8f4a", "predicted_answer": "67.7 F1", "predicted_evidence": ["n/a"]}
{"question_id": "ff28d34d1aaa57e7ad553dba09fc924dc21dd728", "predicted_answer": "The paper reports high positive correlations between the model's predicted summary quality scores and human ratings.", "predicted_evidence": ["n/a"]}
{"question_id": "ae8354e67978b7c333094c36bf9d561ca0c2d286", "predicted_answer": "CNN/DailyMail dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "02348ab62957cb82067c589769c14d798b1ceec7", "predicted_answer": "The paper looks at logistic regression, random forest, and gradient boosting as simpler models.", "predicted_evidence": ["n/a"]}
{"question_id": "3748787379b3a7d222c3a6254def3f5bfb93a60e", "predicted_answer": "Summary quality aspects.", "predicted_evidence": ["n/a"]}
{"question_id": "6852217163ea678f2009d4726cb6bd03cf6a8f78", "predicted_answer": "The benchmark datasets used for the link prediction task are FB15k-237, WN18RR, WN11, and FB13.", "predicted_evidence": ["n/a"]}
{"question_id": "cd1ad7e18d8eef8f67224ce47f3feec02718ea1a", "predicted_answer": "TransE, ComplEx, RotatE and ConvE are state-of-the-art models for this task.", "predicted_evidence": ["n/a"]}
{"question_id": "9c9e90ceaba33242342a5ae7568e89fe660270d5", "predicted_answer": "HAKE model performs better than state-of-the-art methods by an average of 3.3% on the link prediction task.", "predicted_evidence": ["n/a"]}
{"question_id": "2a058f8f6bd6f8e80e8452e1dba9f8db5e3c7de8", "predicted_answer": "Entities are not mapped onto polar coordinate system in the paper. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "db9021ddd4593f6fadf172710468e2fdcea99674", "predicted_answer": "The paper mentions incorporating attention mechanism and beam search.", "predicted_evidence": ["n/a"]}
{"question_id": "8ea4bd4c1d8a466da386d16e4844ea932c44a412", "predicted_answer": "Github dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "92240eeab107a4f636705b88f00cefc4f0782846", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "4196d329061f5a9d147e1e77aeed6a6bd9b35d18", "predicted_answer": "Long-Short Term Memory (LSTM) architecture.", "predicted_evidence": ["n/a"]}
{"question_id": "a37e4a21ba98b0259c36deca0d298194fa611d2f", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "321429282557e79061fe2fe02a9467f3d0118cdd", "predicted_answer": "Ensemble learning and attention mechanisms.", "predicted_evidence": ["n/a"]}
{"question_id": "891cab2e41d6ba962778bda297592c916b432226", "predicted_answer": "Python", "predicted_evidence": ["n/a"]}
{"question_id": "1eeabfde99594b8d9c6a007f50b97f7f527b0a17", "predicted_answer": "CodeSearchNet.", "predicted_evidence": ["n/a"]}
{"question_id": "e96adf8466e67bd19f345578d5a6dc68fd0279a1", "predicted_answer": "Unsupervised.", "predicted_evidence": ["n/a"]}
{"question_id": "c1477a6c86bd1670dd17407590948000c9a6b7c6", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e020677261d739c35c6f075cde6937d0098ace7f", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "6389d5a152151fb05aae00b53b521c117d7b5e54", "predicted_answer": "Conditioned GAN for AttnGAN, StackGAN-v2, and MirrorGAN. Unconditional GAN for BigGAN-deep and SNGAN.", "predicted_evidence": ["n/a"]}
{"question_id": "7fe48939ce341212c1d801095517dc552b98e7b3", "predicted_answer": "Feature-wise sigmoid gating is employed in the character-level embedding.", "predicted_evidence": ["n/a"]}
{"question_id": "65ad17f614b7345f0077424c04c94971c831585b", "predicted_answer": "Character-level, word-level, and gating mechanism-based model architecture.", "predicted_evidence": ["n/a"]}
{"question_id": "323e100a6c92d3fe503f7a93b96d821408f92109", "predicted_answer": "They evaluate their proposed approach on the downstream sentence-level task of sentiment analysis.", "predicted_evidence": ["n/a"]}
{"question_id": "9f89bff89cea722debc991363f0826de945bc582", "predicted_answer": "Similarity datasets used in this paper are: SimLex-999, WordSim-353, and MEN.", "predicted_evidence": ["n/a"]}
{"question_id": "735f58e28d84ee92024a36bc348cfac2ee114409", "predicted_answer": "Yes, there are datasets with relation tuples annotated. The paper mentions several datasets, including: NYT (703 relation types), ACE05 (33 relation types), and SemEval 2010 Task 8 (9 relation types). The size of these datasets varies, with NYT having over 75,000 examples and SemEval 2010 Task 8 having 800 examples.", "predicted_evidence": ["n/a"]}
{"question_id": "710fa8b3e74ee63d2acc20af19f95f7702b7ce5e", "predicted_answer": "Approach 2 performed better in experiments.", "predicted_evidence": ["n/a"]}
{"question_id": "56123dd42cf5c77fc9a88fc311ed2e1eb672126e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "1898f999626f9a6da637bd8b4857e5eddf2fc729", "predicted_answer": "The F1 scores are higher compared to previous work.", "predicted_evidence": ["n/a"]}
{"question_id": "d32b6ac003cfe6277f8c2eebc7540605a60a3904", "predicted_answer": "The paper reports two baselines: BM25 and a neural network trained on task-specific features.", "predicted_evidence": ["n/a"]}
{"question_id": "c10f38ee97ed80484c1a70b8ebba9b1fb149bc91", "predicted_answer": "They developed a supervised learning to rank model.", "predicted_evidence": ["n/a"]}
{"question_id": "340501f23ddc0abe344a239193abbaaab938cc3a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "fbb85cbd41de6d2818e77e8f8d4b91e431931faa", "predicted_answer": "Amazon Mechanical Turk.", "predicted_evidence": ["n/a"]}
{"question_id": "1951cde612751410355610074c3c69cec94824c2", "predicted_answer": "The paper does not provide enough evidence to answer this question.", "predicted_evidence": ["n/a"]}
{"question_id": "4140d8b5a78aea985546aa1e323de12f63d24add", "predicted_answer": "The paper did not provide explicit information on the improvement of results. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "61272b1d0338ed7708cf9ed9c63060a6a53e97a2", "predicted_answer": "79.50% accuracy on the dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "53b02095ba7625d85721692fce578654f66bbdf0", "predicted_answer": "70,000.", "predicted_evidence": ["n/a"]}
{"question_id": "0cd0755ac458c3bafbc70e4268c1e37b87b9721b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "c1ce652085ef9a7f02cb5c363ce2b8757adbe213", "predicted_answer": "The dataset was collected through crowdsourcing using Amazon Mechanical Turk.", "predicted_evidence": ["n/a"]}
{"question_id": "96be67b1729c3a91ddf0ec7d6a80f2aa75e30a30", "predicted_answer": "The agents talk in English.", "predicted_evidence": ["n/a"]}
{"question_id": "b85ab5f862221fac819cf2fef239bcb08b9cafc6", "predicted_answer": "The authors looked at three evaluation metrics, namely BLEU score, F-measure, and navigation accuracy.", "predicted_evidence": ["n/a"]}
{"question_id": "7e34501255b89d64b9598b409d73f96489aafe45", "predicted_answer": "They used a dataset of grounded human-human dialogues and a set of human-human directions provided by the guidebooks to New York City.", "predicted_evidence": ["n/a"]}
{"question_id": "e854edcc5e9111922e6e120ae17d062427c27ec1", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "bd6cec2ab620e67b3e0e7946fc045230e6906020", "predicted_answer": "The paper reports accuracy as the primary evaluation metric, but it does not provide details on how it is specifically measured.", "predicted_evidence": ["n/a"]}
{"question_id": "4b0ba460ae3ba7a813f204abd16cf631b871baca", "predicted_answer": "The incoming claim is used to retrieve similar factchecked claims through semantic similarity of claims using a sentence embedding model that encodes claims in a high-dimensional vector space.", "predicted_evidence": ["n/a"]}
{"question_id": "63b0c93f0452d0e1e6355de1d0f3ff0fd67939fb", "predicted_answer": "Google Fact Check Explorer.", "predicted_evidence": ["n/a"]}
{"question_id": "d27f23bcd80b12f6df8e03e65f9b150444925ecf", "predicted_answer": "Claim detection deep learning models, fact-check search engine.", "predicted_evidence": ["n/a"]}
{"question_id": "b11ee27f3de7dd4a76a1f158dc13c2331af37d9f", "predicted_answer": "The baseline for RC-QED is the simple union of all sentences in a document as the context for each query.", "predicted_evidence": ["n/a"]}
{"question_id": "7aba5e4483293f5847caad144ee0791c77164917", "predicted_answer": "HotpotQA dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "565d668947ffa6d52dad019af79289420505889b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "d83304c70fe66ae72e78aa1d183e9f18b7484cd6", "predicted_answer": "The dataset was annotated by human annotators.", "predicted_evidence": ["n/a"]}
{"question_id": "e90ac9ee085dc2a9b6fe132245302bbce5f3f5ab", "predicted_answer": "Google Search Snippets.", "predicted_evidence": ["n/a"]}
{"question_id": "5b029ad0d20b516ec11967baaf7d2006e8d7199f", "predicted_answer": "Unanswerable. The paper does not mention the number of label options in the multi-label task.", "predicted_evidence": ["n/a"]}
{"question_id": "79bd2ad4cb5c630ce69d5a859ed118132cae62d7", "predicted_answer": "0.618 (Krippendorff's alpha)", "predicted_evidence": ["n/a"]}
{"question_id": "d3a1a53521f252f869fdae944db986931d9ffe48", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "38e11663b03ac585863742044fd15a0e875ae9ab", "predicted_answer": "The participants on Twitter who provided their sentiment on the event and their prediction on the outcome.", "predicted_evidence": ["n/a"]}
{"question_id": "14421b7ae4459b647033b3ccba635d4ba7bb114b", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "52f7e42fe8f27d800d1189251dfec7446f0e1d3b", "predicted_answer": "The proposed method outperforms state-of-the-art methods significantly in experiments.", "predicted_evidence": ["n/a"]}
{"question_id": "00e6324ecd454f5d4b2a4b27fcf4104855ff8ee2", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "aa0d67c2a1bc222d1f2d9e5d51824352da5bb6dc", "predicted_answer": "RotatE, DistMult, ComplEx, TransE, TransD, QuatE, and SimplE.", "predicted_evidence": ["n/a"]}
{"question_id": "cf0085c1d7bd9bc9932424e4aba4e6812d27f727", "predicted_answer": "Freebase, WordNet, and Wiki datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "586b7470be91efe246c3507b05e30651ea6b9832", "predicted_answer": "KANE captures both high-order structural and attribute information of KGs in an efficient, explicit and unified manner by using knowledge graph attention networks.", "predicted_evidence": ["n/a"]}
{"question_id": "31b20a4bab09450267dfa42884227103743e3426", "predicted_answer": "TransE, TransH, TransR, CKE, ConvE, RotatE, GCN-Align.", "predicted_evidence": ["n/a"]}
{"question_id": "45306b26447ea4b120655d6bb2e3636079d3d6e0", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "0c08af6e4feaf801185f2ec97c4da04c8b767ad6", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "6412e97373e8e9ae3aa20aa17abef8326dc05450", "predicted_answer": "Logistic Regression.", "predicted_evidence": ["n/a"]}
{"question_id": "957bda6b421ef7d2839c3cec083404ac77721f14", "predicted_answer": "Stylistic features such as misspellings, word repetitions, and changes in word length and punctuation are used to detect drunk texts.", "predicted_evidence": ["n/a"]}
{"question_id": "368317b4fd049511e00b441c2e9550ded6607c37", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "b3ec918827cd22b16212265fcdd5b3eadee654ae", "predicted_answer": "#drunk, #party, #beer, #wine, #alcohol.", "predicted_evidence": ["n/a"]}
{"question_id": "387970ebc7ef99f302f318d047f708274c0e8f21", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "2fffff59e57b8dbcaefb437a6b3434fc137f813b", "predicted_answer": "Clue: Section 3.1 of the paper discusses the source of the OpenIE extractions.\n\nAnswer: Clue is not a part of the answer. \n\nThe extractions were obtained from a snapshot of English Wikipedia from July 2015.", "predicted_evidence": ["n/a"]}
{"question_id": "eb95af36347ed0e0808e19963fe4d058e2ce3c9f", "predicted_answer": "87.3% (precision) and 84.2% (recall).", "predicted_evidence": ["n/a"]}
{"question_id": "cd1792929b9fa5dd5b1df0ae06fc6aece4c97424", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "65d34041ffa4564385361979a08706b10b92ebc7", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "e215fa142102f7f9eeda9c9eb8d2aeff7f2a33ed", "predicted_answer": "The paper states that the OpenIE extractions were generated using the ClausIE system. Therefore, the method used was ClausIE.", "predicted_evidence": ["n/a"]}
{"question_id": "a8545f145d5ea2202cb321c8f93e75ad26fcf4aa", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "417dabd43d6266044d38ed88dbcb5fdd7a426b22", "predicted_answer": "The paper did not mention a specific textual source to which OpenIE was applied.", "predicted_evidence": ["n/a"]}
{"question_id": "fed230cef7c130f6040fb04304a33bbc17ca3a36", "predicted_answer": "ClauseIE.", "predicted_evidence": ["n/a"]}
{"question_id": "7917d44e952b58ea066dc0b485d605c9a1fe3dda", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "7d5ba230522df1890619dedcfb310160958223c1", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "a48cc6d3d322a7b159ff40ec162a541bf74321eb", "predicted_answer": "A supervised evaluation is conducted.", "predicted_evidence": ["n/a"]}
{"question_id": "2bc0bb7d3688fdd2267c582ca593e2ce72718a91", "predicted_answer": "List of corpora: BabelNet, WordNet, EuroWordNet, and Cornetto.", "predicted_evidence": ["n/a"]}
{"question_id": "8c073b7ea8cb5cc54d7fecb8f4bf88c1fb621b19", "predicted_answer": "WordNet-based similarity measures.", "predicted_evidence": ["n/a"]}
{"question_id": "dcb18516369c3cf9838e83168357aed6643ae1b8", "predicted_answer": "Lucene-based retrieval system.", "predicted_evidence": ["n/a"]}
{"question_id": "f46a907360d75ad566620e7f6bf7746497b6e4a9", "predicted_answer": "Word2Vec embeddings.", "predicted_evidence": ["n/a"]}
{"question_id": "79d999bdf8a343ce5b2739db3833661a1deab742", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "71d59c36225b5ee80af11d3568bdad7425f17b0c", "predicted_answer": "7.6% better.", "predicted_evidence": ["n/a"]}
{"question_id": "efc65e5032588da4a134d121fe50d49fe8fe5e8c", "predicted_answer": "Supplemental tasks include tagging, question type classification, and subjectivity classification.", "predicted_evidence": ["n/a"]}
{"question_id": "a30958c7123d1ad4723dcfd19d8346ccedb136d5", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "08333e4dd1da7d6b5e9b645d40ec9d502823f5d7", "predicted_answer": "10%", "predicted_evidence": ["n/a"]}
{"question_id": "bc1bc92920a757d5ec38007a27d0f49cb2dde0d1", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "942eb1f7b243cdcfd47f176bcc71de2ef48a17c4", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "9bffc9a9c527e938b2a95ba60c483a916dbd1f6b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "8434974090491a3c00eed4f22a878f0b70970713", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "b67420da975689e47d3ea1c12b601851018c4071", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "01d91d356568fca79e47873bd0541bd22ba66ec0", "predicted_answer": "The paper used the SemEval-2017 and SemEval-2018 datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "37e45a3439b048a80c762418099a183b05772e6a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "a4e66e842be1438e5cd8d7cb2a2c589f494aee27", "predicted_answer": "Decision Trees.", "predicted_evidence": ["n/a"]}
{"question_id": "cb78e280e3340b786e81636431834b75824568c3", "predicted_answer": "9", "predicted_evidence": ["n/a"]}
{"question_id": "2941874356e98eb2832ba22eae9cb08ec8ce0308", "predicted_answer": "The paper does not mention the baseline benchmarks.", "predicted_evidence": ["n/a"]}
{"question_id": "4e50e9965059899d15d3c3a0c0a2d73e0c5802a0", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "67d8e50ddcc870db71c94ad0ad7f8a59a6c67ca6", "predicted_answer": "Seven.", "predicted_evidence": ["n/a"]}
{"question_id": "aecb485ea7d501094e50ad022ade4f0c93088d80", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "2fea3c955ff78220b2c31a8ad1322bc77f6706f8", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "faa4f28a2f2968cecb770d9379ab2cfcaaf5cfab", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "da068b20988883bc324e55c073fb9c1a5c39be33", "predicted_answer": "Black-box context injection is evaluated on BLEU scores and human evaluation to demonstrate that the correct gender and number information is injected.", "predicted_evidence": ["n/a"]}
{"question_id": "0d6d5b6c00551dd0d2519f117ea81d1e9e8785ec", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "edcde2b675cf8a362a63940b2bbdf02c150fe01f", "predicted_answer": "The components of the black-box context injection system are encoder representation, target language model, auxiliary token embedding, context embedding, and an attention mechanism.", "predicted_evidence": ["n/a"]}
{"question_id": "d20d6c8ecd7cb0126479305d27deb0c8b642b09f", "predicted_answer": "CMVN (Cepstral Mean Variance Normalization) and SpecAugment (Spectrogram Augmentation) are mentioned.", "predicted_evidence": ["n/a"]}
{"question_id": "11e6b79f1f48ddc6c580c4d0a3cb9bcb42decb17", "predicted_answer": "Mel-frequency cepstral coefficients (MFCCs), filter-bank features, and log Mel-spectrograms.", "predicted_evidence": ["n/a"]}
{"question_id": "2677b88c2def3ed94e25a776599555a788d197f2", "predicted_answer": "LSTMP+NGRAM is their best model.", "predicted_evidence": ["n/a"]}
{"question_id": "8ca31caa34cc5b65dc1d01d0d1f36bf8c4928805", "predicted_answer": "Spontaneous speech in the study is conversational telephone speech.", "predicted_evidence": ["n/a"]}
{"question_id": "9ab43f941c11a4b09a0e4aea61b4a5b4612e7933", "predicted_answer": "The previous models used independent span prediction approach for multi-span questions.", "predicted_evidence": ["n/a"]}
{"question_id": "5a02a3dd26485a4e4a77411b50b902d2bda3731b", "predicted_answer": "They use an approach called Tag-based Multi-Span Extraction, which combines sequence tagging and multiple span extraction, to answer multi-span questions. Answer: sequence tagging.", "predicted_evidence": ["n/a"]}
{"question_id": "579941de2838502027716bae88e33e79e69997a6", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "9a65cfff4d99e4f9546c72dece2520cae6231810", "predicted_answer": "F1 score of the proposed model on the entire DROP dataset is 69.2.", "predicted_evidence": ["n/a"]}
{"question_id": "a9def7958eac7b9a780403d4f136927f756bab83", "predicted_answer": "Coref-Net.", "predicted_evidence": ["n/a"]}
{"question_id": "547be35cff38028648d199ad39fb48236cfb99ee", "predicted_answer": "5 times more data.", "predicted_evidence": ["n/a"]}
{"question_id": "47a30eb4d0d6f5f2ff4cdf6487265a25c1b18fd8", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "e42fbf6c183abf1c6c2321957359c7683122b48e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e574f0f733fb98ecef3c64044004aa7a320439be", "predicted_answer": "The expectation regularization loss is defined as a quadratic penalty on the mean of the label distribution, where the mean is computed using the current model's soft predictions.", "predicted_evidence": ["n/a"]}
{"question_id": "b65b1c366c8bcf544f1be5710ae1efc6d2b1e2f1", "predicted_answer": "The non-neural baselines used for the task were rule-based and memory-based.", "predicted_evidence": ["n/a"]}
{"question_id": "bd3ccb63fd8ce5575338d7332e96def7a3fabad6", "predicted_answer": "ATIS (Airline Travel Information System)", "predicted_evidence": ["n/a"]}
{"question_id": "7c794fa0b2818d354ca666969107818a2ffdda0c", "predicted_answer": "Intent classification and slot filling.", "predicted_evidence": ["n/a"]}
{"question_id": "1ef5fc4473105f1c72b4d35cf93d312736833d3d", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "5f9bd99a598a4bbeb9d2ac46082bd3302e961a0f", "predicted_answer": "The models are evaluated on SQuAD 2.0 and a new dataset called HotpotQA.", "predicted_evidence": ["n/a"]}
{"question_id": "b2fab9ffbcf1d6ec6d18a05aeb6e3ab9a4dbf2ae", "predicted_answer": "The paper does not provide enough evidence or information related to how they train models in this setup. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e9cf1b91f06baec79eb6ddfd91fc5d434889f652", "predicted_answer": "The setup provides four commands: 'stop', 'continue', 'why', and 'which'.", "predicted_evidence": ["n/a"]}
{"question_id": "6976296126e4a5c518e6b57de70f8dc8d8fde292", "predicted_answer": "They propose several models, including a unimodal model using text data only, a unimodal model using image data only, a hybrid (multimodal) model, and a feature-based model.", "predicted_evidence": ["n/a"]}
{"question_id": "53640834d68cf3b86cf735ca31f1c70aa0006b72", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "b2b0321b0aaf58c3aa9050906ade6ef35874c5c1", "predicted_answer": "838,859.", "predicted_evidence": ["n/a"]}
{"question_id": "4e9684fd68a242cb354fa6961b0e3b5c35aae4b6", "predicted_answer": "The multimodal model showed an improvement of 3.9% over the best unimodal model. Therefore, the results of multimodal models are better than unimodal models.", "predicted_evidence": ["n/a"]}
{"question_id": "2e632eb5ad611bbd16174824de0ae5efe4892daf", "predicted_answer": "The paper doesn't provide any explicit opinion on why current multimodal models cannot outperform models analyzing only text. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "d1ff6cba8c37e25ac6b261a25ea804d8e58e09c0", "predicted_answer": "The metrics used to benchmark the results are Accuracy, F1-score, Recall and Precision.", "predicted_evidence": ["n/a"]}
{"question_id": "24c0f3d6170623385283dfda7f2b6ca2c7169238", "predicted_answer": "Manual collection.", "predicted_evidence": ["n/a"]}
{"question_id": "21a9f1cddd7cb65d5d48ec4f33fe2221b2a8f62e", "predicted_answer": "The MMHS150K dataset contains 151,325 tweets.", "predicted_evidence": ["n/a"]}
{"question_id": "a0ef0633d8b4040bf7cdc5e254d8adf82c8eed5e", "predicted_answer": "BERT, FastText, and VGG16.", "predicted_evidence": ["n/a"]}
{"question_id": "b0799e26152197aeb3aa3b11687a6cc9f6c31011", "predicted_answer": "The paper proposed three different models.", "predicted_evidence": ["n/a"]}
{"question_id": "4ce4db7f277a06595014db181342f8cb5cb94626", "predicted_answer": "The dataset used in the paper includes annotations for whether each tweet contains hate speech or not. The annotations were provided by a team of expert annotators. Answer: Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "62a6382157d5f9c1dce6e6c24ac5994442053002", "predicted_answer": "The evaluation metrics used were purity, Normalized Mutual Information (NMI), and Adjusted Rand Index (ARI).", "predicted_evidence": ["n/a"]}
{"question_id": "9e04730907ad728d62049f49ac828acb4e0a1a2a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "5a0841cc0628e872fe473874694f4ab9411a1d10", "predicted_answer": "25%", "predicted_evidence": ["n/a"]}
{"question_id": "a5dd569e6d641efa86d2c2b2e970ce5871e0963f", "predicted_answer": "Agglomerative Hierarchical Clustering (AHC) and K-Means clustering.", "predicted_evidence": ["n/a"]}
{"question_id": "785c054f6ea04701f4ab260d064af7d124260ccc", "predicted_answer": "20News and Reuters-21578.", "predicted_evidence": ["n/a"]}
{"question_id": "3f6610d1d68c62eddc2150c460bf1b48a064e5e6", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "4c854d33a832f3f729ce73b206ff90677e131e48", "predicted_answer": "Transformers and sequential neural models.", "predicted_evidence": ["n/a"]}
{"question_id": "163c15da1aa0ba370a00c5a09294cd2ccdb4b96d", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "90dd5c0f5084a045fd6346469bc853c33622908f", "predicted_answer": "The paper evaluates the proposed model on a benchmark dataset called AI2's Elementary School Math (ESM).", "predicted_evidence": ["n/a"]}
{"question_id": "095888f6e10080a958d9cd3f779a339498f3a109", "predicted_answer": "They used two datasets: Math23K and MAWPS.", "predicted_evidence": ["n/a"]}
{"question_id": "57e783f00f594e08e43a31939aedb235c9d5a102", "predicted_answer": "The evaluation metrics used were F1 score, precision, recall, BLEU score, and Word Error Rate.", "predicted_evidence": ["n/a"]}
{"question_id": "9646fa1abbe3102a0364f84e0a55d107d45c97f0", "predicted_answer": "Real production data came from an online marketplace.", "predicted_evidence": ["n/a"]}
{"question_id": "29983f4bc8a5513a198755e474361deee93d4ab6", "predicted_answer": "Humor rating labels and binary feedback labels (i.e., whether or not the user found the joke funny).", "predicted_evidence": ["n/a"]}
{"question_id": "6c0f97807cd83a94a4d26040286c6f89c4a0f8e0", "predicted_answer": "TF-IDF and word embedding representations.", "predicted_evidence": ["n/a"]}
{"question_id": "13ca4bf76565564c8ec3238c0cbfacb0b41e14d2", "predicted_answer": "WikiText-103, AG-NEWS and Sogou News.", "predicted_evidence": ["n/a"]}
{"question_id": "70797f66d96aa163a3bee2be30a328ba61c40a18", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "71f2b368228a748fd348f1abf540236568a61b07", "predicted_answer": "French texts from various genres and domains.", "predicted_evidence": ["n/a"]}
{"question_id": "d3d4eef047aa01391e3e5d613a0f1f786ae7cfc7", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "63723c6b398100bba5dc21754451f503cb91c9b8", "predicted_answer": "The paper presents a new French language model called CamemBERT that achieves state of the art on a variety of natural language processing tasks.", "predicted_evidence": ["n/a"]}
{"question_id": "5471766ca7c995dd7f0f449407902b32ac9db269", "predicted_answer": "CamemBERT outperformed previous results on several French language tasks by a significant margin. Specifically, it achieved a new state-of-the-art performance on 8 tasks and surpassed the previous state-of-the-art results by an average margin of 6.2%.", "predicted_evidence": ["n/a"]}
{"question_id": "dc49746fc98647445599da9d17bc004bafdc4579", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "8720c096c8b990c7b19f956ee4930d5f2c019e2b", "predicted_answer": "Five months.", "predicted_evidence": ["n/a"]}
{"question_id": "b573b36936ffdf1d70e66f9b5567511c989b46b2", "predicted_answer": "French text from various sources, including Wikipedia, Europarl and various web pages.", "predicted_evidence": ["n/a"]}
{"question_id": "bf25a202ac713a34e09bf599b3601058d9cace46", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "abebf9c8c9cf70ae222ecb1d3cabf8115b9fc8ac", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "2df910c9806f0c379d7bb1bc2be2610438e487dc", "predicted_answer": "The paper used four datasets: Twitter dataset, Reddit dataset, Wikipedia Talk dataset, and the Civil Comments dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "a2a3af59f3f18a28eb2ca7055e1613948f395052", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d92f1c15537b33b32bfc436e6d017ae7d9d6c29a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "fa3663567c48c27703e09c42930e51bacfa54905", "predicted_answer": "0.903 F1 score.", "predicted_evidence": ["n/a"]}
{"question_id": "7997b9971f864a504014110a708f215c84815941", "predicted_answer": "Limited context and noisy text.", "predicted_evidence": ["n/a"]}
{"question_id": "0d1408744651c3847469c4a005e4a9dccbd89cf1", "predicted_answer": "F1-score, Precision, Recall.", "predicted_evidence": ["n/a"]}
{"question_id": "a3d83c2a1b98060d609e7ff63e00112d36ce2607", "predicted_answer": "1.9.", "predicted_evidence": ["n/a"]}
{"question_id": "aeda22ae760de7f5c0212dad048e4984cd613162", "predicted_answer": "The dataset includes annotations for manual evaluation and diagnostic testing.", "predicted_evidence": ["n/a"]}
{"question_id": "d5fa26a2b7506733f3fa0973e2fe3fc1bbd1a12d", "predicted_answer": "Yes. The possible sentence transformations are represented as new sentences in the COSTRA 1.0 dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "2d536961c6e1aec9f8491e41e383dc0aac700e0a", "predicted_answer": "15 types of modifications: Antonym, Appositive, Attribute, Comparative, Compound, Contradiction, Contraction, Derivation, MWE (multi-word expression), Negation, Punctuation, Syntactic, Tense, Wh-Questions, Word Order.", "predicted_evidence": ["n/a"]}
{"question_id": "18482658e0756d69e39a77f8fcb5912545a72b9b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "9d336c4c725e390b6eba8bb8fe148997135ee981", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "016b59daa84269a93ce821070f4f5c1a71752a8a", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "771b373d09e6eb50a74fffbf72d059ad44e73ab0", "predicted_answer": "They introduce language variation using diverse approaches such as synonym substitutions, sentence splitting and reordering, and paraphrasing.", "predicted_evidence": ["n/a"]}
{"question_id": "efb52bda7366d2b96545cf927f38de27de3b5b77", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "1a7d28c25bb7e7202230e1b70a885a46dac8a384", "predicted_answer": "400,000.", "predicted_evidence": ["n/a"]}
{"question_id": "6bc45d4f908672945192390642da5a2760971c40", "predicted_answer": "The paper does not provide information about the size of the unrelated corpus universal embedding is trained on.", "predicted_evidence": ["n/a"]}
{"question_id": "48cc41c372d44b69a477998be449f8b81384786b", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "efb3a87845460655c53bd7365bcb8393c99358ec", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "0619fc797730a3e59ac146a5a4575c81517cc618", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "846a1992d66d955fa1747bca9a139141c19908e8", "predicted_answer": "They used three datasets - Sentiment140, Sanders Analytics and SemEval2016 Task 4 dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "1ef8d1cb1199e1504b6b0daea52f2e4bd2ef7023", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "12d77ac09c659d2e04b5e3955a283101c3ad1058", "predicted_answer": "Three datasets used are: SemEval-2013 dataset, Sentiment140 dataset, and the STS-Gold dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "d60a3887a0d434abc0861637bbcd9ad0c596caf4", "predicted_answer": "The paper does not propose any semantic rules. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "69a7a6675c59a4c5fb70006523b9fe0f01ca415c", "predicted_answer": "Entity prediction, link prediction, and triple classification.", "predicted_evidence": ["n/a"]}
{"question_id": "60cb756d382b3594d9e1f4a5e2366db407e378ae", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "352a1bf734b2d7f0618e9e2b0dbed4a3f1787160", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "045dbdbda5d96a672e5c69442e30dbf21917a1ee", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "c20b012ad31da46642c553ce462bc0aad56912db", "predicted_answer": "Amazon, Yelp, IMDB.", "predicted_evidence": ["n/a"]}
{"question_id": "13e87f6d68f7217fd14f4f9a008a65dd2a0ba91c", "predicted_answer": "The paper does not provide a clear answer to the question.", "predicted_evidence": ["n/a"]}
{"question_id": "89b9a2389166b992c42ca19939d750d88c5fa79b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "dccc3b182861fd19ccce5bd00ce9c3f40451ed6e", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "98ba7a7aae388b1a77dd6cab890977251d906359", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "3da9a861dfa25ed486cff0ef657d398fdebf8a93", "predicted_answer": "Baseline models: LSTM, GRU, and Tree-LSTM.", "predicted_evidence": ["n/a"]}
{"question_id": "8c0a0747a970f6ea607ff9b18cfeb738502d9a95", "predicted_answer": "Unanswerable. The paper did not provide information on the performance of any approach on their dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "529dabe7b4a8a01b20ee099701834b60fb0c43b0", "predicted_answer": "The utterances come from diverse settings including office, home, and public places.", "predicted_evidence": ["n/a"]}
{"question_id": "a2be2bd84e5ae85de2ab9968147b3d49c84dfb7f", "predicted_answer": "Genres are not covered.", "predicted_evidence": ["n/a"]}
{"question_id": "5699996a7a2bb62c68c1e62e730cabf1e3186eef", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "944d5dbe0cfc64bf41ea36c11b1d378c408d40b8", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "327e6c6609fbd4c6ae76284ca639951f03eb4a4c", "predicted_answer": "8.73% inferior.", "predicted_evidence": ["n/a"]}
{"question_id": "df8cc1f395486a12db98df805248eb37c087458b", "predicted_answer": "The new model is evaluated on the GLUE benchmark and the SQuAD dataset. Answer: GLUE benchmark and SQuAD dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "6e97c06f998f09256be752fa75c24ba853b0db24", "predicted_answer": "The authors measure performance using accuracy and F1 score.", "predicted_evidence": ["n/a"]}
{"question_id": "de2d33760dc05f9d28e9dabc13bab2b3264cadb7", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "63bb39fd098786a510147f8ebc02408de350cb7c", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "6333845facb22f862ffc684293eccc03002a4830", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "a12a08099e8193ff2833f79ecf70acf132eda646", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "999b20dc14cb3d389d9e3ba5466bc3869d2d6190", "predicted_answer": "Recent Advances in Neural Question Generation.", "predicted_evidence": ["n/a"]}
{"question_id": "ca4b66ffa4581f9491442dcec78ca556253c8146", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "b3ff166bd480048e099d09ba4a96e2e32b42422b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "3703433d434f1913307ceb6a8cfb9a07842667dd", "predicted_answer": "The paper covers both supervised and unsupervised learning paradigms for neural question generation. Answer: Supervised, Unsupervised.", "predicted_evidence": ["n/a"]}
{"question_id": "f7c34b128f8919e658ba4d5f1f3fc604fb7ff793", "predicted_answer": "Text, image and knowledge graph.", "predicted_evidence": ["n/a"]}
{"question_id": "d42031893fd4ba5721c7d37e1acb1c8d229ffc21", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "a999761aa976458bbc7b4f330764796446d030ff", "predicted_answer": "Open Named Entity modeling from embedding distribution.", "predicted_evidence": ["n/a"]}
{"question_id": "f229069bcb05c2e811e4786c89b0208af90d9a25", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "6b55b558ed581759425ede5d3a6fcdf44b8082ac", "predicted_answer": "Previous methods: Rule-based methods, VADER, Na\u00efve Bayes, SVM, Maximum Entropy, Decision Tree, Random Forest, and CNN.", "predicted_evidence": ["n/a"]}
{"question_id": "3e3f5254b729beb657310a5561950085fa690e83", "predicted_answer": "The paper does not mention any \"effective word score\" calculation. Therefore, the answer is: Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "5bb96b255dab3e47a8a68b1ffd7142d0e21ebe2a", "predicted_answer": "The paper measures tweet subjectivity using distant supervision.", "predicted_evidence": ["n/a"]}
{"question_id": "129c03acb0963ede3915415953317556a55f34ee", "predicted_answer": "To improve the performance of DMN, it is necessary to provide supporting fact supervision.", "predicted_evidence": ["n/a"]}
{"question_id": "58b3b630a31fcb9bffb510390e1ec30efe87bfbf", "predicted_answer": "Supporting fact supervision refers to giving additional information in the form of factual statements that support the answer to a question in the training data for dynamic memory networks.", "predicted_evidence": ["n/a"]}
{"question_id": "141dab98d19a070f1ce7e7dc384001d49125d545", "predicted_answer": "They added convolutional layers to the input module. \n\nAnswer: Convolutional layers were added.", "predicted_evidence": ["n/a"]}
{"question_id": "afdad4c9bdebf88630262f1a9a86ac494f06c4c1", "predicted_answer": "They introduced Dynamic Attention Memory module for DMN+.", "predicted_evidence": ["n/a"]}
{"question_id": "bfd4fc82ffdc5b2b32c37f4222e878106421ce2a", "predicted_answer": "The model uses attention mechanisms to dynamically select relevant memories at each hop, thus allowing it to circumvent the lack of supporting facts during training.", "predicted_evidence": ["n/a"]}
{"question_id": "1ce26783f0ff38925bfc07bbbb65d206e52c2d21", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "9213159f874b3bdd9b4de956a88c703aac988411", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "5f4e6ce4a811c4b3ab07335d89db2fd2a8d8d8b2", "predicted_answer": "They perform manual evaluation using two criteria: (1) style preservation and (2) content preservation.", "predicted_evidence": ["n/a"]}
{"question_id": "a234bcbf2e41429422adda37d9e926b49ef66150", "predicted_answer": "The paper uses the BLEU and Self-BLEU metrics for automatic evaluation.", "predicted_evidence": ["n/a"]}
{"question_id": "c383fa9170ae00a4a24a8e39358c38395c5f034b", "predicted_answer": "The paper does not provide enough evidence or information to answer this question. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "83251fd4a641cea8b180b49027e74920bca2699a", "predicted_answer": "They model style as a suite of low-level linguistic controls, such as frequency of pronouns, prepositions, and subordinate clause constructions. (Answer: as a suite of low-level linguistic controls)", "predicted_evidence": ["n/a"]}
{"question_id": "5d70c32137e82943526911ebdf78694899b3c28a", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "97dac7092cf8082a6238aaa35f4b185343b914af", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "195611926760d1ceec00bd043dfdc8eba2df5ad1", "predicted_answer": "BERT (Bidirectional Encoder Representations from Transformers)", "predicted_evidence": ["n/a"]}
{"question_id": "445e792ce7e699e960e2cb4fe217aeacdd88d392", "predicted_answer": "This paper does not provide enough information to answer this question.", "predicted_evidence": ["n/a"]}
{"question_id": "a3b1520e3da29d64af2b6e22ff15d330026d0b36", "predicted_answer": "Visual, textual and connectivity features are used from each data type.", "predicted_evidence": ["n/a"]}
{"question_id": "2cf8825639164a842c3172af039ff079a8448592", "predicted_answer": "The paper does not provide enough evidence or information related to how the data is annotated. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "36b25021464a9574bf449e52ae50810c4ac7b642", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "98515bd97e4fae6bfce2d164659cd75e87a9fc89", "predicted_answer": "The user interaction data is sourced from the social network platform Reddit.", "predicted_evidence": ["n/a"]}
{"question_id": "53bf6238baa29a10f4ff91656c470609c16320e1", "predicted_answer": "The textual data is sourced from participants' free-text responses to open-ended survey questions.", "predicted_evidence": ["n/a"]}
{"question_id": "b27f7993b1fe7804c5660d1a33655e424cea8d10", "predicted_answer": "The source of the visual data is smartphones.", "predicted_evidence": ["n/a"]}
{"question_id": "e21a8581cc858483a31c6133e53dd0cfda76ae4c", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "9f6e877e3bde771595e8aee10c2656a0e7b9aeb2", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "a3783e42c2bf616c8a07bd3b3d503886660e4344", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "0d0959dba3f7c15ee4f5cdee51682656c4abbd8f", "predicted_answer": "A sememe is a minimal unit of meaning in Chinese language.", "predicted_evidence": ["n/a"]}
{"question_id": "589be705a5cc73a23f30decba23ce58ec39d313b", "predicted_answer": "The paper used a diverse range of Dutch language datasets for training and evaluation.", "predicted_evidence": ["n/a"]}
{"question_id": "6e962f1f23061f738f651177346b38fd440ff480", "predicted_answer": "The paper does not provide enough information to determine the current state of the art.", "predicted_evidence": ["n/a"]}
{"question_id": "594a6bf37eab64a16c6a05c365acc100e38fcff1", "predicted_answer": "They experimented on several language tasks including named entity recognition, part-of-speech tagging, dependency parsing, and natural language inference.", "predicted_evidence": ["n/a"]}
{"question_id": "d79d897f94e666d5a6fcda3b0c7e807c8fad109e", "predicted_answer": "The experiments in the paper suggest that natural language based agents are more robust. \n\nAnswer: Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "599d9ca21bbe2dbe95b08cf44dfc7537bde06f98", "predicted_answer": "Natural language based agents show significantly better performance in the experiments conducted.", "predicted_evidence": ["n/a"]}
{"question_id": "827464c79f33e69959de619958ade2df6f65fdee", "predicted_answer": "3 times faster.", "predicted_evidence": ["n/a"]}
{"question_id": "8e857e44e4233193c7b2d538e520d37be3ae1552", "predicted_answer": "The authors perform experiments on Atari games and a text-based game called \"Coin Collector\" to evaluate the effectiveness of their proposed natural language state representation for reinforcement learning.", "predicted_evidence": ["n/a"]}
{"question_id": "084fb7c80a24b341093d4bf968120e3aff56f693", "predicted_answer": "The state to learn and complete tasks is represented via natural language as a sentence. Answer: Sentence.", "predicted_evidence": ["n/a"]}
{"question_id": "babe72f0491e65beff0e5889380e8e32d7a81f78", "predicted_answer": "Unanswerable. The paper does not provide a comparison with a MMR baseline.", "predicted_evidence": ["n/a"]}
{"question_id": "31ee92e521be110b6a5a8d08cc9e6f90a3a97aae", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "737397f66751624bcf4ef891a10b29cfc46b0520", "predicted_answer": "Datasets used in the paper: Moral Foundations Dataset (MFD), Moral Machine dataset, and Moral Reasoning dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "87cb19e453cf7e248f24b5f7d1ff9f02d87fc261", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "5fb6a21d10adf4e81482bb5c1ec1787dc9de260d", "predicted_answer": "They quantify moral relevance using moral keywords and their frequency in a text.", "predicted_evidence": ["n/a"]}
{"question_id": "542a87f856cb2c934072bacaa495f3c2645f93be", "predicted_answer": "Fairness, loyalty, authority, harm, and sanctity.", "predicted_evidence": ["n/a"]}
{"question_id": "4fcc668eb3a042f60c4ce2e7d008e7923b25b4fc", "predicted_answer": "The paper uses multiple dataset sources to demonstrate moral sentiment through history.", "predicted_evidence": ["n/a"]}
{"question_id": "c180f44667505ec03214d44f4970c0db487a8bae", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "76d62e414a345fe955dc2d99562ef5772130bc7e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "6b9310b577c6232e3614a1612cbbbb17067b3886", "predicted_answer": "Guidelines for input vernacular writing are: using simple sentences, avoiding classical Chinese vocabulary and idioms, and using commonly used vocabulary.", "predicted_evidence": ["n/a"]}
{"question_id": "d484a71e23d128f146182dccc30001df35cdf93f", "predicted_answer": "3.7% and 1.5 BLEU score improvement.", "predicted_evidence": ["n/a"]}
{"question_id": "5787ac3e80840fe4cf7bfae7e8983fa6644d6220", "predicted_answer": "Classical Chinese poems and modern Chinese poems.", "predicted_evidence": ["n/a"]}
{"question_id": "ee31c8a94e07b3207ca28caef3fbaf9a38d94964", "predicted_answer": "The evaluation metrics were joint goal accuracy, match score, F1 score, success rate, and average turns.", "predicted_evidence": ["n/a"]}
{"question_id": "66d743b735ba75589486e6af073e955b6bb9d2a4", "predicted_answer": "The baseline systems were rule-based systems.", "predicted_evidence": ["n/a"]}
{"question_id": "b9f852256113ef468d60e95912800fab604966f6", "predicted_answer": "MultiWOZ 2.1 and MultiWOZ 2.2.", "predicted_evidence": ["n/a"]}
{"question_id": "88f8ab2a417eae497338514142ac12c3cec20876", "predicted_answer": "The KB used is unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "05e3b831e4c02bbd64a6e35f6c52f0922a41539a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "bd74452f8ea0d1d82bbd6911fbacea1bf6e08cab", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "6472f9d0a385be81e0970be91795b1b97aa5a9cf", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "2173809eb117570d289cefada6971e946b902bd6", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "293e9a0b30670f4f0a380e574a416665a8c55bc2", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "17de58c17580350c9da9c2f3612784b432154d11", "predicted_answer": "SVM (Support Vector Machine) classifier.", "predicted_evidence": ["n/a"]}
{"question_id": "ff27d6e6eb77e55b4d39d343870118d1a6debd5e", "predicted_answer": "Linear SVM.", "predicted_evidence": ["n/a"]}
{"question_id": "29772ba04886bee2d26b7320e1c6d9b156078891", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "94dc437463f7a7d68b8f6b57f1e3606eacc4490a", "predicted_answer": "There are 4 categories.", "predicted_evidence": ["n/a"]}
{"question_id": "9d9d84822a9c42eb0257feb7c18086d390dae3be", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d27e3a099954e917b6491e81b2e907478d7f1233", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "c0a11ba0f6bbb4c69b5a0d4ae9d18e86a4a8f354", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "dfc393ba10ec4af5a17e5957fcbafdffdb1a6443", "predicted_answer": "The paper analyzes three NLI models: ESIM, DIIN, and BERT.", "predicted_evidence": ["n/a"]}
{"question_id": "311a7fa62721e82265f4e0689b4adc05f6b74215", "predicted_answer": "They define upward reasoning as the case where increasing the value of an input feature always increases the output value of the model, and downward reasoning as the opposite.", "predicted_evidence": ["n/a"]}
{"question_id": "82bcacad668351c0f81bd841becb2dbf115f000e", "predicted_answer": "Monotonicity reasoning refers to the ability to reason about how changing one variable affects the value of another variable, while preserving the same direction of change.", "predicted_evidence": ["n/a"]}
{"question_id": "5937ebbf04f62d41b48cbc6b5c38fc309e5c2328", "predicted_answer": "Dialogue acts were found to have relations with emotions in the datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "dcd6f18922ac5c00c22cef33c53ff5ae08b42298", "predicted_answer": "The paper does not mention an \"ensemble annotator\" and therefore this question is Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "2965c86467d12b79abc16e1457d848cb6ca88973", "predicted_answer": "The dialogue act labels were defined using existing taxonomies and annotator guidelines.", "predicted_evidence": ["n/a"]}
{"question_id": "b99948ac4810a7fe3477f6591b8cf211d6398e67", "predicted_answer": "One model was used.", "predicted_evidence": ["n/a"]}
{"question_id": "73d657d6faed0c11c65b1ab60e553db57f4971ca", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "9ef182b61461d0d8b6feb1d6174796ccde290a15", "predicted_answer": "They annotate their own dataset. \n\nAnswer: Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "f6f8054f327a2c084a73faca16cf24a180c094ae", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "b8f711179a468fec9a0d8a961fb0f51894af4b31", "predicted_answer": "Siamese neural network.", "predicted_evidence": ["n/a"]}
{"question_id": "3bf429633ecbbfec3d7ffbcfa61fa90440cc918b", "predicted_answer": "Aspect terms are identified using linguistic patterns and rules.", "predicted_evidence": ["n/a"]}
{"question_id": "94e0cf44345800ef46a8c7d52902f074a1139e1a", "predicted_answer": "WebAnno, CONLL2003, Wikigold and Ontonotes are the web and user-generated NER datasets used for the analysis.", "predicted_evidence": ["n/a"]}
{"question_id": "ad67ca844c63bf8ac9fdd0fa5f58c5a438f16211", "predicted_answer": "Raw audio data from thousands of hours of unlabeled recordings from diverse sources.", "predicted_evidence": ["n/a"]}
{"question_id": "12eaaf3b6ebc51846448c6e1ad210dbef7d25a96", "predicted_answer": "14.", "predicted_evidence": ["n/a"]}
{"question_id": "828615a874512844ede9d7f7d92bdc48bb48b18d", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "a43c400ae37a8705ff2effb4828f4b0b177a74c4", "predicted_answer": "The character representations from various languages are joint using a shared character-level architecture.", "predicted_evidence": ["n/a"]}
{"question_id": "4056ee2fd7a0a0f444275e627bb881134a1c2a10", "predicted_answer": "News Crawl 2015 dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "f6496b8d09911cdf3a9b72aec0b0be6232a6dba1", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "5c90e1ed208911dbcae7e760a553e912f8c237a5", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "3c3b4797e2b21e2c31cf117ad9e52f327721790f", "predicted_answer": "English, Spanish, and Chinese.", "predicted_evidence": ["n/a"]}
{"question_id": "a7d72f308444616a0befc8db7ad388b3216e2143", "predicted_answer": "The paper uses two datasets: TACRED and a Wikipedia-based Cross-lingual Relation Extraction Corpus.", "predicted_evidence": ["n/a"]}
{"question_id": "dfb0351e8fa62ceb51ce77b0f607885523d1b8e8", "predicted_answer": "Using both language and vision improves the performance of auto-completion compared to using only language.", "predicted_evidence": ["n/a"]}
{"question_id": "a130aa735de3b65c71f27018f20d3c068bafb826", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "0c1663a7f7750b399f40ef7b4bf19d5c598890ff", "predicted_answer": "They use a neural network to complete the user query prefix conditioned upon an image.", "predicted_evidence": ["n/a"]}
{"question_id": "aa800b424db77e634e82680f804894bfa37f2a34", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "fbd47705262bfa0a2ba1440a2589152def64cbbd", "predicted_answer": "4.3%", "predicted_evidence": ["n/a"]}
{"question_id": "51aaec4c511d96ef5f5c8bae3d5d856d8bc288d3", "predicted_answer": "Baselines.", "predicted_evidence": ["n/a"]}
{"question_id": "3aee5c856e0ee608a7664289ffdd11455d153234", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "f42d470384ca63a8e106c7caf1cb59c7b92dbc27", "predicted_answer": "The evaluation metrics used in the paper are BLEU-4 score, Average Percentage of Verbs and Prepositions in the Generated Plan, Success Rate, and Coverage.", "predicted_evidence": ["n/a"]}
{"question_id": "29bdd1fb20d013b23b3962a065de3a564b14f0fb", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "25b2ae2d86b74ea69b09c140a41593c00c47a82b", "predicted_answer": "The navigation instructions were collected from Amazon Mechanical Turk.", "predicted_evidence": ["n/a"]}
{"question_id": "fd7f13b63f6ba674f5d5447b6114a201fe3137cb", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "c82e945b43b2e61c8ea567727e239662309e9508", "predicted_answer": "The term \"additional features\" is not clearly defined or mentioned in the paper, therefore this question is unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "fbee81a9d90ff23603ee4f5986f9e8c0eb035b52", "predicted_answer": "The paper does not provide information on their initial results on this task.", "predicted_evidence": ["n/a"]}
{"question_id": "39cf0b3974e8a19f3745ad0bcd1e916bf20eeab8", "predicted_answer": "Mental Health Electronic Health Records from the South London and Maudsley NHS Foundation Trust.", "predicted_evidence": ["n/a"]}
{"question_id": "1f6180bba0bc657c773bd3e4269f87540a520ead", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "57388bf2693d71eb966d42fa58ab66d7f595e55f", "predicted_answer": "The method uses a morphological lexicon to segment words into morphemes, which are then used to generate subword units.", "predicted_evidence": ["n/a"]}
{"question_id": "47796c7f0a7de76ccb97ccbd43dc851bb8a613d5", "predicted_answer": "The paper proposes a new morphological word segmentation method based on unsupervised learning using a subword-level neural language model.", "predicted_evidence": ["n/a"]}
{"question_id": "9d5153a7553b7113716420a6ddceb59f877eb617", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "55c840a2f1f663ab2bff984ae71501b17429d0c0", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "fa5357c56ea80a21a7ca88a80f21711c5431042c", "predicted_answer": "96", "predicted_evidence": ["n/a"]}
{"question_id": "35915166ab2fd3d39c0297c427d4ac00e8083066", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "e6c872fea474ea96ca2553f7e9d5875df4ef55cd", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "fc29bb14f251f18862c100e0d3cd1396e8f2c3a1", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "f3e96c5487d87557a661a65395b0162033dc05b3", "predicted_answer": "Polish and Lithuanian are examples of prefixing languages.", "predicted_evidence": ["n/a"]}
{"question_id": "74db8301d42c7e7936eb09b2171cd857744c52eb", "predicted_answer": "The performance is evaluated using F1 score.", "predicted_evidence": ["n/a"]}
{"question_id": "587885bc86543b8f8b134c20e2c62f6251195571", "predicted_answer": "Three target languages studied in the paper are German, Hungarian, and Italian.", "predicted_evidence": ["n/a"]}
{"question_id": "b72264a73eea36c828e7de778a8b4599a5d02b39", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "24cc1586e5411a7f8574796d3c576b7c677d6e21", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "db291d734524fa51fb314628b64ebe1bac7f7e1e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "85abd60094c92eb16f39f861c6de8c2064807d02", "predicted_answer": "Word embeddings, sentence-level cross-lingual embeddings, and bilingual document vectors.", "predicted_evidence": ["n/a"]}
{"question_id": "50f09a044f0c0795cc636c3e25a4f7c3231fb08d", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "26b5c090f72f6d51e5d9af2e470d06b2d7fc4a98", "predicted_answer": "The paper compares against two baselines: an RNN encoder-decoder model and a Transformer model.", "predicted_evidence": ["n/a"]}
{"question_id": "8c0621016e96d86a7063cb0c9ec20c76a2dba678", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "f1214a05cc0e6d870c789aed24a8d4c768e1db2f", "predicted_answer": "The paper explored the language pairs Chinese-English and German-English.", "predicted_evidence": ["n/a"]}
{"question_id": "41d3ab045ef8e52e4bbe5418096551a22c5e9c43", "predicted_answer": "The paper used multiple datasets, including WMT14 English-German, WMT15 English-German, WMT16 Romanian-to-English, and IWSLT14 French-to-English.", "predicted_evidence": ["n/a"]}
{"question_id": "62736ad71c76a20aee8e003c462869bab4ab4b1e", "predicted_answer": "The paper does not provide evidence on how the order of binomials is tracked across time.", "predicted_evidence": ["n/a"]}
{"question_id": "aaf50a6a9f449389ef212d25d0fae59c10b0df92", "predicted_answer": "Web forums, news articles, scientific publications and online blogs.", "predicted_evidence": ["n/a"]}
{"question_id": "a1917232441890a89b9a268ad8f987184fa50f7a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "574f17134e4dd041c357ebb75a7ef590da294d22", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "41fd359b8c1402b31b6f5efd660143d1414783a0", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d216d715ec27ee2d4949f9e908895a18fb3238e2", "predicted_answer": "Previous rules for predicting binomial ordering that are used in the paper are: adjective for affect before colour, size, and shape adjectives. Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "ba973b13f26cd5eb1da54663c0a72842681d5bf5", "predicted_answer": "The paper does not mention any particular online text resources used to test binomial lists. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "508580af51483b5fb0df2630e8ea726ff08d537b", "predicted_answer": "They model a city description using word embeddings.", "predicted_evidence": ["n/a"]}
{"question_id": "89d1687270654979c53d0d0e6a845cdc89414c67", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "fc6cfac99636adda28654e1e19931c7394d76c7c", "predicted_answer": "K-means.", "predicted_evidence": ["n/a"]}
{"question_id": "ed7a3e7fc1672f85a768613e7d1b419475950ab4", "predicted_answer": "multi-domain", "predicted_evidence": ["n/a"]}
{"question_id": "72ceeb58e783e3981055c70a3483ea706511fac3", "predicted_answer": "Joint goal accuarcy, Iu, In, IF1, turn-level accuarcy, token-level accuarcy.", "predicted_evidence": ["n/a"]}
{"question_id": "9bfa46ad55136f2a365e090ce585fc012495393c", "predicted_answer": "The paper uses the MultiWOZ 2.0 and 2.1 datasets to evaluate performance. Answer: MultiWOZ 2.0 and 2.1.", "predicted_evidence": ["n/a"]}
{"question_id": "42812113ec720b560eb9463ff5e74df8764d1bff", "predicted_answer": "The paper doesn't mention anything about an automatic theorem prover inferring the relation. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "4f4892f753b1d9c5e5e74c7c94d8c9b6ef523e7b", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "f258ada8577bb71873581820a94695f4a2c223b3", "predicted_answer": "10,000.", "predicted_evidence": ["n/a"]}
{"question_id": "05bb75a1e1202850efa9191d6901de0a34744af0", "predicted_answer": "ConceptNet and Social Media improve performance the most.", "predicted_evidence": ["n/a"]}
{"question_id": "770aeff30846cd3d0d5963f527691f3685e8af02", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "f7817b949605fb04b1e4fec9dd9ca8804fb92ae9", "predicted_answer": "The approach from English does not work on other languages due to the differences in the grammar and morphology of those languages.", "predicted_evidence": ["n/a"]}
{"question_id": "8255f74cae1352e5acb2144fb857758dda69be02", "predicted_answer": "They measure grammaticality using human evaluations.", "predicted_evidence": ["n/a"]}
{"question_id": "db62d5d83ec187063b57425affe73fef8733dd28", "predicted_answer": "MAD-X model.", "predicted_evidence": ["n/a"]}
{"question_id": "946676f1a836ea2d6fe98cb4cfc26b9f4f81984d", "predicted_answer": "Unanswerable. The paper does not report any overall performance metric for the model described.", "predicted_evidence": ["n/a"]}
{"question_id": "3b090b416c4ad7d9b5b05df10c5e7770a4590f6a", "predicted_answer": "Unanswerable", "predicted_evidence": ["n/a"]}
{"question_id": "a1e07c7563ad038ee2a7de5093ea08efdd6077d4", "predicted_answer": "The paper employed two datasets, but it doesn't provide information about their size. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "a1c4f9e8661d4d488b8684f055e0ee0e2275f767", "predicted_answer": "Baseline models are the LSTM and BERT.", "predicted_evidence": ["n/a"]}
{"question_id": "c5171daf82107fce0f285fa18f19e91fbd1215c5", "predicted_answer": "BLEU and Self-BLEU metrics.", "predicted_evidence": ["n/a"]}
{"question_id": "baeb6785077931e842079e9d0c9c9040947ffa4e", "predicted_answer": "The paper used two datasets: the Yelp dataset and the E2E NLG Challenge dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "bb570d4a1b814f508a07e74baac735bf6ca0f040", "predicted_answer": "The model uses a deep enhanced representation approach that encodes both explicit and implicit discourse relations, which allows for better performance than prior models.", "predicted_evidence": ["n/a"]}
{"question_id": "1771a55236823ed44d3ee537de2e85465bf03eaf", "predicted_answer": "Unanswerable. The paper does not provide information on the recall score difference between the systems.", "predicted_evidence": ["n/a"]}
{"question_id": "1d74fd1d38a5532d20ffae4abbadaeda225b6932", "predicted_answer": "F1 score and recall values are not reported in the paper. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "da8bda963f179f5517a864943dc0ee71249ee1ce", "predicted_answer": "The system has 12 layers.", "predicted_evidence": ["n/a"]}
{"question_id": "5c059a13d59947f30877bed7d0180cca20a83284", "predicted_answer": "Wikipedia and three news corpora: CNN, DailyMail, and GIGA.", "predicted_evidence": ["n/a"]}
{"question_id": "a1885f807753cff7a59f69b5cf6d0fdef8484057", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "c2553166463b7b5ae4d9786f0446eb06a90af458", "predicted_answer": "Systems tested are: MMT, Stanford and UW.", "predicted_evidence": ["n/a"]}
{"question_id": "cc9f0ac8ead575a9b485a51ddc06b9ecb2e2a44d", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "69e678666d11731c9bfa99953e2cd5a5d11a4d4f", "predicted_answer": "Two large datasets used for evaluation are WikiTableQuestions and GraphQuestions.", "predicted_evidence": ["n/a"]}
{"question_id": "471d624498ab48549ce492ada9e6129da05debac", "predicted_answer": "The paper evaluates both rule-based and neural network-based context modeling methods.", "predicted_evidence": ["n/a"]}
{"question_id": "f858031ebe57b6139af46ee0f25c10870bb00c3c", "predicted_answer": "Two datasets models are tested on: WikiTableQuestions and Spider.", "predicted_evidence": ["n/a"]}
{"question_id": "1763a029daca7cab10f18634aba02a6bd1b6faa7", "predicted_answer": "4.35% improvement", "predicted_evidence": ["n/a"]}
{"question_id": "f9de9ddea0c70630b360167354004ab8cbfff041", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "fc8bc6a3c837a9d1c869b7ee90cf4e3c39bcd102", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "58e65741184c81c9e7fe0ca15832df2d496beb6f", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "269b05b74d5215b09c16e95a91ae50caedd9e2aa", "predicted_answer": "They use the Krippendorff's alpha inter-annotator metric. \n\nAnswer: Krippendorff's alpha", "predicted_evidence": ["n/a"]}
{"question_id": "0d7f514f04150468b2d1de9174c12c28e52c5511", "predicted_answer": "0.76.", "predicted_evidence": ["n/a"]}
{"question_id": "4d223225dbf84a80e2235448a4d7ba67bfb12490", "predicted_answer": "The paper mentions that the resources used in their study were adapted to the properties of Chinese text, including the use of a Chinese discourse parser. Therefore, the resources were adapted to properties of Chinese text. Answer: Adapted to Chinese property.", "predicted_evidence": ["n/a"]}
{"question_id": "ca26cfcc755f9d0641db0e4d88b4109b903dbb26", "predicted_answer": "The paper does not provide information on how the results compare to baseline models.", "predicted_evidence": ["n/a"]}
{"question_id": "6cdd61ebf84aa742155f4554456cc3233b6ae2bf", "predicted_answer": "The baselines used are claim-only and claim+premise linguistic feature models.", "predicted_evidence": ["n/a"]}
{"question_id": "8e8097cada29d89ca07166641c725e0f8fed6676", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "951098f0b7169447695b47c142384f278f451a1e", "predicted_answer": "The dataset contains annotations of argument impact, pragmatic context, and discourse context.", "predicted_evidence": ["n/a"]}
{"question_id": "07c59824f5e7c5399d15491da3543905cfa5f751", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "77f04cd553df691e8f4ecbe19da89bc32c7ac734", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "728a55c0f628f2133306b6bd88af00eb54017b12", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d5498d16e8350c9785782b57b1e5a82212dbdaad", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "3e839783d8a4f2fe50ece4a9b476546f0842b193", "predicted_answer": "Their result on Stance Sentiment Emotion Corpus was 78.75 F1 score.", "predicted_evidence": ["n/a"]}
{"question_id": "2869d19e54fb554fcf1d6888e526135803bb7d75", "predicted_answer": "76.05% F1-score.", "predicted_evidence": ["n/a"]}
{"question_id": "894c086a2cbfe64aa094c1edabbb1932a3d7c38a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "722e9b6f55971b4c48a60f7a9fe37372f5bf3742", "predicted_answer": "The multi-tasking is performed by jointly training a shared encoder to predict both sentiment and emotion labels.", "predicted_evidence": ["n/a"]}
{"question_id": "9c2f306044b3d1b3b7fdd05d1c046e887796dd7a", "predicted_answer": "Datasets used for training are as follows: SemEval 2014 datasets for ABSA (Restaurant and Laptop), SentiHood dataset, Foursquare dataset and EmoBank dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "3d99bc8ab2f36d4742e408f211bec154bc6696f7", "predicted_answer": "125,039,893 parameters.", "predicted_evidence": ["n/a"]}
{"question_id": "9219eef636ddb020b9d394868959325562410f83", "predicted_answer": "Previous state-of-the-art model is BERT-based model.", "predicted_evidence": ["n/a"]}
{"question_id": "ff83eea2df9976c1a01482818340871b17ad4f8c", "predicted_answer": "76.16 F1 score.", "predicted_evidence": ["n/a"]}
{"question_id": "0ee20a3a343e1e251b74a804e9aa1393d17b46d6", "predicted_answer": "The paper mentions a classifier to automatically classify tweets as factual, propagandistic or unverifiable, which can facilitate the annotation task for human annotators. Thus the classifier can assist human annotators in identifying the nature of the tweets.", "predicted_evidence": ["n/a"]}
{"question_id": "f0e8f045e2e33a2129e67fb32f356242db1dc280", "predicted_answer": "The paper does not provide any specific recommendations to improve performance in future.", "predicted_evidence": ["n/a"]}
{"question_id": "b6c235d5986914b380c084d9535a7b01310c0278", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e9b1e8e575809f7b80b1125305cfa76ae4f5bdfb", "predicted_answer": "Two neural classifiers, CNN and LSTM, are used.", "predicted_evidence": ["n/a"]}
{"question_id": "1e4450e23ec81fdd59821055f998fd9db0398b16", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "02ce4c288df14a90a210cb39973c6ac0fb4cec59", "predicted_answer": "The paper does not provide information about the languages included in the dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "60726d9792d301d5ff8e37fbb31d5104a520dea3", "predicted_answer": "The paper uses multiple datasets, including Twitter data, Google Trends data, and news articles, among others.", "predicted_evidence": ["n/a"]}
{"question_id": "e39d90b8d959697d9780eddce3a343e60543be65", "predicted_answer": "Terms: Twitter metadata, Domain-specific knowledge, Crowdsourcing, Leading Questions.", "predicted_evidence": ["n/a"]}
{"question_id": "c6e63e3b807474e29bfe32542321d015009e7148", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "4ef2fd79d598accc54c084f0cca8ad7c1b3f892a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "40e3639b79e2051bf6bce300d06548e7793daee0", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "8383e52b2adbbfb533fbe8179bc8dae11b3ed6da", "predicted_answer": "The paper explores intent of the passengers riding in autonomous vehicles, including but not limited to destination, route, and preferences.", "predicted_evidence": ["n/a"]}
{"question_id": "5f7850254b723adf891930c6faced1058b99bd57", "predicted_answer": "The HMM models use linguistic features and word embeddings, and the interpretability of those features is not explicitly discussed in the paper.", "predicted_evidence": ["n/a"]}
{"question_id": "4d05a264b2353cff310edb480a917d686353b007", "predicted_answer": "The HMMs learn state sequence information that the LSTMs do not.", "predicted_evidence": ["n/a"]}
{"question_id": "7cdce4222cea6955b656c1a3df1129bb8119e2d0", "predicted_answer": "The authors train an HMM and an LSTM on the same data and use information gain to determine the amount of additional information each method learns beyond the other.", "predicted_evidence": ["n/a"]}
{"question_id": "6ea63327ffbab2fc734dd5c2414e59d3acc56ea5", "predicted_answer": "The paper does not provide evidence for the gap in performance between the HMMs and the LSTMs. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "50690b72dc61748e0159739a9a0243814d37f360", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "8266642303fbc6a1138b4e23ee1d859a6f584fbb", "predicted_answer": "Datasets: Hate Speech and Offensive Language (OLID), and Hate Speech and Target Identification (GermEval).", "predicted_evidence": ["n/a"]}
{"question_id": "3685bf2409b23c47bfd681989fb4a763bcab6be2", "predicted_answer": "Algorithm: FastText embeddings\nDimension size: 300", "predicted_evidence": ["n/a"]}
{"question_id": "19225e460fff2ac3aebc7fe31fcb4648eda813fb", "predicted_answer": "Twitter messages (tweets) with and without hate speech.", "predicted_evidence": ["n/a"]}
{"question_id": "f37026f518ab56c859f6b80b646d7f19a7b684fa", "predicted_answer": "3 times.", "predicted_evidence": ["n/a"]}
{"question_id": "1231934db6adda87c1b15e571468b8e9d225d6fe", "predicted_answer": "864,982.", "predicted_evidence": ["n/a"]}
{"question_id": "81303f605da57ddd836b7c121490b0ebb47c60e7", "predicted_answer": "Datasets used: Hate Speech Text, Toxic Comment Classification Challenge, Wikipedia Toxicity Data.", "predicted_evidence": ["n/a"]}
{"question_id": "a3f108f60143d13fe38d911b1cc3b17bdffde3bd", "predicted_answer": "0.93.", "predicted_evidence": ["n/a"]}
{"question_id": "118ff1d7000ea0d12289d46430154cc15601fd8e", "predicted_answer": "The paper did not mention a specific baseline for the hate speech detection task.", "predicted_evidence": ["n/a"]}
{"question_id": "102a0439739428aac80ac11795e73ce751b93ea1", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d9c26c1bfb3830c9f3dbcccf4c8ecbcd3cb54404", "predicted_answer": "English-German, English-French, and German-French.", "predicted_evidence": ["n/a"]}
{"question_id": "04f72eddb1fc73dd11135a80ca1cf31e9db75578", "predicted_answer": "The new dataset has 30% more coverage than the existing datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "f74eaee72cbd727a6dffa1600cdf1208672d713e", "predicted_answer": "The paper measured coverage using the percentage of the sentences in the training set that had at least one annotated QA-SRL triple.", "predicted_evidence": ["n/a"]}
{"question_id": "068dbcc117c93fa84c002d3424bafb071575f431", "predicted_answer": "Quality was measured using inter-annotator agreement.", "predicted_evidence": ["n/a"]}
{"question_id": "96526a14820b7debfd6f7c5beeade0a854b93d1a", "predicted_answer": "The corpus was obtained through crowdsourcing.", "predicted_evidence": ["n/a"]}
{"question_id": "32ba4d2d15194e889cbc9aa1d21ff1aa6fa27679", "predicted_answer": "Workers are trained through an online tutorial.", "predicted_evidence": ["n/a"]}
{"question_id": "78c010db6413202b4063dc3fb6e3cc59ec16e7e3", "predicted_answer": "The improved annotation protocol in the paper involves adding explicit annotation guidelines for answering questions, and a two-step annotation process that includes a \"first pass\" annotation and a \"second pass\" review.", "predicted_evidence": ["n/a"]}
{"question_id": "a69af5937cab861977989efd72ad1677484b5c8c", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "8847f2c676193189a0f9c0fe3b86b05b5657b76a", "predicted_answer": "The dataset contains 7,942 questions.", "predicted_evidence": ["n/a"]}
{"question_id": "05196588320dfb0b9d9be7d64864c43968d329bc", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "e930f153c89dfe9cff75b7b15e45cd3d700f4c72", "predicted_answer": "The paper suggests that the performance of the multilingual encoder is not heavily affected by the training data size.", "predicted_evidence": ["n/a"]}
{"question_id": "545ff2f76913866304bfacdb4cc10d31dbbd2f37", "predicted_answer": "Multilingual parallel corpora available at the UN corpus and for machine translation competitions.", "predicted_evidence": ["n/a"]}
{"question_id": "cf93a209c8001ffb4ef505d306b6ced5936c6b63", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "fb5ce11bfd74e9d7c322444b006a27f2ff32a0cf", "predicted_answer": "70.0%", "predicted_evidence": ["n/a"]}
{"question_id": "1e2ffa065b640e912d6ed299ff713a12195e12c4", "predicted_answer": "The authors perform simulations on MuJoCo and Carla simulators to validate their approach. \n\nAnswer: MuJoCo and Carla simulators.", "predicted_evidence": ["n/a"]}
{"question_id": "28b2a20779a78a34fb228333dc4b93fd572fda15", "predicted_answer": "Supervised learning.", "predicted_evidence": ["n/a"]}
{"question_id": "b367b823c5db4543ac421d0057b02f62ea16bf9f", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "84737d871bde8058d8033e496179f7daec31c2d3", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "7b3d207ed47ae58286029b62fd0c160a0145e73d", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d58c264068d8ca04bb98038b4894560b571bab3e", "predicted_answer": "The paper reports performance results on various datasets, with F1 scores ranging from 0.85 to 0.97.", "predicted_evidence": ["n/a"]}
{"question_id": "f80d89fb905b3e7e17af1fe179b6f441405ad79b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "5f6fac08c97c85d5f4f4d56d8b0691292696f8e6", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "6adec34d86095643e6b89cda5c7cd94f64381acc", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "62ba1fefc1eb826fe0cbac092d37a3e2098967e9", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "93ac147765ee2573923f68aa47741d4bcbf88fa8", "predicted_answer": "The paper does not propose any features. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "14c0328e8ec6360a913b8ecb3e50cb27650ff768", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "6073fa9050da76eeecd8aa3ccc7ecb16a238d83f", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "eacd7e540cc34cb45770fcba463f4bf968681d59", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "1124804c3702499b78cf0678bab5867e81284b6c", "predicted_answer": "The paper proposes the features \"pointer-explanations\" and \"pointer-highlighting\".", "predicted_evidence": ["n/a"]}
{"question_id": "2b78052314cb730824836ea69bc968df7964b4e4", "predicted_answer": "SQuAD, NewsQA, TriviaQA.", "predicted_evidence": ["n/a"]}
{"question_id": "11d2f0d913d6e5f5695f8febe2b03c6c125b667c", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "1c85a25ec9d0c4f6622539f48346e23ff666cd5f", "predicted_answer": "The paper does not provide enough evidence to answer this question. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "37d829cd42db9ae3d56ab30953a7cf9eda050841", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "4b41f399b193d259fd6e24f3c6e95dc5cae926dd", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "76377e5bb7d0a374b0aefc54697ac9cd89d2eba8", "predicted_answer": "They obtain word lattices from words using a sliding window.", "predicted_evidence": ["n/a"]}
{"question_id": "85aa125b3a15bbb6f99f91656ca2763e8fbdb0ff", "predicted_answer": "Exact match rate (EMR), F1 score and accuracy.", "predicted_evidence": ["n/a"]}
{"question_id": "4b128f9e94d242a8e926bdcb240ece279d725729", "predicted_answer": "LCQMC, BQ Corpus, SogouQA.", "predicted_evidence": ["n/a"]}
{"question_id": "f8f13576115992b0abb897ced185a4f9d35c5de9", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "1fdcc650c65c11908f6bde67d5052087245f3dde", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "abad9beb7295d809d7e5e1407cbf673c9ffffd19", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "265c9b733e4dfffb76acfbade4c0c9b14d3ccde1", "predicted_answer": "The paper states that the dataset consists of \"ultrasound data from 50 children aged 4-11, imaged in the mid-sagittal plane during speech tasks\".", "predicted_evidence": ["n/a"]}
{"question_id": "0f928732f226185c76ad5960402e9342c0619310", "predicted_answer": "Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) are used for classification.", "predicted_evidence": ["n/a"]}
{"question_id": "11c5b12e675cfd8d1113724f019d8476275bd700", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "d24acc567ebaec1efee52826b7eaadddc0a89e8b", "predicted_answer": "68 instances.", "predicted_evidence": ["n/a"]}
{"question_id": "2d62a75af409835e4c123a615b06235a352a67fe", "predicted_answer": "Convolutional neural networks (CNNs)", "predicted_evidence": ["n/a"]}
{"question_id": "fffbd6cafef96eeeee2f9fa5d8ab2b325ec528e6", "predicted_answer": "15.", "predicted_evidence": ["n/a"]}
{"question_id": "c034f38a570d40360c3551a6469486044585c63c", "predicted_answer": "The paper does not provide information on how the proposed method compares to the baselines in terms of perplexity. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "9cbea686732b5b85f77868ca47d2f93cf34516ed", "predicted_answer": "The paper does not provide enough evidence to answer this question. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "6aee16c4f319a190c2a451c1c099b66162299a28", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "4d4b9ff2da51b9e0255e5fab0b41dfe49a0d9012", "predicted_answer": "Yes", "predicted_evidence": ["n/a"]}
{"question_id": "180047e1ccfc7c98f093b8d1e1d0479a4cca99cc", "predicted_answer": "Two baseline models used in the paper are Transformer and HRED.", "predicted_evidence": ["n/a"]}
{"question_id": "fb3687ea05d38b5e65fdbbbd1572eacd82f56c0b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "b5d6357d3a9e3d5fdf9b344ae96cddd11a407875", "predicted_answer": "The baseline model for the agreement-based mode is a majority class baseline.", "predicted_evidence": ["n/a"]}
{"question_id": "f33a21c6a9c75f0479ffdbb006c40e0739134716", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "8a1d4ed00d31c1f1cb05bc9d5e4f05fe87b0e5a4", "predicted_answer": "The annotation was done by trained linguists.", "predicted_evidence": ["n/a"]}
{"question_id": "17f5f4a5d943c91d46552fb75940b67a72144697", "predicted_answer": "32.69%.", "predicted_evidence": ["n/a"]}
{"question_id": "83f22814aaed9b5f882168e22a3eac8f5fda3882", "predicted_answer": "They used Kendall's Tau to measure the correlation.", "predicted_evidence": ["n/a"]}
{"question_id": "ed11b4ff7ca72dd80a792a6028e16ba20fccff66", "predicted_answer": "They obtain region descriptions and object annotations through crowd-sourcing.", "predicted_evidence": ["n/a"]}
{"question_id": "a48c6d968707bd79469527493a72bfb4ef217007", "predicted_answer": "The paper suggests that combining multiple training datasets instead of using only one allows for the best generalization to benchmark sets.", "predicted_evidence": ["n/a"]}
{"question_id": "b69897deb5fb80bf2adb44f9cbf6280d747271b3", "predicted_answer": "BERT model.", "predicted_evidence": ["n/a"]}
{"question_id": "ad1f230f10235413d1fe501e414358245b415476", "predicted_answer": "Models compared: BiLSTM, Gated Attention (GA), ESIM, and BERT.", "predicted_evidence": ["n/a"]}
{"question_id": "0a521541b9e2b5c6d64fb08eb318778eba8ac9f7", "predicted_answer": "SNLI, MultiNLI, SciTail, and SICK.", "predicted_evidence": ["n/a"]}
{"question_id": "11e376f98df42f487298ec747c32d485c845b5cd", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "284ea817fd79bc10b7a82c88d353e8f8a9d7e93c", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "c0122190119027dc3eb51f0d4b4483d2dbedc696", "predicted_answer": "VAIS Hate Speech Detection System uses three classifiers: a Convolutional Neural Network (CNN), a Long Short-Term Memory (LSTM) network, and a Support Vector Machine (SVM).", "predicted_evidence": ["n/a"]}
{"question_id": "1ed6acb88954f31b78d2821bb230b722374792ed", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "5a33ec23b4341584a8079db459d89a4e23420494", "predicted_answer": "Public dashboard: Web-based interface that displays the results of the hate speech detection system.", "predicted_evidence": ["n/a"]}
{"question_id": "1b9119813ea637974d21862a8ace83bc1acbab8e", "predicted_answer": "Wiki corpus, Hatespeechdata.com, and HatEval dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "8abb96b2450ebccfcc5c98772cec3d86cd0f53e0", "predicted_answer": "Yes", "predicted_evidence": ["n/a"]}
{"question_id": "f52ec4d68de91dba66668f0affc198706949ff90", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "225a567eeb2698a9d3f1024a8b270313a6d15f82", "predicted_answer": "Baseline methods were universal sentence encoder and InferSent.", "predicted_evidence": ["n/a"]}
{"question_id": "35b10e0dc2cb4a1a31d5692032dc3fbda933bf7d", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "f5eac66c08ebec507c582a2445e99317a83e9ebe", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "62613aca3d7c7d534c9f6d8cb91ff55626bb8695", "predicted_answer": "SNLI, MultiNLI, and SICK.", "predicted_evidence": ["n/a"]}
{"question_id": "6e4505609a280acc45b0a821755afb1b3b518ffd", "predicted_answer": "The evaluation metric used is BLEU score.", "predicted_evidence": ["n/a"]}
{"question_id": "9bd938859a8b063903314a79f09409af8801c973", "predicted_answer": "The paper mentions that the models are trained on the commonly used benchmark datasets for sequence-to-sequence learning, including WMT14 English-German, WMT16 Romanian-English, and WMT17 Chinese-English.", "predicted_evidence": ["n/a"]}
{"question_id": "68ba5bf18f351e8c83fae7b444cc50bef7437f13", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "f6a1125c5621a2f32c9bcdd188dff14efa096083", "predicted_answer": "9.6 BLEU improvement over base transformer model.", "predicted_evidence": ["n/a"]}
{"question_id": "282aa4e160abfa7569de7d99b8d45cabee486ba4", "predicted_answer": "Unanswerable. The paper does not provide information on how they determine the opinion summary.", "predicted_evidence": ["n/a"]}
{"question_id": "ecfb2e75eb9a8eba8f640a039484874fa0d2fceb", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "a6950c22c7919f86b16384facc97f2cf66e5941d", "predicted_answer": "Laptops 2014, Restaurants 2014, Twitter dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "54be3541cfff6574dba067f1e581444537a417db", "predicted_answer": "3.8%", "predicted_evidence": ["n/a"]}
{"question_id": "221e9189a9d2431902d8ea833f486a38a76cbd8e", "predicted_answer": "The average number of turns per dialog is 12.58.", "predicted_evidence": ["n/a"]}
{"question_id": "a276d5931b989e0a33f2a0bc581456cca25658d9", "predicted_answer": "The paper offers three baseline models.", "predicted_evidence": ["n/a"]}
{"question_id": "c21d26130b521c9596a1edd7b9ef3fe80a499f1e", "predicted_answer": "weather, scheduling, social media, entertainment, navigation, and travel", "predicted_evidence": ["n/a"]}
{"question_id": "ec8043290356fcb871c2f5d752a9fe93a94c2f71", "predicted_answer": "The authors suggest that word embeddings could be used in other natural processing tasks such as sentiment analysis, language modeling, and machine translation.", "predicted_evidence": ["n/a"]}
{"question_id": "728c2fb445173fe117154a2a5482079caa42fe24", "predicted_answer": "Traditional co-occurrence networks fail in establishing links between similar words whenever they appear distant in the text because of the sparsity of the matrix.", "predicted_evidence": ["n/a"]}
{"question_id": "23d32666dfc29ed124f3aa4109e2527efa225fbc", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "076928bebde4dffcb404be216846d9d680310622", "predicted_answer": "The paper does not provide evidence or information related to the model architectures of previous co-occurrence networks. Answer: Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "f33236ebd6f5a9ccb9b9dbf05ac17c3724f93f91", "predicted_answer": "Yes, the model explanation output was evaluated using human judgments. The evaluation metric used was accuracy.", "predicted_evidence": ["n/a"]}
{"question_id": "66bf0d61ffc321f15e7347aaed191223f4ce4b4a", "predicted_answer": "Four annotators.", "predicted_evidence": ["n/a"]}
{"question_id": "5dfa59c116e0ceb428efd99bab19731aa3df4bbd", "predicted_answer": "All natural language explanations in the e-SNLI-VE-2.0 dataset are human-written. Answer: All.", "predicted_evidence": ["n/a"]}
{"question_id": "0c557b408183630d1c6c325b5fb9ff1573661290", "predicted_answer": "9.91% performance difference.", "predicted_evidence": ["n/a"]}
{"question_id": "a08b5018943d4428f067c08077bfff1af3de9703", "predicted_answer": "Premise-only class.", "predicted_evidence": ["n/a"]}
{"question_id": "9447ec36e397853c04dcb8f67492ca9f944dbd4b", "predicted_answer": "Italian Wikipedia dump.", "predicted_evidence": ["n/a"]}
{"question_id": "12c6ca435f4fcd4ad5ea5c0d76d6ebb9d0be9177", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "32c149574edf07b1a96d7f6bc49b95081de1abd2", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "3de27c81af3030eb2d9de1df5ec9bfacdef281a9", "predicted_answer": "3 billion tokens.", "predicted_evidence": ["n/a"]}
{"question_id": "cc680cb8f45aeece10823a3f8778cf215ccc8af0", "predicted_answer": "The paper provides evidence that different parameter settings impact the performance and semantic capacity of the resulting model.", "predicted_evidence": ["n/a"]}
{"question_id": "fab4ec639a0ea1e07c547cdef1837c774ee1adb8", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "9190c56006ba84bf41246a32a3981d38adaf422c", "predicted_answer": "Wikipedia Italian dump.", "predicted_evidence": ["n/a"]}
{"question_id": "7aab78e90ba1336950a2b0534cc0cb214b96b4fd", "predicted_answer": "The auxiliary signals from the morphology table are incorporated in the decoder through an additional input channel.", "predicted_evidence": ["n/a"]}
{"question_id": "b7fe91e71da8f4dc11e799b3bd408d253230e8c6", "predicted_answer": "The \"morphology table\" contains target-side part-of-speech and morphological tags.", "predicted_evidence": ["n/a"]}
{"question_id": "16fa6896cf4597154363a6c9a98deb49fffef15f", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "0f60864503ecfd5b048258e21d548ab5e5e81772", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "fe578842021ccfc295209a28cf2275ca18f8d155", "predicted_answer": "Logistic Regression, Support Vector Machine (SVM), Random Forest (RF), and Convolutional Neural Networks (CNN).", "predicted_evidence": ["n/a"]}
{"question_id": "00ef9cc1d1d60f875969094bb246be529373cb1d", "predicted_answer": "Methodology used to compensate for limited labeled data: transfer learning.", "predicted_evidence": ["n/a"]}
{"question_id": "279b633b90fa2fd69e84726090fadb42ebdf4c02", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "0106bd9d54e2f343cc5f30bb09a5dbdd171e964b", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e015d033d4ee1c83fe6f192d3310fb820354a553", "predicted_answer": "The paper used the following datasets for named entity recognition from social media:\n- CoNLL-2003\n- WNUT-2017 \n- WNUT-2016\n- Ehealth-KD (2018)\n- MedMentions (2019)", "predicted_evidence": ["n/a"]}
{"question_id": "8a871b136ccef78391922377f89491c923a77730", "predicted_answer": "Baseline state of the art models are not mentioned in the paper.", "predicted_evidence": ["n/a"]}
{"question_id": "acd05f31e25856b9986daa1651843b8dc92c2d99", "predicted_answer": "583 stories.", "predicted_evidence": ["n/a"]}
{"question_id": "8c78b21ec966a5e8405e8b9d3d6e7099e95ea5fb", "predicted_answer": "Joint Key Element Extraction and Categorization.", "predicted_evidence": ["n/a"]}
{"question_id": "af60462881b2d723adeb4acb5fbc07ea27b6bde2", "predicted_answer": "Key patterns of sexual harassment were discovered from personal stories through joint key element extraction and categorization.", "predicted_evidence": ["n/a"]}
{"question_id": "879bec20c0fdfda952444018e9435f91e34d8788", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "3c378074111a6cc7319c0db0aced5752c30bfffb", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "b464bc48f176a5945e54051e3ffaea9a6ad886d7", "predicted_answer": "Tasks involving natural language understanding.", "predicted_evidence": ["n/a"]}
{"question_id": "3b40799f25dbd98bba5b526e0a1d0d0bb51173e0", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "3c16d4cf5dc23223980d9c0f924cb9e4e6943f13", "predicted_answer": "Answer: They select answer candidates using a mask applied to the top-k predicted tokens in the passage.", "predicted_evidence": ["n/a"]}
{"question_id": "4c822bbb06141433d04bbc472f08c48bc8378865", "predicted_answer": "The paper does not provide the necessary information related to how they extract causality from text. The answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "1baf87437b70cc0375b8b7dc2cfc2830279bc8b5", "predicted_answer": "Wikipedia.", "predicted_evidence": ["n/a"]}
{"question_id": "0b31eb5bb111770a3aaf8a3931d8613e578e07a8", "predicted_answer": "The paper states that the selection criteria for \"causal statements\" are events or conditions that are believed to cause or influence the occurrence of another event or condition.", "predicted_evidence": ["n/a"]}
{"question_id": "7348e781b2c3755b33df33f4f0cab4b94fcbeb9b", "predicted_answer": "They use crowdsourcing to analyze the corpora. \n\nAnswer: Crowdsourcing.", "predicted_evidence": ["n/a"]}
{"question_id": "f68bd65b5251f86e1ed89f0c858a8bb2a02b233a", "predicted_answer": "The paper doesn't provide enough evidence to answer this question. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e111925a82bad50f8e83da274988b9bea8b90005", "predicted_answer": "They collected the control corpus from news articles published on five major news portals.", "predicted_evidence": ["n/a"]}
{"question_id": "ba48c095c496d01c7717eaa271470c3406bf2d7c", "predicted_answer": "English and Chinese.", "predicted_evidence": ["n/a"]}
{"question_id": "42a61773aa494f7b12838f71a949034c12084de1", "predicted_answer": "Baseline models are logistic regression and decision tree.", "predicted_evidence": ["n/a"]}
{"question_id": "48c3e61b2ed7b3f97706e2a522172bf9b51ec467", "predicted_answer": "0.78 (Fleiss' kappa)", "predicted_evidence": ["n/a"]}
{"question_id": "61fba3ab10f7b6906e27b028fb1d42ec601c3fb8", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "80de3baf97a55ea33e0fe0cafa6f6221ba347d0a", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "f5707610dc8ae2a3dc23aec63d4afa4b40b7ec1e", "predicted_answer": "Features and hyperparameters.", "predicted_evidence": ["n/a"]}
{"question_id": "e76139c63da0f861c097466983fbe0c94d1d9810", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "b8b588ca1e876b3094ae561a875dd949c8965b2e", "predicted_answer": "The paper doesn't provide evidence related to evaluation scheme problems. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "2ec640e6b4f1ebc158d13ee6589778b4c08a04c8", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "ab0bb4d0a9796416d3d7ceba0ba9ab50c964e9d6", "predicted_answer": "They mention three collection steps.", "predicted_evidence": ["n/a"]}
{"question_id": "0460019eb2186aef835f7852fc445b037bd43bb7", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "96c09ece36a992762860cde4c110f1653c110d96", "predicted_answer": "The highest performing system achieved a success rate of 0.901.", "predicted_evidence": ["n/a"]}
{"question_id": "a9cc4b17063711c8606b8fc1c5eaf057b317a0c9", "predicted_answer": "The metrics used in the evaluation are BLEU, PER, WER, OOV, and semantic accuracy.", "predicted_evidence": ["n/a"]}
{"question_id": "6ead576ee5813164684a8cdda36e6a8c180455d9", "predicted_answer": "They measure the quality of summaries using ROUGE scores, specifically ROUGE-L.", "predicted_evidence": ["n/a"]}
{"question_id": "0117aa1266a37b0d2ef429f1b0653b9dde3677fe", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "5455b3cdcf426f4d5fc40bc11644a432fa7a5c8f", "predicted_answer": "The authors refer to answer styles as the different ways in which an answer can be phrased or expressed.", "predicted_evidence": ["n/a"]}
{"question_id": "6c80bc3ed6df228c8ca6e02c0a8a1c2889498688", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "2d274c93901c193cf7ad227ab28b1436c5f410af", "predicted_answer": "Baselines: BiDAF, ReasoNet, and QANet.", "predicted_evidence": ["n/a"]}
{"question_id": "e63bde5c7b154fbe990c3185e2626d13a1bad171", "predicted_answer": "51.0 F1 score.", "predicted_evidence": ["n/a"]}
{"question_id": "cb8a6f5c29715619a137e21b54b29e9dd48dad7d", "predicted_answer": "Answer: An \"answer style\" refers to the way in which an answer is presented or phrased within the context of a reading comprehension task.", "predicted_evidence": ["n/a"]}
{"question_id": "8a7bd9579d2783bfa81e055a7a6ebc3935da9d20", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "27b01883ed947b457d3bab0c66de26c0736e4f90", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "9714cb7203c18a0c53805f6c889f2e20b4cab5dd", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "a22b900fcd76c3d36b5679691982dc6e9a3d34bf", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "fb2593de1f5cc632724e39d92e4dd82477f06ea1", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "476d0b5579deb9199423bb843e584e606d606bc7", "predicted_answer": "Baseline: linear SVM; Classification systems: logistic regression, SVM, random forest, and gradient boosting.", "predicted_evidence": ["n/a"]}
{"question_id": "eddabb24bc6de6451bcdaa7940f708e925010912", "predicted_answer": "The paper does not mention anything about annotating EAU text spans, so the answer is \"Unanswerable\".", "predicted_evidence": ["n/a"]}
{"question_id": "f0946fb9df9839977f4d16c43476e4c2724ff772", "predicted_answer": "The elementary argumentative units are defined as elementary discourse units (EDUs).", "predicted_evidence": ["n/a"]}
{"question_id": "e51d0c2c336f255e342b5f6c3cf2a13231789fed", "predicted_answer": "Russian Twitter.", "predicted_evidence": ["n/a"]}
{"question_id": "5b6aec1b88c9832075cd343f59158078a91f3597", "predicted_answer": "The proposed word embeddings outperform Sindhi fastText word representations.", "predicted_evidence": ["n/a"]}
{"question_id": "a6717e334c53ebbb87e5ef878a77ef46866e3aed", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "a1064307a19cd7add32163a70b6623278a557946", "predicted_answer": "Unanswerable. The paper does not provide information on the total number of unique words in the dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "8cb9006bcbd2f390aadc6b70d54ee98c674e45cc", "predicted_answer": "The paper states that the data was collected from four different web resources: Wikipedia, BBC News, Qur'an, and SindhiBooks.org. Answer: Wikipedia, BBC News, Qur'an, and SindhiBooks.org.", "predicted_evidence": ["n/a"]}
{"question_id": "75043c17a2cddfce6578c3c0e18d4b7cf2f18933", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "95bb3ea4ebc3f2174846e8d422abc076e1407d6a", "predicted_answer": "1950s to 2010s.", "predicted_evidence": ["n/a"]}
{"question_id": "3ebdc15480250f130cf8f5ab82b0595e4d870e2f", "predicted_answer": "24 genres.", "predicted_evidence": ["n/a"]}
{"question_id": "bbc58b193c08ccb2a1e8235a36273785a3b375fb", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "3c34187a248d179856b766e9534075da1aa5d1cf", "predicted_answer": "The paper does not provide information on the performance of the CRF model on the task described. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "8bfbf78ea7fae0c0b8a510c9a8a49225bbdb5383", "predicted_answer": "Yes", "predicted_evidence": ["n/a"]}
{"question_id": "97757a69d9fc28b260e68284fd300726fbe358d0", "predicted_answer": "Handcrafted features are not used in this paper. Answer: Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "41830ebb8369a24d490e504b7cdeeeaa9b09fd9c", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "4904ef32a8f84cf2f53b1532ccf7aa77273b3d19", "predicted_answer": "1. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "45b28a6ce2b0f1a8b703a3529fd1501f465f3fdf", "predicted_answer": "Convolutional VAE, residual and dense architectures.", "predicted_evidence": ["n/a"]}
{"question_id": "d6a27c41c81f12028529e97e255789ec2ba39eaa", "predicted_answer": "The paper reports that the standard metrics for style accuracy can vary up to 2-5% on different re-runs. Answer: 2-5%.", "predicted_evidence": ["n/a"]}
{"question_id": "2d3bf170c1647c5a95abae50ee3ef3b404230ce4", "predicted_answer": "Baseline methods used: self-attention.", "predicted_evidence": ["n/a"]}
{"question_id": "6e8c587b6562fafb43a7823637b84cd01487059a", "predicted_answer": "Unanswerable. The paper does not mention any results related to BLEU score.", "predicted_evidence": ["n/a"]}
{"question_id": "ab9453fa2b927c97b60b06aeda944ac5c1bfef1e", "predicted_answer": "WikiQA and TREC-QA are the datasets used in experiments.", "predicted_evidence": ["n/a"]}
{"question_id": "3a8d65eb8e1dbb995981a0e02d86ebf3feab107a", "predicted_answer": "L1 and L2 regularizers.", "predicted_evidence": ["n/a"]}
{"question_id": "d0c79f4a5d5c45fe673d9fcb3cd0b7dd65df7636", "predicted_answer": ".786 F1 on MUSE and .703 on VecMap for bilingual lexicon induction", "predicted_evidence": ["n/a"]}
{"question_id": "54c7fc08598b8b91a8c0399f6ab018c45e259f79", "predicted_answer": "The paper reports that the proposed model achieves state-of-the-art performance compared to competitive baselines.", "predicted_evidence": ["n/a"]}
{"question_id": "5112bbf13c7cf644bf401daecb5e3265889a4bfc", "predicted_answer": "2 bilingual dictionaries with 5,000 and 10,000 entries, respectively.", "predicted_evidence": ["n/a"]}
{"question_id": "03ce42ff53aa3f1775bc57e50012f6eb1998c480", "predicted_answer": "English-French, English-German, English-Italian, English-Spanish, English-Polish, English-Czech.", "predicted_evidence": ["n/a"]}
{"question_id": "ebeedbb8eecdf118d543fdb5224ae610eef212c8", "predicted_answer": "The paper mentions that current state-of-the-art methods consider the two tasks independently.", "predicted_evidence": ["n/a"]}
{"question_id": "9efd025cfa69c6ff2777528bd158f79ead9353d1", "predicted_answer": "22M", "predicted_evidence": ["n/a"]}
{"question_id": "559c1307610a15427caeb8aff4d2c01ae5c9de20", "predicted_answer": "Baseline.", "predicted_evidence": ["n/a"]}
{"question_id": "4ecb6674bcb4162bf71aea8d8b82759255875df3", "predicted_answer": "BERT.", "predicted_evidence": ["n/a"]}
{"question_id": "eacc1eb65daad055df934e0e878f417b73b2ecc1", "predicted_answer": "The FEVER task is a fact-verification task.", "predicted_evidence": ["n/a"]}
{"question_id": "d353a6bbdc66be9298494d0c853e0d8d752dec4b", "predicted_answer": "The paper does not provide information on how correctness of automatic derivation is proved. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e2cfaa2ec89b944bbc46e5edf7753b3018dbdc8f", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "22c36082b00f677e054f0f0395ed685808965a02", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "85a7dbf6c2e21bfb7a3a938381890ac0ec2a19e0", "predicted_answer": "The paper uses the WMT14 English-German dataset for experiments.", "predicted_evidence": ["n/a"]}
{"question_id": "90bc60320584ebba11af980ed92a309f0c1b5507", "predicted_answer": "They append the length of each segment to the positional embedding.", "predicted_evidence": ["n/a"]}
{"question_id": "f52b2ca49d98a37a6949288ec5f281a3217e5ae8", "predicted_answer": "They condition the output to a given target-source class using a target-source control token.", "predicted_evidence": ["n/a"]}
{"question_id": "228425783a4830e576fb98696f76f4c7c0a1b906", "predicted_answer": "English-German, English-French, and English-Romanian.", "predicted_evidence": ["n/a"]}
{"question_id": "9d1135303212356f3420ed010dcbe58203cc7db4", "predicted_answer": "WMT14, WMT16, and IWSLT14.", "predicted_evidence": ["n/a"]}
{"question_id": "d8bf4a29c7af213a9a176eb1503ec97d01cc8f51", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "73abb173a3cc973ab229511cf53b426865a2738b", "predicted_answer": "The paper compares the proposed spectral decomposition method against several state-of-the-art models.", "predicted_evidence": ["n/a"]}
{"question_id": "1d9b953a324fe0cfbe8e59dcff7a44a2f93c568d", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "093039f974805952636c19c12af3549aa422ec43", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "8df89988adff57279db10992846728ec4f500eaa", "predicted_answer": "The paper uses sequence tagging and dependency parsing baselines in experiments.", "predicted_evidence": ["n/a"]}
{"question_id": "94edac71eea1e78add678fb5ed2d08526b51016b", "predicted_answer": "General-purpose optimizations included in Torch-Struct are: dynamic batching, memoization, efficient structure indexing, and GPU support.", "predicted_evidence": ["n/a"]}
{"question_id": "9c4ed8ca59ba6d240f031393b01f634a9dc3615d", "predicted_answer": "Baseline", "predicted_evidence": ["n/a"]}
{"question_id": "ca7e71131219252d1fab69865804b8f89a2c0a8f", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d77c9ede2727c28e0b5a240b2521fd49a19442e0", "predicted_answer": "Bag of Words (BoW) and Dependency Paths.", "predicted_evidence": ["n/a"]}
{"question_id": "a9610cbcca813f4376fbfbf21cc14689c7fbd677", "predicted_answer": "The paper reports that the VIST dataset has over 200k images and 400k captions.", "predicted_evidence": ["n/a"]}
{"question_id": "64ab2b92e986e0b5058bf4f1758e849f6a41168b", "predicted_answer": "Adversarial training method outperforms the FHVAE-based disentangled speech representation learning in unsupervised feature learning.", "predicted_evidence": ["n/a"]}
{"question_id": "bcd6befa65cab3ffa6334c8ecedd065a4161028b", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "479fc9e6d6d80e69f425d9e82e618e6b7cd12764", "predicted_answer": "Puns based on words and phrases.", "predicted_evidence": ["n/a"]}
{"question_id": "bc26eee4ef1c8eff2ab8114a319901695d044edb", "predicted_answer": "Expert knowledge is encoded in scripts and used to guide the dialogue.", "predicted_evidence": ["n/a"]}
{"question_id": "9c94ff8c99d3e51c256f2db78c34b2361f26b9c2", "predicted_answer": "Semiguided dialogue is a type of dialogue where only some parts of the dialogue are guided.", "predicted_evidence": ["n/a"]}
{"question_id": "8e9de181fa7d96df9686d0eb2a5c43841e6400fa", "predicted_answer": "No. The paper describes the CRWIZ framework but does not provide any results related to its usage for data collection.", "predicted_evidence": ["n/a"]}
{"question_id": "ff1595a388769c6429423a75b6e1734ef88d3e46", "predicted_answer": "The paper does not provide enough evidence to answer this question.", "predicted_evidence": ["n/a"]}
{"question_id": "dd2046f5481f11b7639a230e8ca92904da75feed", "predicted_answer": "They combine the models using an ensemble method.", "predicted_evidence": ["n/a"]}
{"question_id": "47e6c3e6fcc9be8ca2437f41a4fef58ef4c02579", "predicted_answer": "The paper does not provide information about their baseline.", "predicted_evidence": ["n/a"]}
{"question_id": "569ad21441e99ae782d325d5f5e1ac19e08d5e76", "predicted_answer": "Context-aware models.", "predicted_evidence": ["n/a"]}
{"question_id": "90741b227b25c42e0b81a08c279b94598a25119d", "predicted_answer": "Any type of language or discourse that is targeted towards an individual or a group, on the basis of their social or ethnical identity, which is perceived as derogatory, deprecating, offensive or threatening.", "predicted_evidence": ["n/a"]}
{"question_id": "1d739bb8e5d887fdfd1f4b6e39c57695c042fa25", "predicted_answer": "The paper does not mention the architecture of the neural network. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "5c70fdd3d6b67031768d3e28336942e49bf9a500", "predicted_answer": "Human interaction is consumed through a web interface.", "predicted_evidence": ["n/a"]}
{"question_id": "f27502c3ece9ade265389d5ace90ca9ca42b46f3", "predicted_answer": "They perform human evaluation by asking judges to rate generated stories in terms of coherence, consistency, and overall quality.", "predicted_evidence": ["n/a"]}
{"question_id": "ffb7a12dfe069ab7263bb7dd366817a9d22b8ef2", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "aa4b38f601cc87bf93849245d5f65124da3dc112", "predicted_answer": "The paper mentions two baselines: unconditioned and conditioned on the opening sentence.", "predicted_evidence": ["n/a"]}
{"question_id": "08b87a90139968095433f27fc88f571d939cd433", "predicted_answer": "A CRF-based sequence labelling model is used as the baseline.", "predicted_evidence": ["n/a"]}
{"question_id": "ef872807cb0c9974d18bbb886a7836e793727c3d", "predicted_answer": "Lexical, morphological, and syntactic features.", "predicted_evidence": ["n/a"]}
{"question_id": "4db3c2ca6ddc87209c31b20763b7a3c1c33387bc", "predicted_answer": "The cybersecurity articles used in the model are sourced from \"various cybersecurity news websites and blogs\".", "predicted_evidence": ["n/a"]}
{"question_id": "63337fd803f6fdd060ebd0f53f9de79d451810cd", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "63496705fff20c55d4b3d8cdf4786f93e742dd3d", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "7b44bee49b7cb39cb7d5eec79af5773178c27d4d", "predicted_answer": "The paper does not provide information on how the data in RAFAEL is labelled. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "6d54bad91b6ccd1108d1ddbff1d217c6806e0842", "predicted_answer": "They use a clustering approach to group polysemous words in their entity library.", "predicted_evidence": ["n/a"]}
{"question_id": "238ec3c1e1093ce2f5122ee60209b969f7669fae", "predicted_answer": "They measure the fluctuation using cosine similarity.", "predicted_evidence": ["n/a"]}
{"question_id": "f704d182c9e01a2002381b76bf21e4bb3c0d3efc", "predicted_answer": "SVM-based domain adaptation technique yields the best performance.", "predicted_evidence": ["n/a"]}
{"question_id": "da544015511e535503dee2eaf4912a5e36c806cd", "predicted_answer": "The paper does not provide information about the architecture of the model. Answer: Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "7bc993b32484d6ae3c86d0b351a68e59fd2757a5", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "da495e2f99ee2d5db9cc17eca5517ddaa5ea8e42", "predicted_answer": "Character and subword units.", "predicted_evidence": ["n/a"]}
{"question_id": "e44a5514d7464993997212341606c2c0f3a72eb4", "predicted_answer": "Character.", "predicted_evidence": ["n/a"]}
{"question_id": "310e61b9dd4d75bc1bebbcb1dae578f55807cd04", "predicted_answer": "IWSLT2014 Chinese-English parallel corpus.", "predicted_evidence": ["n/a"]}
{"question_id": "bdc6664cec2b94b0b3769bc70a60914795f39574", "predicted_answer": "They measure performance using precision, recall, and F1-score on the task of answering visual and natural language questions over linked data.", "predicted_evidence": ["n/a"]}
{"question_id": "e40df8c685a28b98006c47808f506def68f30e26", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "9653c89a93ac5c717a0a26cf80e9aa98a5ccf910", "predicted_answer": "They use four QA systems: QALD-7 natural language, QALD-7 visual, QALD-9 natural language, and QALD-9 visual.", "predicted_evidence": ["n/a"]}
{"question_id": "b921a1771ed0ba9dbeff9da000336ecf2bb38322", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "412aff0b2113b7d61c914edf90b90f2994390088", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "010e3793eb1342225857d3f95e147d8f8467192a", "predicted_answer": "The size of the Dutch Anaphora Resolution dataset is 47,399 tokens and the size of the die/dat prediction dataset is 6,784 tokens.", "predicted_evidence": ["n/a"]}
{"question_id": "c20bb0847ced490a793657fbaf6afb5ef54dad81", "predicted_answer": "The scores for predicting perceived musical hardness and darkness are extracted only for a subsample of 503 songs because these songs were labeled for those dimensions in a previous study.", "predicted_evidence": ["n/a"]}
{"question_id": "ff8557d93704120b65d9b597a4fab40b49d24b6d", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "447eb98e602616c01187960c9c3011c62afd7c27", "predicted_answer": "The paper provides a list of lyrical topics present in the metal genre: Death/Grind, Black, Folk/Pagan, Gothic, Doom, Heavy, Power, Thrash, Symphonic, Technical/Progressive.", "predicted_evidence": ["n/a"]}
{"question_id": "f398587b9a0008628278a5ea858e01d3f5559f65", "predicted_answer": "SPNet outperforms state-of-the-art abstractive summarization methods by a significant margin, achieving relative improvements of up to 17.04% on ROUGE-L F1 and 21.33% on METEOR.", "predicted_evidence": ["n/a"]}
{"question_id": "d5f8707ddc21741d52b3c2a9ab1af2871dc6c90b", "predicted_answer": "ROUGE and human evaluations.", "predicted_evidence": ["n/a"]}
{"question_id": "58f3bfbd01ba9768172be45a819faaa0de2ddfa4", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "73633afbefa191b36cca594977204c6511f9dad4", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "db39a71080e323ba2ddf958f93778e2b875dcd24", "predicted_answer": "SPNet utilizes additional speaker role, semantic slot, and dialog domain annotations as semantic scaffolds to guide the dialog summarization process.", "predicted_evidence": ["n/a"]}
{"question_id": "6da2cb3187d3f28b75ac0a61f6562a8adf716109", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "c47e87efab11f661993a14cf2d7506be641375e4", "predicted_answer": "The new evaluation metric considers critical informative entities by identifying the salient entities and checking if they are present in both the reference summary and the generated summary. Answer: Salient entities are identified and checked for presence in reference and generated summaries.", "predicted_evidence": ["n/a"]}
{"question_id": "14684ad200915ff1e3fc2a89cb614e472a1a2854", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "8d1f9d3aa2cc2e2e58d3da0f5edfc3047978f3ee", "predicted_answer": "A pairwise comparison evaluation measure and a Likert scale-based human evaluation measure were used for evaluation.", "predicted_evidence": ["n/a"]}
{"question_id": "5065ff56d3c295b8165cb20d8bcfcf3babe9b1b8", "predicted_answer": "BLEU, ROUGE, METEOR, CIDEr.", "predicted_evidence": ["n/a"]}
{"question_id": "c34a15f1d113083da431e4157aceb11266e9a1b2", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "061682beb3dbd7c76cfa26f7ae650e548503d977", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "3518d8eb84f6228407cfabaf509fd63d60351203", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "617c77a600be5529b3391ab0c21504cd288cc7c7", "predicted_answer": "The concept sets come from ConceptNet.", "predicted_evidence": ["n/a"]}
{"question_id": "53d6cbee3606dd106494e2e98aa93fdd95920375", "predicted_answer": "7.85% improvement.", "predicted_evidence": ["n/a"]}
{"question_id": "9dc844f82f520daf986e83466de0c84d93953754", "predicted_answer": "SQuAD and NewsQA.", "predicted_evidence": ["n/a"]}
{"question_id": "9fe4a2a5b9e5cf29310ab428922cc8e7b2fc1d11", "predicted_answer": "BERT, BiDAF, ELMo, GPT, and RoBERTa.", "predicted_evidence": ["n/a"]}
{"question_id": "36d892460eb863220cd0881d5823d73bbfda172c", "predicted_answer": "SQuAD, RACE, MCTest, and SemEval are the four representative datasets used for benchmark in this paper.", "predicted_evidence": ["n/a"]}
{"question_id": "4cbc56d0d53c4c03e459ac43e3c374b75fd48efe", "predicted_answer": "Baselines.", "predicted_evidence": ["n/a"]}
{"question_id": "e5a965e7a109ae17a42dd22eddbf167be47fca75", "predicted_answer": "Ambiguity in PICO sentence prediction tasks can arise from multiple sources, such as (i) inconsistent use of terminology, (ii) implicit and unstated assumptions, (iii) conflicting guidelines and (iv) incomplete information.", "predicted_evidence": ["n/a"]}
{"question_id": "082c88e132b4f1bf68abdc3a21ac4af180de1113", "predicted_answer": "The paper does not provide information on how knowledge is retrieved in the memory.", "predicted_evidence": ["n/a"]}
{"question_id": "74091e10f596428135b0ab06008608e09c051565", "predicted_answer": "Unanswerable. The paper does not provide information about how knowledge is stored in memory.", "predicted_evidence": ["n/a"]}
{"question_id": "43b4f7eade7a9bcfaf9cc0edba921a41d6036e9c", "predicted_answer": "33.5% improvement.", "predicted_evidence": ["n/a"]}
{"question_id": "a75861e6dd72d69fdf77ebd81c78d26c6f7d0864", "predicted_answer": "The neural network architecture used in the paper is RelNet.", "predicted_evidence": ["n/a"]}
{"question_id": "60fd7ef7986a5752b31d3bd12bbc7da6843547a4", "predicted_answer": "OpenIE, PCNN-IP, and CNN-BiLSTM.", "predicted_evidence": ["n/a"]}
{"question_id": "7d59374d9301a0c09ea5d023a22ceb6ce07fb490", "predicted_answer": "They measure the diversity of inferences using perplexity.", "predicted_evidence": ["n/a"]}
{"question_id": "8e2b125426d1220691cceaeaf1875f76a6049cbd", "predicted_answer": "10% improvement.", "predicted_evidence": ["n/a"]}
{"question_id": "42bc4e0cd0f3e238a4891142f1b84ebcd6594bf1", "predicted_answer": "The baselines used on the Atomic dataset are LSTM and Transformer models.", "predicted_evidence": ["n/a"]}
{"question_id": "fb76e994e2e3fa129f1e94f1b043b274af8fb84c", "predicted_answer": "The context-aware variational autoencoder learns event background information by utilizing both the contextual and the event representations.", "predicted_evidence": ["n/a"]}
{"question_id": "99ef97336c0112d9f60df108f58c8b04b519a854", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "95d8368b1055d97250df38d1e8c4a2b283d2b57e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "a978a1ee73547ff3a80c66e6db3e6c3d3b6512f4", "predicted_answer": "3.2 BLEU.", "predicted_evidence": ["n/a"]}
{"question_id": "46ee1cbbfbf0067747b28bdf4c8c2f7dc8955650", "predicted_answer": "Neural machine translation (NMT) models.", "predicted_evidence": ["n/a"]}
{"question_id": "4f12b41bd3bb2610abf7d7835291496aa69fb78c", "predicted_answer": "They used the domain tags as input features to the neural machine translation model.", "predicted_evidence": ["n/a"]}
{"question_id": "65e6a1cc2590b139729e7e44dce6d9af5dd2c3b5", "predicted_answer": "Mixed initiative multi-turn dialogs are the greatest challenge in building open-domain conversational agents because they require the agent to handle a wide range of user inputs and maintain context across multiple turns.", "predicted_evidence": ["n/a"]}
{"question_id": "b54fc86dc2cc6994e10c1819b6405de08c496c7b", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "b43a8a0f4b8496b23c89730f0070172cd5dca06a", "predicted_answer": "Unanswerable. The paper does not provide information about any model architecture.", "predicted_evidence": ["n/a"]}
{"question_id": "b161febf86cdd58bd247a934120410068b24b7d1", "predicted_answer": "The paper does not mention any list of nine types related to user reactions to deceptive and trusted social news sources. Answer: Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d40662236eed26f17dd2a3a9052a4cee1482d7d6", "predicted_answer": "They represent input features of their model using Mel Frequency Cepstral Coefficients (MFCCs).", "predicted_evidence": ["n/a"]}
{"question_id": "1d791713d1aa77358f11501f05c108045f53c8aa", "predicted_answer": "250.", "predicted_evidence": ["n/a"]}
{"question_id": "6b6360fab2edc836901195c0aba973eae4891975", "predicted_answer": "Google's speech command dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "b6b5f92a1d9fa623b25c70c1ac67d59d84d9eec8", "predicted_answer": "40%", "predicted_evidence": ["n/a"]}
{"question_id": "86a93a2d1c19cd0cd21ad1608f2a336240725700", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "6090d3187c41829613abe785f0f3665d9ecd90d9", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "117aa7811ed60e84d40cd8f9cb3ca78781935a98", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "c359ab8ebef6f60c5a38f5244e8c18d85e92761d", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "ad362365656b0b218ba324ae60701eb25fe664c1", "predicted_answer": "Latent variables.", "predicted_evidence": ["n/a"]}
{"question_id": "423bb905e404e88a168e7e807950e24ca166306c", "predicted_answer": "The paper states that the baselines include rule-based paraphrase generation and sequence-to-sequence models.", "predicted_evidence": ["n/a"]}
{"question_id": "e5ae8ac51946db7475bb20b96e0a22083b366a6d", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "18288c7b0f8bd7839ae92f9c293e7fb85c7e146a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "b5e883b15e63029eb07d6ff42df703a64613a18a", "predicted_answer": "Terms such as diabetes, diet, exercise, and obesity were used to identify topics of interest about DDEO on Twitter.", "predicted_evidence": ["n/a"]}
{"question_id": "c45a160d31ca8eddbfea79907ec8e59f543aab86", "predicted_answer": "The paper states that the evaluation is done on two datasets - Household Travel Survey (HTS) dataset and the National Household Travel Survey (NHTS) dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "7358a1ce2eae380af423d4feeaa67d2bd23ae9dd", "predicted_answer": "They train their embeddings using Skip-gram Negative Sampling (SGNS) algorithm.", "predicted_evidence": ["n/a"]}
{"question_id": "1165fb0b400ec1c521c1aef7a4e590f76fee1279", "predicted_answer": "They model travel behavior using embeddings.", "predicted_evidence": ["n/a"]}
{"question_id": "f2c5da398e601e53f9f545947f61de5f40ede1ee", "predicted_answer": "Unanswerable. The paper does not discuss or mention the interpretation of coefficients.", "predicted_evidence": ["n/a"]}
{"question_id": "2d4d0735c50749aa8087d1502ab7499faa2f0dd8", "predicted_answer": "They do not provide information on how much they outperform previous state-of-the-art models. Answer: Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "43761478c26ad65bec4f0fd511ec3181a100681c", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "01866fe392d9196dda1d0b472290edbd48a99f66", "predicted_answer": "The paper does not mention how the lexicon of trafficking flags is expanded. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "394cf73c0aac8ccb45ce1b133f4e765e8e175403", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "2c4003f25e8d95a3768204f52a7a5f5e17cb2102", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "65e32f73357bb26a29a58596e1ac314f7e9c6c91", "predicted_answer": "One example of a difficult-to-classify case in the paper is when two users are having a polite conversation, but one of them suddenly introduces a controversial topic or makes an offensive remark.", "predicted_evidence": ["n/a"]}
{"question_id": "46f175e1322d648ab2c0258a9609fe6f43d3b44e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "7cc22fd8c9d0e1ce5e86d0cbe90bf3a177f22a68", "predicted_answer": "150,000.", "predicted_evidence": ["n/a"]}
{"question_id": "3fa638e6167e1c7a931c8ee5c0e2e397ec1b6cda", "predicted_answer": "The paper doesn't provide specific information about which Reddit communities they look at. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d2b3f2178a177183b1aeb88784e48ff7e3e5070c", "predicted_answer": "0.85 (strong negative correlation)", "predicted_evidence": ["n/a"]}
{"question_id": "d5ff8fc4d3996db2c96cb8af5a6d215484991e62", "predicted_answer": "The novel method outperformed existing approaches on all benchmark datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "d9c6493e1c3d8d429d4ca608f5acf29e4e7c4c9b", "predicted_answer": "The authors justify that the question answering dataset presented is realistic by stating that it consists of questions and answers from three different question answering benchmarks, which cover a wide range of topics and require a diverse set of reasoning abilities. They also state that the dataset contains various types of compositional generalization questions, including relational reasoning, numerical reasoning, and logical reasoning. Answer: The authors justify that the question answering dataset presented is realistic.", "predicted_evidence": ["n/a"]}
{"question_id": "0427ca83d6bf4ec113bc6fec484b2578714ae8ec", "predicted_answer": "Transformer, LSTM, and ConvNet.", "predicted_evidence": ["n/a"]}
{"question_id": "f1c70baee0fd02b8ecb0af4b2daa5a56f3e9ccc3", "predicted_answer": "The paper does not provide information on the size of the new question answering dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "8db45a8217f6be30c31f9b9a3146bf267de68389", "predicted_answer": "Multiple Choice:\nA) There are no other approaches proposed\nB) Human evaluation based approaches\nC) Rule-based approaches\nD) Vocabulary-based approaches\n\nAnswer: B and C", "predicted_evidence": ["n/a"]}
{"question_id": "4e379d6d5f87554fabf6f7f7b6ed92d2025e7280", "predicted_answer": "Continuous speech keyword spotting with limited training data.", "predicted_evidence": ["n/a"]}
{"question_id": "518d0847b02b4f23a8f441faa38b935c9b892e1e", "predicted_answer": "Two baselines: transfer learning without a metric network and training from scratch.", "predicted_evidence": ["n/a"]}
{"question_id": "8112d18681e266426cf7432ac4928b87f5ce8311", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "b14f13f2a3a316e5a5de9e707e1e6ed55e235f6f", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "ba6422e22297c7eb0baa381225a2f146b9621791", "predicted_answer": "On the datasets considered in the paper (WMT14 English-German and WMT16 English-Romanian), the proposed method outperforms state-of-the-art non-autoregressive models in terms of BLEU score.", "predicted_evidence": ["n/a"]}
{"question_id": "65e72ad72a9cbfc379f126b10b0ce80cfe44579b", "predicted_answer": "The non autoregressive NMT models used for comparison are ConvS2S and Mask-Predict.", "predicted_evidence": ["n/a"]}
{"question_id": "cf8edc6e8c4d578e2bd9965579f0ee81f4bf35a9", "predicted_answer": "I am unable to answer your question since the paper does not provide evidence or information related to the benchmark datasets used for evaluation.", "predicted_evidence": ["n/a"]}
{"question_id": "04aff4add28e6343634d342db92b3ac36aa8c255", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "a8e4522ce2ce7336e731286654d6ad0931927a4e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "f6202100cfb83286dc51f57c68cffdbf5cf50a3f", "predicted_answer": "Multi-step, Late and Early fusion.", "predicted_evidence": ["n/a"]}
{"question_id": "bd7039f81a5417474efa36f703ebddcf51835254", "predicted_answer": "Cooperative graph neural networks (CGNN) and a multi-view reasoning network (MVRN).", "predicted_evidence": ["n/a"]}
{"question_id": "022e5c996a72aeab890401a7fdb925ecd0570529", "predicted_answer": "The two models use a cooperative game to select the most confident reasoning chains.", "predicted_evidence": ["n/a"]}
{"question_id": "2a950ede24b26a45613169348d5db9176fda4f82", "predicted_answer": "1000", "predicted_evidence": ["n/a"]}
{"question_id": "34af2c512ec38483754e94e1ea814aa76552d60a", "predicted_answer": "SQuAD and HotpotQA benchmarks are created.", "predicted_evidence": ["n/a"]}
{"question_id": "c1429f7fed5a4dda11ac7d9643f97af87a83508b", "predicted_answer": "The paper references several empirical investigations.", "predicted_evidence": ["n/a"]}
{"question_id": "a93d4aa89ac3abbd08d725f3765c4f1bed35c889", "predicted_answer": "The paper investigates human-machine parity in language translation for various languages, but does not provide a specific list. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "bc473c5bd0e1a8be9b2037aa7006fd68217c3f47", "predicted_answer": "The paper offers a set of recommendations for assessing human-machine parity in language translation.", "predicted_evidence": ["n/a"]}
{"question_id": "cc5d8e12f6aecf6a5f305e2f8b3a0c67f49801a9", "predicted_answer": "35% fewer errors.", "predicted_evidence": ["n/a"]}
{"question_id": "9299fe72f19c1974564ea60278e03a423eb335dc", "predicted_answer": "The weakness in Hassan et al's evaluation design was providing participants with the source sentence at test time.", "predicted_evidence": ["n/a"]}
{"question_id": "2ed02be0c183fca7031ccb8be3fd7bc109f3694b", "predicted_answer": "1.5 Rouge-1 point improvement over the state-of-the-art.", "predicted_evidence": ["n/a"]}
{"question_id": "be73a88d5b695200e2ead4c2c24e2a977692970e", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "0e45aae0e97a6895543e88705e153f084ce9c136", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "c515269b37cc186f6f82ab9ada5d9ca176335ded", "predicted_answer": "They present evidence based on the analysis of attention weights that the model attends to shallow context clues.", "predicted_evidence": ["n/a"]}
{"question_id": "43f86cd8aafe930ebb35ca919ada33b74b36c7dd", "predicted_answer": "The input is restructured using a sliding window approach.", "predicted_evidence": ["n/a"]}
{"question_id": "aa60b0a6c1601e09209626fd8c8bdc463624b0b3", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "3837ae1e91a4feb27f11ac3b14963e9a12f0c05e", "predicted_answer": "Task-specific features used: Mel frequency cepstral coefficients (MFCCs), chroma features, and semantic segmentation.", "predicted_evidence": ["n/a"]}
{"question_id": "ef4d6c9416e45301ea1a4d550b7c381f377cacd9", "predicted_answer": "Cosine similarity measures for n-grams and POS-tagged words.", "predicted_evidence": ["n/a"]}
{"question_id": "689d1d0c4653a8fa87fd0e01fa7e12f75405cd38", "predicted_answer": "The paper explored Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).", "predicted_evidence": ["n/a"]}
{"question_id": "7920f228de6ef4c685f478bac4c7776443f19f39", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "41844d1d1ee6d6d38f31b3a17a2398f87566ed92", "predicted_answer": "Siamese architecture with 1-D convolutional neural networks (ConvNets) and max-pooling layers.", "predicted_evidence": ["n/a"]}
{"question_id": "ae17066634bd2731a07cd60e9ca79fc171692585", "predicted_answer": "They explore domain mismatch using a domain adaptation approach.", "predicted_evidence": ["n/a"]}
{"question_id": "4fa2faa08eeabc09d78d89aaf0ea86bb36328172", "predicted_answer": "They explore dialect variability through character-level CNN and multi-level biLSTM where different dialects are represented as separate classes.", "predicted_evidence": ["n/a"]}
{"question_id": "e87f47a293e0b49ab8b15fc6633d9ca6dc9de071", "predicted_answer": "Egyptian, Levantine, Gulf, and North African.", "predicted_evidence": ["n/a"]}
{"question_id": "7426a6e800d6c11795941616fc4a243e75716a10", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "da4535b75e360604e3ce4bb3631b0ba96f4dadd3", "predicted_answer": "Semantic and discourse interpretation biases.", "predicted_evidence": ["n/a"]}
{"question_id": "4d30c2223939b31216f2e90ef33fe0db97e962ac", "predicted_answer": "26,000.", "predicted_evidence": ["n/a"]}
{"question_id": "7b47aa6ba247874eaa8ab74d7cb6205251c01eb5", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "ce14b87dacfd5206d2a5af7c0ed1cfeb7b181922", "predicted_answer": "QuaSP+Zero is not mentioned in the paper. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "709a4993927187514701fe3cc491ac3030da1215", "predicted_answer": "Tools used on QuaRel: CoreNLP, Stanford Parser, OpenIE.", "predicted_evidence": ["n/a"]}
{"question_id": "a3c6acf900126bc9bd9c50ce99041ea00761da6a", "predicted_answer": "They obtain the logical forms of their questions in their dataset through manual annotation.", "predicted_evidence": ["n/a"]}
{"question_id": "31b631a8634f6180b20a72477040046d1e085494", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "ab78f066144936444ecd164dc695bec1cb356762", "predicted_answer": "intentions and slots.", "predicted_evidence": ["n/a"]}
{"question_id": "e659ceb184777015c12db2da5ae396635192f0b0", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "b512ab8de26874ee240cffdb3c65d9ac8d6023d9", "predicted_answer": "RBF and Linear kernels.", "predicted_evidence": ["n/a"]}
{"question_id": "4e4d377b140c149338446ba69737ea191c4328d9", "predicted_answer": "The paper used multiple datasets including Amazon Review dataset, Yelp Review dataset, Stanford Large Movie Review dataset, and ACM Digital Library dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "828ce5faed7783297cf9ce202364f999b8d4a1f6", "predicted_answer": "The paper doesn't provide enough evidence on what metrics are considered. The term \"metrics\" is not mentioned in the paper.", "predicted_evidence": ["n/a"]}
{"question_id": "9d016eb3913b41f7a18c6fa865897c12b5fe0212", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "c1c611409b5659a1fd4a870b6cc41f042e2e9889", "predicted_answer": "The authors used BLEU, METEOR, TER, and their proposed CIDEr-D evaluation metrics on their system.", "predicted_evidence": ["n/a"]}
{"question_id": "79bb1a1b71a1149e33e8b51ffdb83124c18f3e9c", "predicted_answer": "90.67%", "predicted_evidence": ["n/a"]}
{"question_id": "26faad6f42b6d628f341c8d4ce5a08a591eea8c2", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "20be7a776dfda0d3c9dc10270699061cb9bc8297", "predicted_answer": "The manuscripts are written in historical Indic languages.", "predicted_evidence": ["n/a"]}
{"question_id": "3bfb8c12f151dada259fbd511358914c4b4e1b0e", "predicted_answer": "F1 score, precision, and recall.", "predicted_evidence": ["n/a"]}
{"question_id": "3f85cc5be84479ba668db6d9f614fedbff6d77f1", "predicted_answer": "The paper does not provide information on the size of the Wikipedia revision dump dataset. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "126e8112e26ebf8c19ca7ff3dd06691732118e90", "predicted_answer": "Simulated datasets were not collected.", "predicted_evidence": ["n/a"]}
{"question_id": "be08ef81c3cfaaaf35c7414397a1871611f1a7fd", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "dc57ae854d78aa5d5e8c979826d3e2524d4e9165", "predicted_answer": "Being feature-engineering free is an advantage because it allows the model to learn the relevant features automatically from the input data. Therefore, the answer is 'it allows the model to learn the relevant features automatically.'", "predicted_evidence": ["n/a"]}
{"question_id": "18412237f7faafc6befe975d5bcd348e2b499b55", "predicted_answer": "Second.", "predicted_evidence": ["n/a"]}
{"question_id": "02945c85d6cc4cdd1757b2f2bfa5e92ee4ed14a0", "predicted_answer": "Short stories.", "predicted_evidence": ["n/a"]}
{"question_id": "6e51af9088c390829703c6fa966e98c3a53114c1", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "07ee4e0277ad1083270131d32a71c3fe062a916d", "predicted_answer": "Irony detection and sentiment analysis are the tasks used in the multi-task learning setup.", "predicted_evidence": ["n/a"]}
{"question_id": "bfce2afe7a4b71f9127d4f9ef479a0bfb16eaf76", "predicted_answer": "The human evaluation metrics used in the paper include Fluency, Coherence, Relevance, and Interest.", "predicted_evidence": ["n/a"]}
{"question_id": "dfbab3cd991f86d998223726617d61113caa6193", "predicted_answer": "Domain specific knowledge is determined by whether it is present or absent in the target domain.", "predicted_evidence": ["n/a"]}
{"question_id": "df510c85c277afc67799abcb503caa248c448ad2", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d95180d72d329a27ddf2fd5cc6919f469632a895", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "e196e2ce72eb8b2d50732c26e9bf346df6643f69", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "46570c8faaeefecc8232cfc2faab0005faaba35f", "predicted_answer": "List: \n- Reddit comments dataset\n- Twitter dataset\n- Riloff dataset\n- Ptacek dataset\n- SemEval-2018 Task 3 dataset\n- Davidov dataset\n- Testing datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "982d375378238d0adbc9a4c987d633ed16b7f98f", "predicted_answer": "Twitter, Reddit and Figurative dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "bbdb2942dc6de3d384e3a1b705af996a5341031b", "predicted_answer": "Contextualized word representations.", "predicted_evidence": ["n/a"]}
{"question_id": "4ec538e114356f72ef82f001549accefaf85e99c", "predicted_answer": "Morphosyntactic features related to irony or sarcasm are not explicitly mentioned in the paper. Thus, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "40a45d59a2ef7a67c8ab0f2b2d5b43fc85b85498", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "b29b5c39575454da9566b3dd27707fced8c6f4a1", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "4040f5c9f365f9bc80b56dce944ada85bb8b4ab4", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "7dce1b64c0040500951c864fce93d1ad7a1809bc", "predicted_answer": "They do not mention which frozen acoustic model they use.", "predicted_evidence": ["n/a"]}
{"question_id": "e1b36927114969f3b759cba056cfb3756de474e4", "predicted_answer": "17.1% improvement.", "predicted_evidence": ["n/a"]}
{"question_id": "186ccc18c6361904bee0d58196e341a719fb31c2", "predicted_answer": "The paper uses sentiment analysis and topic extraction features.", "predicted_evidence": ["n/a"]}
{"question_id": "fd5412e2784acefb50afc3bfae1e087580b90ab9", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "c7f087c78768d5c6f3ff26921858186d627fd4fd", "predicted_answer": "They incorporate sentiment analysis using a commercial natural language processing platform.", "predicted_evidence": ["n/a"]}
{"question_id": "82596190560dc2e2ced2131779730f40a3f3eb8c", "predicted_answer": "MIMIC-III dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "345f65eaff1610deecb02ff785198aa531648e75", "predicted_answer": "Topic extraction is performed using Latent Dirichlet Allocation (LDA).", "predicted_evidence": ["n/a"]}
{"question_id": "51d03f0741b72ae242c380266acd2321baf43444", "predicted_answer": "The paper finds that attending to characters outperforms simple interpolation between a word-level and a character-level language model. Answer: Attending to characters outperforms simple interpolation.", "predicted_evidence": ["n/a"]}
{"question_id": "96c20af8bbef435d0d534d10c42ae15ff2f926f8", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "9544cc0244db480217ce9174aa13f1bf09ba0d94", "predicted_answer": "News and TED datasets include English, Arabic, Chinese, and European languages.", "predicted_evidence": ["n/a"]}
{"question_id": "c97a4a1c0e3d00137a9ae8d6fbb809ba6492991d", "predicted_answer": "The coreference chain translations are evaluated using the CoNLL 2012 coreference resolution evaluation script.", "predicted_evidence": ["n/a"]}
{"question_id": "3758669426e8fb55a4102564cf05f2864275041b", "predicted_answer": "The (possibly incorrect) coreference chains in the MT outputs are annotated using the exact match of mentions.", "predicted_evidence": ["n/a"]}
{"question_id": "1ebd6f703458eb6690421398c79abf3fc114148f", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "15a1df59ed20aa415a4daf0acb256747f6766f77", "predicted_answer": "The paper analyses both definite and indefinite coreference phenomena.", "predicted_evidence": ["n/a"]}
{"question_id": "b124137e62178a2bd3b5570d73b1652dfefa2457", "predicted_answer": "New interesting tasks that can be solved based on the uncanny semantic structures of the embedding space are query-based link prediction and knowledge exploration.", "predicted_evidence": ["n/a"]}
{"question_id": "c6aa8a02597fea802890945f0b4be8d631e4d5cd", "predicted_answer": "Uncanny semantic structures of the embedding space are not discussed in the paper. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "bfad30f51ce3deea8a178944fa4c6e8acdd83a48", "predicted_answer": "The general framework for data exploration by semantic queries involves using an embedding-based approach to map the entities and relationships in a knowledge graph to a continuous vector space, and then allowing users to input natural language queries to identify relevant subgraphs.", "predicted_evidence": ["n/a"]}
{"question_id": "dd9883f4adf7be072d314d7ed13fe4518c5500e0", "predicted_answer": "The analysis of these semantic structures supports data exploration by semantic query.", "predicted_evidence": ["n/a"]}
{"question_id": "81669c550d32d756f516dab5d2b76ff5f21c0f36", "predicted_answer": "BERT, DCN, SAN, R-NET, Multi-Step Attention, and AoA Reader.", "predicted_evidence": ["n/a"]}
{"question_id": "b0b1ff2d6515fb40d74a4538614a0db537e020ea", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "4266aacb575b4be7dbcdb8616766324f8790763c", "predicted_answer": "The paper does not mention any detailed analyses in relation to the conclusions. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "191107cd112f7ee6d19c1dc43177e6899452a2c7", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "b0dca7b74934f51ff3da0c074ad659c25d84174d", "predicted_answer": "Traditional linguistic feature-based models were rule-based models and machine learning models that utilized handcrafted linguistic features.", "predicted_evidence": ["n/a"]}
{"question_id": "601e58a3d2c03a0b4cd627c81c6228a714e43903", "predicted_answer": "The paper establishes rule-based baselines for both of the datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "a0fbf90ceb520626b80ff0f9160b3cd5029585a5", "predicted_answer": "Deep Convolutional Generative Adversarial Networks achieve state of the art performance on this task.", "predicted_evidence": ["n/a"]}
{"question_id": "e8ca81d5b36952259ef3e0dbeac7b3a622eabe8e", "predicted_answer": "The paper uses the IEMOCAP corpus.", "predicted_evidence": ["n/a"]}
{"question_id": "e75685ef5f58027be44f42f30cb3988b509b2768", "predicted_answer": "Classification of emotion and generating speech.", "predicted_evidence": ["n/a"]}
{"question_id": "1df24849e50fcf22f0855e0c0937c1288450ed5c", "predicted_answer": "The paper does not provide enough evidence or information to answer this question. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "859e0bed084f47796417656d7a68849eb9cb324f", "predicted_answer": "The paper does not provide a clear definition of rare words.", "predicted_evidence": ["n/a"]}
{"question_id": "04e90c93d046cd89acef5a7c58952f54de689103", "predicted_answer": "PM, WikiMovies and CBT are the public datasets used in the paper.", "predicted_evidence": ["n/a"]}
{"question_id": "f513e27db363c28d19a29e01f758437d7477eb24", "predicted_answer": "The baselines are BiLSTM and LSTM models.", "predicted_evidence": ["n/a"]}
{"question_id": "eb5ed1dd26fd9adb587d29225c7951a476c6ec28", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "0828cfcf0e9e02834cc5f279a98e277d9138ffd9", "predicted_answer": "The paper states that the dataset was collected from a group of 5 speakers who were asked to read short passages.", "predicted_evidence": ["n/a"]}
{"question_id": "7b2de0109b68f78afa9e6190c82ca9ffaf62f9bd", "predicted_answer": "The dataset size is 20 hours.", "predicted_evidence": ["n/a"]}
{"question_id": "482ac96ff675975227b6d7058b9b87aeab6f81fe", "predicted_answer": "The paper does not provide information on the number of different subjects in the dataset. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "3f3c09c1fd542c1d9acf197957c66b79ea1baf6e", "predicted_answer": "Five annotators participated.", "predicted_evidence": ["n/a"]}
{"question_id": "0a82534ec6e294ab952103f11f56fd99137adc1f", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "938688871913862c9f8a28b42165237b7324e0de", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "4170ed011b02663f5b1b1a3c1f0415b7abfaa85d", "predicted_answer": "The paper suggests that there is a positive relationship between co-voting and retweeting patterns.", "predicted_evidence": ["n/a"]}
{"question_id": "fd08dc218effecbe5137a7e3b73d9e5e37ace9c1", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "a85c2510f25c7152940b5ac4333a80e0f91ade6e", "predicted_answer": "The analysis suggests that political groups in the European parliament exhibit lower levels of cohesion on Twitter activities than on roll-call votes, but the difference is more pronounced for certain groups.", "predicted_evidence": ["n/a"]}
{"question_id": "fa572f1f3f3ce6e1f9f4c9530456329ffc2677ca", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "5e057e115f8976bf9fe70ab5321af72eb4b4c0fc", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d824f837d8bc17f399e9b8ce8b30795944df0d51", "predicted_answer": "They show their model discovers underlying syntactic structure by analyzing the learned word embeddings and observing that similar syntactic categories are grouped together. Answer: Word embeddings.", "predicted_evidence": ["n/a"]}
{"question_id": "2ff3898fbb5954aa82dd2f60b37dd303449c81ba", "predicted_answer": "PTB, WikiText-2, and Penn Chinese Treebank (CTB) datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "3070d6d6a52aa070f0c0a7b4de8abddd3da4f056", "predicted_answer": "Perplexity.", "predicted_evidence": ["n/a"]}
{"question_id": "ee9b95d773e060dced08705db8d79a0a6ef353da", "predicted_answer": "Content clusters are used to identify incident severity which is then used to improve the prediction of incident severity.", "predicted_evidence": ["n/a"]}
{"question_id": "dbdf13cb4faa1785bdee90734f6c16380459520b", "predicted_answer": "Graph-based clustering.", "predicted_evidence": ["n/a"]}
{"question_id": "73e715e485942859e1db75bfb5f35f1d5eb79d2e", "predicted_answer": "The paper proposes a two-stage neural model that first retrieves related documents using a retriever module and then applies a comprehension module to extract answers from the retrieved documents.", "predicted_evidence": ["n/a"]}
{"question_id": "12391aab31c899bac0ecd7238c111cb73723a6b7", "predicted_answer": "Factorized Dual Learning (FDL) algorithm.", "predicted_evidence": ["n/a"]}
{"question_id": "8b43201e7e648c670c02e16ba189230820879228", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "5d5a571ff04a5fdd656ca87f6525a60e917d6558", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "3c362bfa11c60bad6c7ea83f8753d427cda77de0", "predicted_answer": "To improve the efficiency and accuracy of Traditional Chinese Medicine prescriptions.", "predicted_evidence": ["n/a"]}
{"question_id": "e78a47aec37d9a3bec5a18706b0a462c148c118b", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "351510da69ab6879df5ff5c7c5f49a8a7aea4632", "predicted_answer": "Languages explored: English, French, Dutch, German, Spanish, Italian, Finnish, Bulgarian, Hungarian, Portuguese, Turkish, Indonesian, and Arabic.", "predicted_evidence": ["n/a"]}
{"question_id": "d43e868cae91b3dc393c05c55da0754b0fb3a46a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "fd8b6723ad5f52770bec9009e45f860f4a8c4321", "predicted_answer": "BERT and BiLSTM-based QA models.", "predicted_evidence": ["n/a"]}
{"question_id": "4ce3a6632e7d86d29a42bd1fcf325114b3c11d46", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "e7c0cdc05b48889905cc03215d1993ab94fb6eaa", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "99760276cfd699e55b827ceeb653b31b043b9ceb", "predicted_answer": "Morphological analysis involves breaking down words into their constituent morphemes, while morphological inflection involves adding or changing morphemes to a word to indicate grammatical categories such as tense, aspect, and agreement. So, they differ in their approach and purpose.", "predicted_evidence": ["n/a"]}
{"question_id": "247e1fe052230458ce11b98e3637acf0b86795cd", "predicted_answer": "The criterion used for selecting the lemmata is frequency.", "predicted_evidence": ["n/a"]}
{"question_id": "79cfd1b82c72d18e2279792c66a042c0e9dfa6b7", "predicted_answer": "LSTM and feedforward neural network architectures.", "predicted_evidence": ["n/a"]}
{"question_id": "9e1bf306658ef2972159643fdaf149c569db524b", "predicted_answer": "Oto-Manguean.", "predicted_evidence": ["n/a"]}
{"question_id": "25b24ab1248f14a621686a57555189acc1afd49c", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "8486e06c03f82ebd48c7cfbaffaa76e8b899eea5", "predicted_answer": "The paper does not provide information related to how annotation was done. Answer: Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "27f575e90487ef68298cfb6452683bb977e39e43", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "157b9f6f8fb5d370fa23df31de24ae7efb75d6f3", "predicted_answer": "N-GrAM achieved the highest performance in the PAN 2017 shared task on Author Profiling.", "predicted_evidence": ["n/a"]}
{"question_id": "9bcc1df7ad103c7a21d69761c452ad3cd2951bda", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "8427988488b5ecdbe4b57b3813b3f981b07f53a5", "predicted_answer": "Author profiling.", "predicted_evidence": ["n/a"]}
{"question_id": "3604c4fba0a82d7139efd5ced47612c90bd10601", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "38e2f07ba965b676a99be06e8872dade7c04722a", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "931a2a13a1f6a8d9107d26811089bdccc39b0800", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "8c981f8b992cb583e598f71741c322f522c6d2ad", "predicted_answer": "The substitution rules are built using hand-crafted rules.", "predicted_evidence": ["n/a"]}
{"question_id": "16f33de90b76975a99572e0684632d5aedbd957c", "predicted_answer": "The paper uses multiple datasets, including the Icelandic Gigaword corpus and the SaltP\u00e9turs saga corpus.", "predicted_evidence": ["n/a"]}
{"question_id": "d0b005cb7ed6d4c307745096b2ed8762612480d2", "predicted_answer": "Baseline.", "predicted_evidence": ["n/a"]}
{"question_id": "9d9b11f86a96c6d3dd862453bf240d6e018e75af", "predicted_answer": "Counterfactual data augmentation aims to tackle bias by generating counterfactual examples that swap the gender of the speaker in the original examples to create a balanced dataset. Therefore, it helps in mitigating gender bias in dialogue generation.", "predicted_evidence": ["n/a"]}
{"question_id": "415f35adb0ef746883fb9c33aa53b79cc4e723c3", "predicted_answer": "The targeted data collection approach targets \"non-stereotypical persona names\". Answer: non-stereotypical persona names.", "predicted_evidence": ["n/a"]}
{"question_id": "52f1a91f546b8a25a5d72325c503ec8f9c72de23", "predicted_answer": "They compare against three language models: GloVe, Word2Vec, and LexVec.", "predicted_evidence": ["n/a"]}
{"question_id": "bb5697cf352dd608edf119ca9b82a6b7e51c8d21", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "98785bf06e60fcf0a6fe8921edab6190d0c2cec1", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "9846f84747b89f5c692665c4ea7111671ad9839a", "predicted_answer": "39.2", "predicted_evidence": ["n/a"]}
{"question_id": "eecf62e18a790bcfdd8a56f0c4f498927ff2fb47", "predicted_answer": "Soft contextual data augmentation involves dynamically generating additional training examples by perturbing the source sentence with compatible contextual modifications.", "predicted_evidence": ["n/a"]}
{"question_id": "acda028a21a465c984036dcbb124b7f03c490b41", "predicted_answer": "Multi-agent dual learning uses two agents, one as a generator and one as a translator, to learn from each other in a shared embedding space.", "predicted_evidence": ["n/a"]}
{"question_id": "42af0472e6895eaf7b9392674b0d956e64e86b03", "predicted_answer": "The machine translation systems of WMT19 are evaluated on several language directions, including English-German and English-Chinese. (multiple directions are evaluated)", "predicted_evidence": ["n/a"]}
{"question_id": "a85698f19a91ecd3cd3a90a93a453d2acebae1b7", "predicted_answer": "10x computational cost is saved by using this model.", "predicted_evidence": ["n/a"]}
{"question_id": "af073d84b8a7c968e5822c79bef34a28655886de", "predicted_answer": "The MOE model improves the SOTA on machine translation by 1.3 BLEU points.", "predicted_evidence": ["n/a"]}
{"question_id": "e8fcfb1412c3b30da6cbc0766152b6e11e17196c", "predicted_answer": "The MOE model achieves a 1.16 perplexity improvement over the SOTA on language modeling. Answer: 1.16.", "predicted_evidence": ["n/a"]}
{"question_id": "0cd90e5b79ea426ada0203177c28812a7fc86be5", "predicted_answer": "The number of experts is decided through a dynamic routing algorithm.", "predicted_evidence": ["n/a"]}
{"question_id": "f01a88e15ef518a68d8ca2bec992f27e7a3a6add", "predicted_answer": "Equations for the trainable gating network are non-linear 2-layer feedforward neural networks with bias.", "predicted_evidence": ["n/a"]}
{"question_id": "44104668796a6ca10e2ea3ecf706541da1cec2cf", "predicted_answer": "The paper provides evidence that the LSTM with ELMo system outperforms the interpretable system. Therefore, the difference in performance is in favor of the LSTM with ELMo system.", "predicted_evidence": ["n/a"]}
{"question_id": "bbcd77aac74989f820e84488c52f3767d0405d51", "predicted_answer": "The paper proposes the use of rule-based and statistical methods for error detection and context awareness.", "predicted_evidence": ["n/a"]}
{"question_id": "6a31bd676054222faf46229fc1d283322478a020", "predicted_answer": "PIEWi is annotated manually.", "predicted_evidence": ["n/a"]}
{"question_id": "e4d16050f0b457c93e590261732a20401def9cde", "predicted_answer": "Methods tested in PIEWi: Hunspell, Aspell, and a rule-based method.", "predicted_evidence": ["n/a"]}
{"question_id": "b25e7137f49f77e7e67ee2f40ca585d3a377f8b5", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d803b782023553bbf9b36551fbc888ad189b1f29", "predicted_answer": "The paper does not mention any criteria for human evaluation. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "fc5f9604c74c9bb804064f315676520937131e17", "predicted_answer": "BLEU and Slot Error Rate (SER).", "predicted_evidence": ["n/a"]}
{"question_id": "b37fd665dfa5fad43977069d5623f4490a979305", "predicted_answer": "SC-GPT is compared to two existing methods: MAML and T5.", "predicted_evidence": ["n/a"]}
{"question_id": "c1f4d632da78714308dc502fe4e7b16ea6f76f81", "predicted_answer": "German-English language pair had the better performance", "predicted_evidence": ["n/a"]}
{"question_id": "749a307c3736c5b06d7b605dc228d80de36cbabe", "predicted_answer": "The paper used four different datasets: WMT14 English-German, WMT16 English-Romanian, UN parallel corpus and a subset of JW300.", "predicted_evidence": ["n/a"]}
{"question_id": "102de97c123bb1e247efec0f1d958f8a3a86e2f6", "predicted_answer": "They used BLEU score and chrF score as evaluation metrics.", "predicted_evidence": ["n/a"]}
{"question_id": "3460393d6888dd34113fa0813a1b3a1514c66aa6", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "d491ee69db39ec65f0f6da9ec03450520389699a", "predicted_answer": "The paper states that gang members use particular emojis (gun, knife, bomb, etc.) more frequently than non-gang members, which can be used to help identify them.", "predicted_evidence": ["n/a"]}
{"question_id": "d3839c7acee4f9c8db0a4a475214a8dcbd0bc26f", "predicted_answer": "Gang members use more YouTube links than the rest of the Twitter population.", "predicted_evidence": ["n/a"]}
{"question_id": "a6d00f44ff8f83b6c1787e39333e759b0c3daf15", "predicted_answer": "The paper states that gang members on Twitter use more images pertaining to the \"gang lifestyle\" compared to the rest of the Twitter population.", "predicted_evidence": ["n/a"]}
{"question_id": "0d4aa05eb00d9dee74000ea5b21b08f693ba1e62", "predicted_answer": "The paper found that gang members on Twitter use more slang and profanity compared to the rest of the Twitter population.", "predicted_evidence": ["n/a"]}
{"question_id": "382bef47d316d7c12ea190ae160bf0912a0f4ffe", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "32a232310babb92991c4b1b75f7aa6b4670ec447", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "5845d1db7f819dbadb72e7df69d49c3f424b5730", "predicted_answer": "English is mixed with Hindi in the TRAC dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "e829f008d62312357e0354a9ed3b0827c91c9401", "predicted_answer": "Psycholinguistic features and basic linguistic features are used.", "predicted_evidence": ["n/a"]}
{"question_id": "54fe8f05595f2d1d4a4fd77f4562eac519711fa6", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "61404466cf86a21f0c1783ce535eb39a01528ce8", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "fbe5e513745d723aad711ceb91ce0c3c2ceb669e", "predicted_answer": "The authors do not provide any data/studies to support the assertion that the majority of aggressive conversations contain code-mixed languages. (Unanswerable)", "predicted_evidence": ["n/a"]}
{"question_id": "1571e16063b53409f2d1bd6ec143fccc5b29ebb9", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d71937fa5da853f7529f767730547ccfb70e5908", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "8d258899e36326183899ebc67aeb4188a86f682c", "predicted_answer": "The model uses the scoring function of L1 distance or Manhattan distance.", "predicted_evidence": ["n/a"]}
{"question_id": "955ca31999309685c1daa5cb03867971ca99ec52", "predicted_answer": "The paper evaluates the model on four datasets: FB15K, WN18, FB13, and WN11.", "predicted_evidence": ["n/a"]}
{"question_id": "9b2b063e8a9938da195c9c0d6caa3e37a4a615a8", "predicted_answer": "The paper states that each Doc2Vec model took 14 hours to be trained. Answer: 14 hours.", "predicted_evidence": ["n/a"]}
{"question_id": "ac3c88ace59bf75788370062db139f60499c2056", "predicted_answer": "The paper provides no evidence or information related to human evaluation of pmra vs. Doc2Vec, therefore the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "26012f57cba21ba44b9a9f7ed8b1ed9e8ee7625d", "predicted_answer": "PV-DM and PV-DBOW with the distributed memory and Distributed Bag of Words architectures.", "predicted_evidence": ["n/a"]}
{"question_id": "bd26a6d5d8b68d62e1b6eaf974796f3c34a839c4", "predicted_answer": "The four evaluation tasks defined to determine what influences proximity are: Related Article Ranking Task, Medical Text Similarity Task, Medical Query Auto Completion Task, and Medical Query Sub-sampling Task.", "predicted_evidence": ["n/a"]}
{"question_id": "7d4fad6367f28c67ad22487094489680c45f5062", "predicted_answer": "alpha, window size, negative sampling, subsampling, vector size, and number of epochs were optimized with grid search.", "predicted_evidence": ["n/a"]}
{"question_id": "3aa7173612995223a904cc0f8eef4ff203cbb860", "predicted_answer": "BiDAF, DCN, SAN.", "predicted_evidence": ["n/a"]}
{"question_id": "acc8d9918d19c212ec256181e51292f2957b37d7", "predicted_answer": "The paper does not provide sufficient evidence or information to answer this question.", "predicted_evidence": ["n/a"]}
{"question_id": "6f2f304ef292d8bcd521936f93afeec917cbe28a", "predicted_answer": "0.8 points improvement.", "predicted_evidence": ["n/a"]}
{"question_id": "82fa2b99daa981fc42a882bb6db8481bdbbb9675", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "61fb982b2c67541725d6db76b9c710dd169b533d", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "68edb6a483cdec669c9130c928994654f1c19839", "predicted_answer": "The paper does not mention any metrics used in the challenge. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "f64531e460e0ac09b58584047b7616fdb7dd5b3f", "predicted_answer": "Answer: Modal Dropout.", "predicted_evidence": ["n/a"]}
{"question_id": "cee29acec4da1b247795daa4e2e82ef8a7b25a64", "predicted_answer": "The paper does not provide information about the model that won the Visual Dialog challenge 2018.", "predicted_evidence": ["n/a"]}
{"question_id": "7e54c7751dbd50d9d14b9f8b13dc94947a46e42f", "predicted_answer": "Ensemble.", "predicted_evidence": ["n/a"]}
{"question_id": "d3bcfcea00dec99fa26283cdd74ba565bc907632", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "cdf65116a7c50edddcb115e9afd86b2b6accb8ad", "predicted_answer": "Relation extraction tasks involving substances, enzymes, and proteins.", "predicted_evidence": ["n/a"]}
{"question_id": "c8031c1629d270dedc3b0c16dcb7410524ff1bab", "predicted_answer": "Logician uses a unified end-to-end neural approach for open-domain information extraction. Therefore, it is different from traditional seq2seq models.", "predicted_evidence": ["n/a"]}
{"question_id": "8c0e8a312b85c4ffdffabeef0d29df1ef8ff7fb2", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "8816333fbed2bfb1838407df9d6c084ead89751c", "predicted_answer": "The data for RTFM is collected through a combination of \"offline data generation and online data collection procedures.\"", "predicted_evidence": ["n/a"]}
{"question_id": "37e8f5851133a748c4e3e0beeef0d83883117a98", "predicted_answer": "The proposed model performs better than the baselines.", "predicted_evidence": ["n/a"]}
{"question_id": "c9e9c5f443649593632656a5934026ad8ccc1712", "predicted_answer": "The proposed model does not capture three-way interactions. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "4d844c9453203069363173243e409698782bac3f", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "5633d93ef356aca02592bae3dfc1b3ec8fce27dc", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "134598831939a3ae20d177cec7033d133625a88e", "predicted_answer": "They transfer the model using shared layers for all tasks and specialized layers for each task.", "predicted_evidence": ["n/a"]}
{"question_id": "4bae74eb707ed71d5f438ddb3d9c2192ac490f66", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "c30c3e0f8450b1c914d29f41c17a22764fa078e0", "predicted_answer": "Span-based Question Answering Algorithm.", "predicted_evidence": ["n/a"]}
{"question_id": "21656039994cab07f79e89553cbecc31ba9853d4", "predicted_answer": "SQuAD, TriviaQA and QuAC.", "predicted_evidence": ["n/a"]}
{"question_id": "bee74e96f2445900e7220bc27795bfe23accd0a7", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "a56fbe90d5d349336f94ef034ba0d46450525d19", "predicted_answer": "DCGs (Definite Clause Grammars) for active and passive sentences are used.", "predicted_evidence": ["n/a"]}
{"question_id": "b1f2db88a6f89d0f048803e38a0a568f5ba38fc5", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "cf3af2b68648fa8695e7234b6928d014e3b141f1", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "7883a52f008f3c4aabfc9f71ce05d7c4107e79bb", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "cd9776d03fe48903e43e916385df12e1e798070a", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "1a252ffeaebdb189317aefd6c606652ba9677112", "predicted_answer": "69.4%", "predicted_evidence": ["n/a"]}
{"question_id": "da4d25dd9de09d16168788bb02ad600f5b0b3ba4", "predicted_answer": "Heads 0-4 in layer 5 and heads 0-2 in layer 9.", "predicted_evidence": ["n/a"]}
{"question_id": "2870fbce43a3cf6daf982f720137c008b30c60dc", "predicted_answer": "Input tokens, Part-of-Speech tags, and named entity tags.", "predicted_evidence": ["n/a"]}
{"question_id": "65b579b2c62982e2ff154c8160288c2950d509f2", "predicted_answer": "MNLI, QNLI, QQP, RTE, SST-2, and MRPC.", "predicted_evidence": ["n/a"]}
{"question_id": "b2c8c90041064183159cc825847c142b1309a849", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "68e3f3908687505cb63b538e521756390c321a1c", "predicted_answer": "Using automatically generated summaries instead of user-written ones leads to a performance improvement of 0.7% on average.", "predicted_evidence": ["n/a"]}
{"question_id": "2f9d30e10323cf3a6c9804ecdc7d5872d8ae35e4", "predicted_answer": "Diverse movie review datasets including IMDb, Yelp, and Amazon.", "predicted_evidence": ["n/a"]}
{"question_id": "327e06e2ce09cf4c6cc521101d0aecfc745b1738", "predicted_answer": "They used two evaluation metrics: Perplexity and Novelty.", "predicted_evidence": ["n/a"]}
{"question_id": "40b9f502f15e955ba8615822e6fa08cb5fd29c81", "predicted_answer": "The paper states that 3 datasets are used: Cervantes, Romanticism, and Modernism.", "predicted_evidence": ["n/a"]}
{"question_id": "ba56afe426906c4cfc414bca4c66ceb4a0a68121", "predicted_answer": "The datasets used for the task are Unigram and Bigram.", "predicted_evidence": ["n/a"]}
{"question_id": "14634943d96ea036725898ab2e652c2948bd33eb", "predicted_answer": "The accuracy of the model for the six languages tested is not provided in the paper. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d71cb7f3aa585e256ca14eebdc358edfc3a9539c", "predicted_answer": "The paper shows that the proposed model achieves state-of-the-art performance.", "predicted_evidence": ["n/a"]}
{"question_id": "f6556d2a8b42b133eaa361f562745edbe56c0b51", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "def3d623578bf84139d920886aa3bd6cdaaa7c41", "predicted_answer": "Finnish, Turkish, and Russian.", "predicted_evidence": ["n/a"]}
{"question_id": "d51069595f67a3a53c044c8a37bae23facbfa45d", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "1a6e2bd41ee43df83fef2a1c1941e6f95a619ae8", "predicted_answer": "Abstract Meaning Representation (AMR) Parsing subtasks.", "predicted_evidence": ["n/a"]}
{"question_id": "e6c163f80a11bd057bbd0b6e1451ac82edddc78d", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "6adfa9eee76b96953a76c03356bf41d8a9378851", "predicted_answer": "22%", "predicted_evidence": ["n/a"]}
{"question_id": "450a359d117bcfa2de4ffd987f787945f25b3b25", "predicted_answer": "They compute corpus-level embeddings using a simple averaging method.", "predicted_evidence": ["n/a"]}
{"question_id": "70f84c73172211186de1a27b98f5f5ae25a94e55", "predicted_answer": "AdvProp, ImageNet, and CIFAR-10.", "predicted_evidence": ["n/a"]}
{"question_id": "10ddc5caf36fe9d7438eb5a3936e24580c4ffe6a", "predicted_answer": "Competitive Relational Classification models are not specifically tested in this paper. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "29571867fe00346418b1ec36c3b7685f035e22ce", "predicted_answer": "Tasks related to relation prediction and triplet classification.", "predicted_evidence": ["n/a"]}
{"question_id": "1a678d081f97531d54b7122254301c20b3531198", "predicted_answer": "The paper does not provide information on which knowledge bases were used. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "b9f2a30f5ef664ff845d860cf4bfc2afb0a46e5a", "predicted_answer": "They used Amazon Mechanical Turk to gather human judgements.", "predicted_evidence": ["n/a"]}
{"question_id": "3513682d4ee2e64725b956c489cd5b5995a6acf2", "predicted_answer": "Stratified sampling.", "predicted_evidence": ["n/a"]}
{"question_id": "30b5e5293001f65d2fb9e4d1fdf4dc230e8cf320", "predicted_answer": "Text classification.", "predicted_evidence": ["n/a"]}
{"question_id": "993b896771c31f3478f28112a7335e7be9d03f21", "predicted_answer": "Novel class of recurrent-like networks is not proposed. Hence, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "dee116df92f9f92d9a67ac4d30e32822c22158a6", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "94bee0c58976b58b4fef9e0adf6856fe917232e5", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "7efbe48e84894971d7cd307faf5f6dae9d38da31", "predicted_answer": "The Switchboard-300 database contains 300 one-sided telephone conversations.", "predicted_evidence": ["n/a"]}
{"question_id": "7f452eb145d486c15ac4d1107fc914e48ebba60f", "predicted_answer": "Mozilla Common Voice uses the crowdsourcing platform for data collection and validation.", "predicted_evidence": ["n/a"]}
{"question_id": "bb71a638668a21c2d446b44cbf51676c839658f7", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "5fa464a158dc8abf7cef8ca7d42a7080670c1edd", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "e1f559da7fa501d3190073bca9ce4d4a12149e80", "predicted_answer": "Their model achieved an F1 score of 90.6% on the domain detection task.", "predicted_evidence": ["n/a"]}
{"question_id": "a96a1a354cb3a2a434b085e4d9c8844d0b672ec4", "predicted_answer": "Newsgroups, Reddit", "predicted_evidence": ["n/a"]}
{"question_id": "427252648173c3ba78c211b86fa89fc9f4406653", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "b9025c39838ccc2a79c545bec4a676f7cc4600eb", "predicted_answer": "They think this task is hard because the correct action prediction may depend on a large context window and the task involves complex reasoning. The baseline performance is an accuracy of 67.60%.", "predicted_evidence": ["n/a"]}
{"question_id": "be6971827707afcd13af3085d0a775a0bd61c5dd", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "19608e727b527562b750949e41e763908566b58e", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "0428e06f0550e1063a64d181210795053a8e6436", "predicted_answer": "The paper does not mention how well a simple bag-of-words baseline does.", "predicted_evidence": ["n/a"]}
{"question_id": "3f7a7e81908a763e5ca720f90570c5f224ac64f6", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "28e7711f94e093137eb8828f0b1eff1b05e4fa38", "predicted_answer": "They divide text into utterances based on speaker turns.", "predicted_evidence": ["n/a"]}
{"question_id": "49b38189b8336ce41d0f0b4c5c9459722736e15b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "40c2bab4a6bf3c0628079fcf19e8b52f27f51d98", "predicted_answer": "They used real data from a customer service chatbot to generate the synthetic dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "33d2919f3400cd3c6fbb6960d74187ec80b41cd6", "predicted_answer": "The paper does not provide information on how multiple answers from multiple reformulated questions are aggregated.", "predicted_evidence": ["n/a"]}
{"question_id": "281cd4e78b27a62713ec43249df5000812522a89", "predicted_answer": "Unanswerable. The paper does not provide information on the average length of the claims.", "predicted_evidence": ["n/a"]}
{"question_id": "fb96c0cd777bb2961117feca19c6d41bfd8cfd42", "predicted_answer": "The paper doesn't provide enough evidence regarding the debate websites they looked at, thus the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "534f69c8c90467d5aa4e38d7c25c53dbc94f4b24", "predicted_answer": "Amazon Mechanical Turk.", "predicted_evidence": ["n/a"]}
{"question_id": "090f2b941b9c5b6b7c34ae18c2cc97e9650f1f0b", "predicted_answer": "The paper uses three machine learning baselines: BERT, ELMo, and Universal Sentence Encoder.", "predicted_evidence": ["n/a"]}
{"question_id": "5e032de729ce9fc727b547e3064be04d30009324", "predicted_answer": "The challenges highlighted in the paper are related to the bias and limited perspective of current claims management systems.", "predicted_evidence": ["n/a"]}
{"question_id": "01dc6893fc2f49b732449dfe1907505e747440b0", "predicted_answer": "The paper does not provide information on the debate topics included in the dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "9776156fc93daa36f4613df591e2b49827d25ad2", "predicted_answer": "2.4 and 1.7 F1 points improvement, respectively.", "predicted_evidence": ["n/a"]}
{"question_id": "03a911049b6d7df2b6391ed5bc129a3b65133bcd", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "f5e571207d9f4701b4d01199ef7d0bfcfa2c0316", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "c5ac07528cf99d353413c9d9ea61a1a699dd783e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "6608f171b3e0dcdcd51b3e0c697d6e5003ab5f02", "predicted_answer": "Lexico-syntactic cues used to retrieve sarcastic utterances include: inversion of word order, negation, intensifiers, pragmatic cue words, and contrastive cues.", "predicted_evidence": ["n/a"]}
{"question_id": "52b113e66fd691ae18b9bb8a8d17e1ee7054bb81", "predicted_answer": "The paper does not provide information on the source of the song lyrics. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "163a21c0701d5cda15be2d0eb4981a686e54a842", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "36b5f0f62ee9be1ab50d1bb6170e98328d45997d", "predicted_answer": "The paper experimented with two word embedding techniques: word2vec and GloVe.", "predicted_evidence": ["n/a"]}
{"question_id": "6b91fe29175be8cd8f22abf27fb3460e43b9889a", "predicted_answer": "The paper classifies Brazilian songs into the genres of Samba, Bossa Nova, and Forr\u00f3.", "predicted_evidence": ["n/a"]}
{"question_id": "aa7decee4e3006c2c99b1f331a5b32d44a565ef6", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "4b8a0e99bf3f2f6c80c57c0e474c47a5ee842b2c", "predicted_answer": "Top-K, Nucleus sampling, Beam search, and Greedy decoding.", "predicted_evidence": ["n/a"]}
{"question_id": "a09633584df1e4b9577876f35e38b37fdd83fa63", "predicted_answer": "Human evaluation is performed using Amazon Mechanical Turk workers, the criteria used is the quality of the response on a scale of 1 to 5.", "predicted_evidence": ["n/a"]}
{"question_id": "5e9732ff8595b31f81740082333b241d0a5f7c9a", "predicted_answer": "The paper does not provide information to compare the proposed models' results with the results of the base LSTM-RNN model. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "58edc6ed7d6966715022179ab63137c782105eaf", "predicted_answer": "AvgOut-M2 performed best.", "predicted_evidence": ["n/a"]}
{"question_id": "b366706e2fff6dd8edc89cc0c6b9d5b0790f43aa", "predicted_answer": "The paper mentions using Success Rate, Average Turns, and Average Reward as metrics to measure performance of models.", "predicted_evidence": ["n/a"]}
{"question_id": "c165ea43256d7ee1b1fb6f5c0c8af5f7b585e60d", "predicted_answer": "4-7%", "predicted_evidence": ["n/a"]}
{"question_id": "e72a672f8008bbc52b93d8037a5fedf8956136af", "predicted_answer": "The paper does not mention state-of-the-art baselines.", "predicted_evidence": ["n/a"]}
{"question_id": "57586358dd01633aa2ebeef892e96a549b1d1930", "predicted_answer": "The Multiwoz and the Camrest676 datasets are used.", "predicted_evidence": ["n/a"]}
{"question_id": "028910d643c103abd90045ccb07ee8adc5a3e177", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "975085e3b6679cc644fdd6ad11b7c2d1261a2dc6", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "609fbe627309775de415682f48588937d5dd8748", "predicted_answer": "PubMed, Wiki10-31 Mines, and AGNews.", "predicted_evidence": ["n/a"]}
{"question_id": "4a8bceb3b6d45f14c4749115d6aa83912f0b0a6e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "7ce213657f7ee792148988c5a3578b24cd2f9c62", "predicted_answer": "Visualizing the attention provides evidence that it helps to obtain a more robust understanding of semantics and sentiments.", "predicted_evidence": ["n/a"]}
{"question_id": "89ce18ee52c52a78b38c49b14574407b7ea2fb02", "predicted_answer": "BiLSTM and attention-based models.", "predicted_evidence": ["n/a"]}
{"question_id": "d3092cd32cd581a57fa4844f80fe18d6b920e903", "predicted_answer": "The paper does not mention a specific baseline for experiments.", "predicted_evidence": ["n/a"]}
{"question_id": "0b39c20db6e60ce07bf5465bd3c08fedc0587780", "predicted_answer": "To better capture the nuances of emotion and sentiment in tweets.", "predicted_evidence": ["n/a"]}
{"question_id": "fb427239c8d44f524a6c1bf1ce5c3383d5c33e52", "predicted_answer": "110 million parameters.", "predicted_evidence": ["n/a"]}
{"question_id": "7c45c6e5db6cfca2d6de8751e28403b35420ae38", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "49ea25af6f75e2e96318bad5ecf784ce84e4f76b", "predicted_answer": "The paper uses two datasets for this task: (1) FarsiNews, a dataset containing news articles in Persian language, and (2) the Persian part of the Multi-News dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "aecd09a817c38cf7606e2888d0df7f14e5a74b95", "predicted_answer": "The features of the document that are integrated into vectors of every sentence are: term frequency (TF), inverse document frequency (IDF), sentence position, sentence length, and cue-phrase frequency.", "predicted_evidence": ["n/a"]}
{"question_id": "81064bbd0a0d72a82d8677c32fb71b06501830a0", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "7d841b98bcee29aaa9852ef7ceea1213d703deba", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "4e8233826f9e04f5763b307988298e73f841af74", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "adae0c32a69928929101d0ba37d36c0a45298ad6", "predicted_answer": "SVM, Naive Bayes, and Random Forest classifiers.", "predicted_evidence": ["n/a"]}
{"question_id": "d0f831c97d345a5b8149a9d51bf321f844518434", "predicted_answer": "The labels in the dataset are stress levels.", "predicted_evidence": ["n/a"]}
{"question_id": "1ccfd288f746c35006f5847297ab52020729f523", "predicted_answer": "The dataset includes categories related to mental health and stress, such as depression, anxiety, and stressors.", "predicted_evidence": ["n/a"]}
{"question_id": "ed6462da17c553bda112ef35917fefe6942fce3c", "predicted_answer": "Three machine learning approaches are compared in this work: Decision Tree, Random Forest, and Support Vector Machine (SVM).", "predicted_evidence": ["n/a"]}
{"question_id": "b8cee4782e05afaeb9647efdb8858554490feba5", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "915cf3d481164217290d7b1eb9d48ed3e249196d", "predicted_answer": "The paper derives patterns and rules for fine-grained dialogue acts in customer service conversations on Twitter.", "predicted_evidence": ["n/a"]}
{"question_id": "d6e8b32048ff83c052e978ff3b8f1cb097377786", "predicted_answer": "The paper doesn't provide enough evidence about how customer satisfaction, customer frustration and overall problem resolution data are collected. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "e26e7e9bcd7e2cea561af596c59b98e823653a4b", "predicted_answer": "Seven different Twitter customer service industries are investigated.", "predicted_evidence": ["n/a"]}
{"question_id": "b24767fe7e6620369063e646fd3048dc645a8348", "predicted_answer": "Informative and Request are more suited to the twitter domain.", "predicted_evidence": ["n/a"]}
{"question_id": "0a7ac8eccbc286e0ab55bc5949f3f8d2ea2d1a60", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e84e80067b3343d136fd75300691c8b3d3efbdac", "predicted_answer": "They align the synthetic data using a word-for-word alignment approach.", "predicted_evidence": ["n/a"]}
{"question_id": "45bd22f2cfb62a5f79ec3c771c8324b963567cc0", "predicted_answer": "They collect the synthetic data from a combination of Phrase-Based Machine Translation (PBMT) and Character-Based Machine Translation (CBMT) models.", "predicted_evidence": ["n/a"]}
{"question_id": "936878cff0e6e327b2554ee5d46686797ee92cf2", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "58c1b162a4491d4a5ae0ff86cc8bd64e98739620", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "4dad15fee1fe01c3eadce8f0914781ca0a6e3f23", "predicted_answer": "They use a slot-independent model architecture.", "predicted_evidence": ["n/a"]}
{"question_id": "892c346617a3391c7dafc9da1b65e5ea3890294d", "predicted_answer": "Graph Convolutional Network.", "predicted_evidence": ["n/a"]}
{"question_id": "36feaac9d9dee5ae09aaebc2019b014e57f61fbf", "predicted_answer": "They measure model size in the number of parameters.", "predicted_evidence": ["n/a"]}
{"question_id": "df25dd9004a3b367202d7731ee912a8052a35780", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "5328cc2588b2bf7b91f4e0f342e8cbfc6dc8ac00", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "2ebd7a59baad1f935fe83f90526557bfa9df4047", "predicted_answer": "12.2% WER.", "predicted_evidence": ["n/a"]}
{"question_id": "766e2e35968ef7434b56330aa41957c5d5f8d0ee", "predicted_answer": "960 hours.", "predicted_evidence": ["n/a"]}
{"question_id": "63a77d2640df8315bf0bc3925fdd7e27132b1244", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "50be9e6203c40ed3db48ed37103f967ef0ea946c", "predicted_answer": "They evaluate their sentence representations by down-stream natural language processing tasks.", "predicted_evidence": ["n/a"]}
{"question_id": "36a9230fadf997d3b0c5fc8af8d89bd48bf04f12", "predicted_answer": "Transformer-based architecture.", "predicted_evidence": ["n/a"]}
{"question_id": "496304f63006205ee63da376e02ef1b3010c4aa1", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "00e9f088291fcf27956f32a791f87e4a1e311e41", "predicted_answer": "multi-task learning objectives.", "predicted_evidence": ["n/a"]}
{"question_id": "e2f269997f5a01949733c2ec8169f126dabd7571", "predicted_answer": "Multiple data sources including Wikipedia, the Toronto BookCorpus, and the UMBC Webbase corpus.", "predicted_evidence": ["n/a"]}
{"question_id": "317a6f211ecf48c58f008c12fbd5d41901db3e36", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "a726046eec1e2efa5fe3926963863bf755e64682", "predicted_answer": "English, German, and Spanish.", "predicted_evidence": ["n/a"]}
{"question_id": "6d9fbd42b54313cfdc2665809886330f209e9286", "predicted_answer": "WMT17 and IWSLT17 corpora.", "predicted_evidence": ["n/a"]}
{"question_id": "bb8f62950acbd4051774f1bfc50e3d424dd33b7c", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "d653d994ef914d76c7d4011c0eb7873610ad795f", "predicted_answer": "Breast cancer related posts were compiled from the Twitter streaming API using relevant keywords and hashtags related to breast cancer.", "predicted_evidence": ["n/a"]}
{"question_id": "880a76678e92970791f7c1aad301b5adfc41704f", "predicted_answer": "The paper used machine learning and NLP methods such as SVM classification and a rule-based approach to extract tweets relevant to breast cancer experiences.", "predicted_evidence": ["n/a"]}
{"question_id": "e3dc8689d8db31f04797f515fe224f6075f5cb16", "predicted_answer": "The paper extracts event and temporal relations, but it does not explicitly mention the specific kind of events that are extracted. Thus, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "cfb5ab893ed77f9df7eeb4940b6bacdef5acccea", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "a5abd4dd91e6f2855e9098bd6ae1481c0fdb0d4a", "predicted_answer": "The paper used three datasets: TempEval-3, MATRES, and ECB+.", "predicted_evidence": ["n/a"]}
{"question_id": "e67d2266476abd157fc8c396b3dfb70cb343471e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "c69f4df4943a2ca4c10933683a02b179a5e76f64", "predicted_answer": "Global latent variables performed better in experiments.", "predicted_evidence": ["n/a"]}
{"question_id": "6aed1122050b2d508dc1790c13cdbe38ff126089", "predicted_answer": "Adaptive Transformers, Accessible Generative models, Hybrid Code Networks.", "predicted_evidence": ["n/a"]}
{"question_id": "8740c3000e740ac5c0bc8f329d908309f7ffeff6", "predicted_answer": "BlisText, Cornell Movie Dialogs Corpus, and Persona-Chat.", "predicted_evidence": ["n/a"]}
{"question_id": "7772cb23b7609f1d4cfd6511ac3fcdc20f8481ba", "predicted_answer": "Outperformed previous approaches in all tasks.", "predicted_evidence": ["n/a"]}
{"question_id": "acf278679c584ae4f332f6134711602af26edfb4", "predicted_answer": "89 languages.", "predicted_evidence": ["n/a"]}
{"question_id": "13f7d50b3b8b0b97d90401eeb0a4e97c9eab3a76", "predicted_answer": "Czech texts.", "predicted_evidence": ["n/a"]}
{"question_id": "48fb76ae9921c9d181f65afc63a42af8ba3bc519", "predicted_answer": "Czech web corpora.", "predicted_evidence": ["n/a"]}
{"question_id": "13149342ccbb7a6df9b4b1bed890cfbdc1331c1f", "predicted_answer": "1,803.", "predicted_evidence": ["n/a"]}
{"question_id": "fbe149bd76863575b98fafb3679f411d3d21b4a3", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "6992f8e5a33f0af0f2206769484c72fecc14700b", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "a91abc7983fffa6b2e1e46133f559cec3d7d9438", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "c45feda62f23245f53e855706e2d8ea733b7fd03", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "9785ecf1107090c84c57112d01a8e83418a913c1", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e051d68a7932f700e6c3f48da57d3e2519936c6d", "predicted_answer": "BERT-based models: BERT-Base-Cased, BERT-Large-Uncased, and BERT-Large-Cased.", "predicted_evidence": ["n/a"]}
{"question_id": "9e2e5918608a2911b341d4887f58a4595d7d1429", "predicted_answer": "Unanswerable. The paper does not provide information on the required amount of training data for each low-resource language.", "predicted_evidence": ["n/a"]}
{"question_id": "0ec4143a4f1a8f597b435f83c0451145be2ab95b", "predicted_answer": "Grapheme-to-phoneme conversion, phoneme-to-grapheme conversion, and noise injection.", "predicted_evidence": ["n/a"]}
{"question_id": "90159e143487505ddc026f879ecd864b7f4f479e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d10e256f2f724ad611fd3ff82ce88f7a78bad7f7", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "c691b47c0380c9529e34e8ca6c1805f98288affa", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "892e42137b14d9fabd34084b3016cf3f12cac68a", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "dc69256bdfe76fa30ce4404b697f1bedfd6125fe", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "097ab15f58cb1fce5b5ffb5082b8d7bbee720659", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "b8d5e9fa08247cb4eea835b19377262d86107a9d", "predicted_answer": "IAM-OnDB, CVL, and the RIMES dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "8de64483ae96c0a03a8e527950582f127b43dceb", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "4d062673b714998800e61f66b6ccbf7eef5be2ac", "predicted_answer": "The paper does not mention or provide information about the \"Moral Choice Machine\". Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "f4238f558d6ddf3849497a130b3a6ad866ff38b3", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "3582fac4b2705db056f75a14949db7b80cbc3197", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "96dcabaa8b6bd89b032da609e709900a1569a0f9", "predicted_answer": "The authors define deontological ethical reasoning as a philosophical approach centered on universal ethical principles, where decisions are made based on adherence to these principles rather than on the consequences of the actions.", "predicted_evidence": ["n/a"]}
{"question_id": "f416c6818a7a8acb7ec4682ed424ecdbd7dd6df1", "predicted_answer": "The framework automatically chooses different curricula at the evolving learning process according to the learning status of the neural dialogue generation model using an adaptive control unit that evaluates the learning status. Answer: Adaptive control unit evaluates the learning status and selects the curricula accordingly.", "predicted_evidence": ["n/a"]}
{"question_id": "a1d422cb2e428333961370496ca281a1be99fdff", "predicted_answer": "Human evaluation metrics: BLEU, Perplexity, Informativeness, Coherence.", "predicted_evidence": ["n/a"]}
{"question_id": "3de9bf4b0b667b3f1181da9f006da1354565bcbd", "predicted_answer": "The automatic evaluation metrics used are BLEU, ROUGE-L, and Distinct.", "predicted_evidence": ["n/a"]}
{"question_id": "1a1293e24f4924064e6fb9998658f5a329879109", "predicted_answer": "BERT and Transformer Encoder-Decoders were used in experiments.", "predicted_evidence": ["n/a"]}
{"question_id": "3ccd337f77c5d2f7294eb459ccc1770796c2eaef", "predicted_answer": "Embedding diversity, Dialogue consistency, Naturalness, Context coherence, and Interestingness.", "predicted_evidence": ["n/a"]}
{"question_id": "f6937199e4b06bfbaa22edacc7339410de9703db", "predicted_answer": "Persona-Chat, DailyDialog, and CornellMovie Dialogs.", "predicted_evidence": ["n/a"]}
{"question_id": "61c9f97ee1ac5a4b8654aa152f05f22e153e7e6e", "predicted_answer": "Datasets used in the paper are AG's News, DBPedia, and Yelp Polarity.", "predicted_evidence": ["n/a"]}
{"question_id": "9ae084e76095194135cd602b2cdb5fb53f2935c1", "predicted_answer": "WER, TER, and BLEU.", "predicted_evidence": ["n/a"]}
{"question_id": "67ee7a53aa57ce0d0bc1a20d41b64cb20303f4b7", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "7eb3852677e9d1fb25327ba014d2ed292184210c", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "4f9a8b50903deb1850aee09c95d1b6204a7410b4", "predicted_answer": "English and Mandarin.", "predicted_evidence": ["n/a"]}
{"question_id": "c96a6b30d71c6669592504e4ee8001e9d1eb1fba", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "42d66726b5bf8de5b0265e09d76f5ab00c0e851a", "predicted_answer": "They used two datasets: Persona-Chat dataset and a custom dataset based on counseling conversations.", "predicted_evidence": ["n/a"]}
{"question_id": "c418deef9e44bc8448d9296c6517824cb95bd554", "predicted_answer": "The paper compares their proposed metric with three existing metrics: perplexity, F1 score, and dialogue length.", "predicted_evidence": ["n/a"]}
{"question_id": "d6d29040e7fafceb188e62afba566016b119b23c", "predicted_answer": "CommonsenseQA and SWAG.", "predicted_evidence": ["n/a"]}
{"question_id": "21663d2744a28e0d3087fbff913c036686abbb9a", "predicted_answer": "Their model differs from BERT in that it incorporates structured commonsense knowledge graphs.", "predicted_evidence": ["n/a"]}
{"question_id": "d8cecea477dfc5163dca6e2078a2fe6bc94ce09f", "predicted_answer": "Metrics: Accuracy, perplexity, and F1 score.", "predicted_evidence": ["n/a"]}
{"question_id": "dd2f21d60cfca3917a9eb8b192c194f4de85e8b2", "predicted_answer": "The paper explores different properties of the posterior distribution including its shape and its ability to cover the support of the prior distribution.", "predicted_evidence": ["n/a"]}
{"question_id": "ccf7415b515fe5c59fa92d4a8af5d2437c591615", "predicted_answer": "The proposed term helps to avoid posterior collapse by explicitly preventing the KL divergence from collapsing.", "predicted_evidence": ["n/a"]}
{"question_id": "fee5aef7ae521ccd1562764a91edefecec34624d", "predicted_answer": "The authors propose adding a constraint on the KL divergence term by including a penalty term that encourages the model to assign a probability mass to each value in the latent space.", "predicted_evidence": ["n/a"]}
{"question_id": "90f80a94fabaab72833256572db1d449c2779beb", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "5872279c5165cc8a0c58cf1f89838b7c43217b0e", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "da55878d048e4dca3ca3cec192015317b0d630b1", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "7d300176afa04947ac847135ac6ea2929908c0b0", "predicted_answer": "SemEval 2016 Task 6: detection and interpretation of ironic and sarcastic tweets. This system achieves state-of-the-art performance in subtask A: binary classification of tweets into ironic vs non-ironic.", "predicted_evidence": ["n/a"]}
{"question_id": "df9d16a2c4983a0ff46081e3ff4d6e7ef3338264", "predicted_answer": "Labels are propagated using a graph-based approach, where the language identification task is formulated as a semi-supervised learning problem, and the labels are propagated through the edges of the graph.", "predicted_evidence": ["n/a"]}
{"question_id": "8c35caf3772637e6297009ceab38f7f5be38ea9d", "predicted_answer": "The social graph of tweet authors contains information about their connection or interaction with each other.", "predicted_evidence": ["n/a"]}
{"question_id": "3a1bd3ec1a7ce9514da0cb2dfcaa454ba8c0ed14", "predicted_answer": "Five English subtasks: \n1. Subtask A - Message Polarity Classification \n2. Subtask B - Topic-Based Message Polarity Classification \n3. Subtask C - Message Impact Classification \n4. Subtask D - Tweet Context-Based Message Polarity Classification \n5. Subtask E - Emotion Detection on Tweets", "predicted_evidence": ["n/a"]}
{"question_id": "39492338e27cb90bf1763e4337c2f697cf5082ba", "predicted_answer": "Four.", "predicted_evidence": ["n/a"]}
{"question_id": "a7adb63db5066d39fdf2882d8a7ffefbb6b622f0", "predicted_answer": "0.44", "predicted_evidence": ["n/a"]}
{"question_id": "980568848cc8e7c43f767da616cf1e176f406b05", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "f1b738a7f118438663f9d77b4ccd3a2c4fd97c01", "predicted_answer": "The evaluation metrics discussed are precision, recall, F1-score, and accuracy.", "predicted_evidence": ["n/a"]}
{"question_id": "5a23f436a7e0c33e4842425cf86d5fd8ba78ac92", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "2f4acd34eb2d09db9b5ad9b1eb82cb4a88c13f5b", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e7329c403af26b7e6eef8b60ba6fefbe40ccf8ce", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e79a5e435fcf5587535f06c9215d19a66caadaff", "predicted_answer": "SemEval-2016 task 8: \"SemEval-2016 Task 8: Meaning Representation Parsing\".", "predicted_evidence": ["n/a"]}
{"question_id": "f7d67d6c6fbc62b2953ab74db6871b122b3c92cc", "predicted_answer": "10 times faster", "predicted_evidence": ["n/a"]}
{"question_id": "085147cd32153d46dd9901ab0f9195bfdbff6a85", "predicted_answer": "The paper mentions two baseline models: a simple CNN and a simple RNN.", "predicted_evidence": ["n/a"]}
{"question_id": "c0035fb1c2b3de15146a7ce186ccd2e366fb4da2", "predicted_answer": "12.6%", "predicted_evidence": ["n/a"]}
{"question_id": "a8e4a67dd67ae4a9ebf983a90b0d256f4b9ff6c6", "predicted_answer": "MR dataset.", "predicted_evidence": ["n/a"]}
{"question_id": "34dd0ee1374a3afd16cf8b0c803f4ef4c6fec8ac", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "53377f1c5eda961e438424d71d16150e669f7072", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "f37ed011e7eb259360170de027c1e8557371f002", "predicted_answer": "9.77", "predicted_evidence": ["n/a"]}
{"question_id": "41d3750ae666ea5a9cea498ddfb973a8366cccd6", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "90b2154ec3723f770c74d255ddfcf7972fe136a2", "predicted_answer": "The presence of three target styles is detected using a multi-strategy approach that combines rule-based and neural network-based methods.", "predicted_evidence": ["n/a"]}
{"question_id": "f3766c6937a4c8c8d5e954b4753701a023e3da74", "predicted_answer": "Fluency is automatically evaluated using perplexity and BERTScore.", "predicted_evidence": ["n/a"]}
{"question_id": "2898e4aa7a3496c628e7ddf2985b48fb11aa3bba", "predicted_answer": "The measures of \"performance\" used in this paper are perplexity and topic coherence.", "predicted_evidence": ["n/a"]}
{"question_id": "fa9df782d743ce0ce1a7a5de6a3de226a7e423df", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "6270d5247f788c4627be57de6cf30112560c863f", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "cb370692fe0beef90cdaa9c8e43a0aab6f0e117a", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "d0c636fa9ef99c4f44ab39e837a680217b140269", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "c47f593a5b92abc2e3c536fe2baaca226913688b", "predicted_answer": "The paper uses several preprocessing techniques such as tokenization, stopword removal, and stemming.", "predicted_evidence": ["n/a"]}
{"question_id": "c3a9732599849ba4a9f07170ce1e50867cf7d7bf", "predicted_answer": "Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) are used in the experiments.", "predicted_evidence": ["n/a"]}
{"question_id": "0fd678d24c86122b9ab27b73ef20216bbd9847d1", "predicted_answer": "The paper uses accuracy, F1 score, and AUC as evaluation metrics.", "predicted_evidence": ["n/a"]}
{"question_id": "b556fd3a9e0cff0b33c63fa1aef3aed825f13e28", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "0db1ba66a7e75e91e93d78c31f877364c3724a65", "predicted_answer": "The paper experimented with 4 tasks. \n\nTask 1: Sentiment Analysis\nTask 2: Paraphrase Detection\nTask 3: Natural Language Inference\nTask 4: Question Classification.", "predicted_evidence": ["n/a"]}
{"question_id": "b44ce9aae8b1479820555b99ce234443168dc1fe", "predicted_answer": "The paper states that the proposed model is trained on \"large-scale monolingual corpora and multilingual parallel data\". The specific multilingual parallel data used is not mentioned. Thus, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "b9c0049a7a5639c33efdb6178c2594b8efdefabb", "predicted_answer": "The proposed model achieves a better performance than the pivoting method.", "predicted_evidence": ["n/a"]}
{"question_id": "99c50d51a428db09edaca0d07f4dab0503af1b94", "predicted_answer": "The paper doesn't provide enough evidence to answer this question. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d1747b1b56fddb05bb1225e98fd3c4c043d74592", "predicted_answer": "They compared six SBD systems.", "predicted_evidence": ["n/a"]}
{"question_id": "5a29b1f9181f5809e2b0f97b4d0e00aea8996892", "predicted_answer": "It uses a combination of precision, recall, and F1 score at both the document and sentence levels, along with the inclusion of a confidence interval, which makes it a more reliable metric.", "predicted_evidence": ["n/a"]}
{"question_id": "f5db12cd0a8cd706a232c69d94b2258596aa068c", "predicted_answer": "6.1% improvement.", "predicted_evidence": ["n/a"]}
{"question_id": "2c8d5e3941a6cc5697b242e64222f5d97dba453c", "predicted_answer": "Dramatically.", "predicted_evidence": ["n/a"]}
{"question_id": "78102422a5dc99812739b8dd2541e4fdb5fe3c7a", "predicted_answer": "The discriminator in this generative adversarial setup is a BiLSTM neural network.", "predicted_evidence": ["n/a"]}
{"question_id": "930c51b9f3936d936ee745716536a4b40f531c7f", "predicted_answer": "GLUE and SNLI.", "predicted_evidence": ["n/a"]}
{"question_id": "20eb673b01d202b731e7ba4f84efc10a18616dd3", "predicted_answer": "Gender representations in open source speech resources.", "predicted_evidence": ["n/a"]}
{"question_id": "e8e6719d531e7bef5d827ac92c7b1ab0b8ec3c8e", "predicted_answer": "There is no clear answer to this question in the paper. Therefore, the answer is \"Unanswerable\".", "predicted_evidence": ["n/a"]}
{"question_id": "f6e5febf2ea53ec80135bbd532d6bb769d843dd8", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "4059c6f395640a6acf20a0ed451d0ad8681bc59b", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "99d7bef0ef395360b939a3f446eff67239551a9d", "predicted_answer": "Yes, some models are evaluated using this metric, and the paper reports their findings.", "predicted_evidence": ["n/a"]}
{"question_id": "a1097ce59270d6f521d92df8d2e3a279abee3e67", "predicted_answer": "The proposed metric differs from human judgement in taking into account the hierarchical structure of discourse relations.", "predicted_evidence": ["n/a"]}
{"question_id": "56e58bdf0df76ad1599021801f6d4c7b77953e29", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e74ba39c35af53d3960be5a6c86eddd62cef859f", "predicted_answer": "The paper does not compare performance of different baselines, therefore the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "458f3963387de57fdc182875c9ca3798b612b633", "predicted_answer": "Baselines.", "predicted_evidence": ["n/a"]}
{"question_id": "69a88b6be3b34acc95c5e36acbe069c0a0bc67d6", "predicted_answer": "The paper does not provide information on the size of the corpus. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "7befb7a8354fca9d2a94e3fd4364625c98067ebb", "predicted_answer": "The evaluation corpus was collected from the COCO and Visual Genome datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "da1994421934082439e8fe5071a01d3d17b56601", "predicted_answer": "Yes, several machine translation systems were tried with these embeddings, and the performance was found to be significantly improved over baseline models.", "predicted_evidence": ["n/a"]}
{"question_id": "30c6d34b878630736f819fd898319ac4e71ee50b", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "a4ff1b91643e0c8a0d4cc1502d25ca85995cf428", "predicted_answer": "Two datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "544e29937e0c972abcdd27c953dc494b2376dd76", "predicted_answer": "BILSTM-Attention model.", "predicted_evidence": ["n/a"]}
{"question_id": "b8fdc600f9e930133bb3ec8fbcc9c600d60d24b0", "predicted_answer": "Baseline: Majority class classifier.", "predicted_evidence": ["n/a"]}
{"question_id": "bdc93ac1b8643617c966e91d09c01766f7503872", "predicted_answer": "The size of the second dataset is 2,500 dialogues.", "predicted_evidence": ["n/a"]}
{"question_id": "4ca0d52f655bb9b4bc25310f3a76c5d744830043", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d2fbf34cf4b5b1fd82394124728b03003884409c", "predicted_answer": "DAI-Labor was the top-scoring team.", "predicted_evidence": ["n/a"]}
{"question_id": "4c71ed7d30ee44cf85ffbd7756b985e32e8e07da", "predicted_answer": "Classification and regression.", "predicted_evidence": ["n/a"]}
{"question_id": "1949d84653562fa9e83413796ae55980ab7318f2", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "7ee660927e2b202376849e489faa7341518adaf9", "predicted_answer": "Mixed Membership Word Embeddings and Topic Models.", "predicted_evidence": ["n/a"]}
{"question_id": "f6380c60e2eb32cb3a9d3bca17cf4dc5ae584eca", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "c7d99e66c4ab555fe3d616b15a5048f3fe1f3f0e", "predicted_answer": "Topic modeling is an example of a computational social science NLP task.", "predicted_evidence": ["n/a"]}
{"question_id": "400efd1bd8517cc51f217b34cbf19c75d94b1874", "predicted_answer": "Yes", "predicted_evidence": ["n/a"]}
{"question_id": "4698298d506bef02f02c80465867f2cd12d29182", "predicted_answer": "Unanswerable. The paper does not mention any previous state of the art benchmarks.", "predicted_evidence": ["n/a"]}
{"question_id": "4e2cb1677df949ee3d1d3cd10962b951da907105", "predicted_answer": "The natural questions are generated using a set of templates with slots that are filled with relevant information from the image and its corresponding question-answer pair.", "predicted_evidence": ["n/a"]}
{"question_id": "9cc0fd3721881bd8e246d20fff5d15bd32365655", "predicted_answer": "The input to the differential network is an image and a question. Answer: Image and Question.", "predicted_evidence": ["n/a"]}
{"question_id": "82c4863293a179fe5c0d9a1ff17d224bde952f54", "predicted_answer": "The paper does not mention a definition of a differential network. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "88d9d32fb7a22943e1f4868263246731a1726e6e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "af82043e7d046c2fb1ed86ef9b48c35492e6a48c", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "1bc8904118eb87fa5949ad7ce5b28ad3b3082bd0", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "5dc1aca619323ea0d4717d1f825606b2b7c21f01", "predicted_answer": "North America and Europe.", "predicted_evidence": ["n/a"]}
{"question_id": "dd5c9a370652f6550b4fd13e2ac317eaf90973a8", "predicted_answer": "Unanswerable. The paper does not provide evidence on the correlation between the prevalence of the #MeToo movement and official reports of sexual harassment.", "predicted_evidence": ["n/a"]}
{"question_id": "39c78924df095c92e058ffa5a779de597e8c43f4", "predicted_answer": "Topics are extracted using a combination of rule-based and machine learning-based approaches.", "predicted_evidence": ["n/a"]}
{"question_id": "a95188a0f35d3cb3ca70ae1527d57ac61710afa3", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "a1557ec0f3deb1e4cd1e68f4880dcecda55656dd", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "096f5c59f43f49cab1ef37126341c78f272c0e26", "predicted_answer": "750,000.", "predicted_evidence": ["n/a"]}
{"question_id": "c348a8c06e20d5dee07443e962b763073f490079", "predicted_answer": "Answer: Answer Extraction Component and Answer Generation Component.", "predicted_evidence": ["n/a"]}
{"question_id": "0300cf768996849cab7463d929afcb0b09c9cf2a", "predicted_answer": "S-Net.", "predicted_evidence": ["n/a"]}
{"question_id": "dd8f72cb3c0961b5ca1413697a00529ba60571fe", "predicted_answer": "MS-MARCO focuses on passages whereas SQuAD focuses on sentences.", "predicted_evidence": ["n/a"]}
{"question_id": "fbd094918b493122b3bba99cefe5da80cf88959c", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "78661bdd4d11148e07bdf17141cf088db4ad60c6", "predicted_answer": "71.4% F1-score on the test set.", "predicted_evidence": ["n/a"]}
{"question_id": "95d98b2a7fbecd1990ec9a070f9d5624891a4f26", "predicted_answer": "3,000.", "predicted_evidence": ["n/a"]}
{"question_id": "586566de02abdf20b7bfd0d5a43ba93cb02795c3", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "dfd9302615b27abf8cbef1a2f880a73dd5f0c753", "predicted_answer": "QAGS evaluates three models.", "predicted_evidence": ["n/a"]}
{"question_id": "e09dcb6fc163bba7d704178e7edba2e630b573c2", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "c8f11561fc4da90bcdd72f76414421e1527c0287", "predicted_answer": "LJ and Blizzard Challenge 2013-2015 datasets.", "predicted_evidence": ["n/a"]}
{"question_id": "51de39c8bad62d3cbfbec1deb74bd8a3ac5e69a8", "predicted_answer": "They introduce several modifications to a basic Seq2Seq architecture such as Convolutional Neural Networks (CNNs) for acoustic embedding, a variational autoencoder (VAE) for modeling speaker information, and multi-band mel spectrogram decomposition.", "predicted_evidence": ["n/a"]}
{"question_id": "d9cbcaf8f0457b4be59178446f1a280d17a923fa", "predicted_answer": "They measure the size of models in terms of the number of parameters.", "predicted_evidence": ["n/a"]}
{"question_id": "fc69f5d9464cdba6db43a525cecde2bf6ddaaa57", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "e1f5531ed04d0aae1dfcb0559f1512a43134c43a", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "4a4b7c0d3e7365440b49e9e6b67908ea5cea687d", "predicted_answer": "The baseline models are FastText, Universal Sentence Encoder (USE), and BERT.", "predicted_evidence": ["n/a"]}
{"question_id": "da845a2a930fd6a3267950bec5928205b6c6e8e8", "predicted_answer": "The speed was measured in terms of lemmatization throughput, reported in tokens per second.", "predicted_evidence": ["n/a"]}
{"question_id": "2fa0b9d0cb26e1be8eae7e782ada6820bc2c037f", "predicted_answer": "88.606% F1-score.", "predicted_evidence": ["n/a"]}
{"question_id": "76ce9e02d97e2d77fe28c0fa78526809e7c195c6", "predicted_answer": "Unanswerable", "predicted_evidence": ["n/a"]}
{"question_id": "64c7545ce349265e0c97fd6c434a5f8efdc23777", "predicted_answer": "The paper does not provide information on how the dataset was annotated. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "47822fec590e840438a3054b7f512fec09dbd1e1", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "989271972b3176d0a5dabd1cc0e4bdb671269c96", "predicted_answer": "Q: Where did they collect their dataset from?\nA: UN annotations.", "predicted_evidence": ["n/a"]}
{"question_id": "26c64edbc5fa4cdded69ace66fdba64a9648b78e", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e06e1b103483e1e58201075c03e610202968c877", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "b0fd686183b056ea3f63a7ab494620df1d598c24", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "7065e6140dbaffadebe62c9c9d3863ca0f829d52", "predicted_answer": "57.", "predicted_evidence": ["n/a"]}
{"question_id": "9508e9ec675b6512854e830fa89fa6a747b520c5", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "a65e5c97ade6e697ec10bcf3c3190dc6604a0cd5", "predicted_answer": "The paper doesn't provide enough evidence to answer this question. Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e28a6e3d8f3aa303e1e0daff26b659a842aba97b", "predicted_answer": "No.", "predicted_evidence": ["n/a"]}
{"question_id": "0fce128b8aaa327ac0d58ec30cd2ecbea2019baa", "predicted_answer": "Baselines: Seq2Seq LSTM, Incremental Encoding, Human Performance (Crowdsourcing) and Random Embodied Agents.", "predicted_evidence": ["n/a"]}
{"question_id": "7a7e279170e7a2f3bc953c37ee393de8ea7bd82f", "predicted_answer": "The Chinese reading comprehension dataset consists of two types: Cloze-style questions and Reading comprehension questions.", "predicted_evidence": ["n/a"]}
{"question_id": "e3981a11d3d6a8ab31e1b0aa2de96f253653cfb2", "predicted_answer": "Chinese.", "predicted_evidence": ["n/a"]}
{"question_id": "74b0d3ee0cc9b0a3d9b264aba9901ff97048a897", "predicted_answer": "They induced the CFG using iterative clustering based on semantic similarity and grounding feedback.", "predicted_evidence": ["n/a"]}
{"question_id": "9eb5b336b3dcb7ab63f673ba9ab1818573cce6c3", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "0a92352839b549d07ac3f4cb997b8dc83f64ba6f", "predicted_answer": "2.7 BLEU points.", "predicted_evidence": ["n/a"]}
{"question_id": "242f96142116cf9ff763e97aecd54e22cb1c8b5a", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "fcd0bd2db39898ee4f444ae970b80ea4d1d9b054", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "5cc937c2dcb8fd4683cb2298d047f27a05e16d43", "predicted_answer": "They try both Maximum Likelihood Estimation (MLE) and Minimum Risk Training (MRT) loss metrics.", "predicted_evidence": ["n/a"]}
{"question_id": "37016cc987d33be5ab877013ef26ec7239b48bd9", "predicted_answer": "Each domain is weighted equally in WDIRL.", "predicted_evidence": ["n/a"]}
{"question_id": "b3dc6d95d1570ad9a58274539ff1def12df8f474", "predicted_answer": "The paper does not provide information on how DIRL is evaluated.", "predicted_evidence": ["n/a"]}
{"question_id": "cc5d3903913fa2e841f900372ec74b0efd5e0c71", "predicted_answer": "Cross-domain sentiment analysis.", "predicted_evidence": ["n/a"]}
{"question_id": "c95fd189985d996322193be71cf5be8858ac72b5", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "4a61260d6edfb0f93100d92e01cf655812243724", "predicted_answer": "Topic models, Parsing, and Word embeddings.", "predicted_evidence": ["n/a"]}
{"question_id": "5c95808cd3ee9585f05ef573b0d4a52e86d04c60", "predicted_answer": "ACL and EMNLP.", "predicted_evidence": ["n/a"]}
{"question_id": "b6f5860fc4a9a763ddc5edaf6d8df0eb52125c9e", "predicted_answer": "English, Chinese, Spanish, French, and German.", "predicted_evidence": ["n/a"]}
{"question_id": "7955dbd79ded8ef4ae9fc28b2edf516320c1cb55", "predicted_answer": "The paper examines the diachronic analysis of the ACL anthology regarding NLP literature.", "predicted_evidence": ["n/a"]}
{"question_id": "6bff681f1f6743ef7aa6c29cc00eac26fafdabc2", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "205163715f345af1b5523da6f808e6dbf5f5dd47", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "8d989490c5392492ad66e6a5047b7d74cc719f30", "predicted_answer": "Ensemble methods were not used for the best model in this paper.", "predicted_evidence": ["n/a"]}
{"question_id": "a7829abed2186f757a59d3da44893c0172c7012b", "predicted_answer": "The paper states that different hyperparameters were tuned on different tasks, but it does not provide a complete list. Therefore, the answer is 'Unanswerable'.", "predicted_evidence": ["n/a"]}
{"question_id": "707db46938d16647bf4b6407b2da84b5c7ab4a81", "predicted_answer": "5.2%", "predicted_evidence": ["n/a"]}
{"question_id": "d72548fa4d29115252605d5abe1561a3ef2430ca", "predicted_answer": "They retrieve neighbor n-grams from the source and target side of a parallel corpus.", "predicted_evidence": ["n/a"]}
{"question_id": "24d06808fa3b903140659ee5a471fdfa86279980", "predicted_answer": "Google's Neural Machine Translation (NMT) system and Moses phrase-based statistical machine translation system.", "predicted_evidence": ["n/a"]}
{"question_id": "dba3d05c495e2c8ca476139e78f65059db2eb72d", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "0062ad4aed09a57d0ece6aa4b873f4a4bf65d165", "predicted_answer": "N-gram cosine similarity.", "predicted_evidence": ["n/a"]}
{"question_id": "67a28fe78f07c1383176b89e78630ee191cf15db", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "d8de12f5eff64d0e9c9e88f6ebdabc4cdf042c22", "predicted_answer": "0.7%", "predicted_evidence": ["n/a"]}
{"question_id": "9cba2ee1f8e1560e48b3099d0d8cf6c854ddea2e", "predicted_answer": "The paper shows that extracting features of multigranular phrases can lead to better classification performance.", "predicted_evidence": ["n/a"]}
{"question_id": "7975c3e1f61344e3da3b38bb12e1ac6dcb153a18", "predicted_answer": "The paper reports that using diverse versions of pre-trained word embeddings can improve the performance of the proposed Multichannel Variable-Size Convolution model. Therefore, the effects are positive. The answer is 'positive' or 'improvement'.", "predicted_evidence": ["n/a"]}
{"question_id": "eddb18109495976123e10f9c6946a256a55074bd", "predicted_answer": "MVCNN outperforms CNN.", "predicted_evidence": ["n/a"]}
{"question_id": "ea6764a362bac95fb99969e9f8c773a61afd8f39", "predicted_answer": "86.7", "predicted_evidence": ["n/a"]}
{"question_id": "62c4c8b46982c3fcf5d7c78cd24113635e2d7010", "predicted_answer": "The paper does not provide specific information on the size range of the datasets. Answer: Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "e9cfe3f15735e2b0d5c59a54c9940ed1d00401a2", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "52ed2eb6f4d1f74ebdc4dcddcae201786d4c0463", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "2c576072e494ab5598667cd6b40bc97fdd7d92d7", "predicted_answer": "In-house Arabic social media data.", "predicted_evidence": ["n/a"]}
{"question_id": "8602160e98e4b2c9c702440da395df5261f55b1f", "predicted_answer": "datasets: Gulf, Tunisian, and Multi-dialect.", "predicted_evidence": ["n/a"]}
{"question_id": "57fdb0f6cd91b64a000630ecb711550941283091", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "3aa43a0d543b88d40e4f3500c7471e263515be40", "predicted_answer": "The paper proposes to use topic modeling, sentiment analysis, and information extraction as elements of natural language processing to analyze qualitative data.", "predicted_evidence": ["n/a"]}
{"question_id": "d82ec1003a3db7370994c7522590f7e5151b1f33", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "58f08d38bbcffb2dd9d660faa8026718d390d64b", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "89e1e0dc5d15a05f8740f471e1cb3ddd296b8942", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "2815bac42db32d8f988b380fed997af31601f129", "predicted_answer": "There is no mention of improvement in accuracy for short jokes in relation to other types of jokes in the paper.", "predicted_evidence": ["n/a"]}
{"question_id": "de03e8cc1ceaf2108383114460219bf46e00423c", "predicted_answer": "The paper evaluated multiple kinds of humor including puns, wordplay, and misdirection.", "predicted_evidence": ["n/a"]}
{"question_id": "8a276dfe748f07e810b3944f4f324eaf27e4a52c", "predicted_answer": "They evaluate if a joke is humorous or not using a human evaluation.", "predicted_evidence": ["n/a"]}
{"question_id": "0716b481b78d80b012bca17c897c62efbe7f3731", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "fed0785d24375ebbde51fb0503b93f14da1d8583", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "675d7c48541b6368df135f71f9fc13a398f0c8c6", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "868c69c8f623e30b96df5b5c8336070994469f60", "predicted_answer": "The CoLA dataset is sourced from linguistic research and textbooks.", "predicted_evidence": ["n/a"]}
{"question_id": "f809fd0d3acfaccbe6c8abb4a9d951a83eec9a32", "predicted_answer": "The CoLA is annotated based on acceptability judgments.", "predicted_evidence": ["n/a"]}
{"question_id": "c4a6b727769328333bb48d59d3fc4036a084875d", "predicted_answer": "Baseline.", "predicted_evidence": ["n/a"]}
{"question_id": "bbeb74731b9ac7f61e2d74a7d9ea74caa85e62ef", "predicted_answer": "Unanswerable.", "predicted_evidence": ["n/a"]}
{"question_id": "93e8ce62361b9f687d5200d2e26015723721a90f", "predicted_answer": "Yes.", "predicted_evidence": ["n/a"]}
{"question_id": "d05d667822cb49cefd03c24a97721f1fe9dc0f4c", "predicted_answer": "They used OpenIE to extract relations between mentions.", "predicted_evidence": ["n/a"]}
