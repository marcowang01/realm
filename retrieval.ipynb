{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk and add all the files into chroma using api\n",
    "# add all the files into chroma using api\n",
    "# query the api for the passages\n",
    "# construct a prompt and then add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod json file\n",
    "import json\n",
    "import os\n",
    "\n",
    "data = json.load(open('./qasper/qasper-test-v0.3.json'))\n",
    "# loop through by key and value\n",
    "parsed_data = []\n",
    "for key, value in data.items():\n",
    "    full_text = \"\"\n",
    "    for section in value['full_text']:\n",
    "        full_text += f\"{section['section_name']}. \"\n",
    "        for paragraph in section['paragraphs']:\n",
    "            full_text += f\"{paragraph} \"\n",
    "    parsed_data.append({\n",
    "        \"full_text\": full_text,\n",
    "        \"metadata\": {\n",
    "            \"arxiv_id\": key,\n",
    "            \"title\": value['title'],\n",
    "        }\n",
    "    })\n",
    "\n",
    "# write to a new json file\n",
    "with open('./qasper/test-papers.json', 'w') as outfile:\n",
    "    json.dump(parsed_data, outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 11801\n"
     ]
    }
   ],
   "source": [
    "# load json back into memory\n",
    "import json\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from typing import Any, List, Mapping, Optional\n",
    "from enum import Enum\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "parsed_data = json.load(open('./qasper/test-papers.json'))\n",
    "docs = []\n",
    "for paper in parsed_data:\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "  texts = text_splitter.split_text(paper['full_text'])\n",
    "  docs += [Document(page_content=text, metadata=paper['metadata']) for text in texts]\n",
    "\n",
    "# print length of docs\n",
    "print(f\"Number of docs: {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt = \"\"\"\n",
    "Your goal is to structure the user's query to match the request schema provided below.\n",
    "\n",
    "<< Structured Request Schema >>\n",
    "When responding use a markdown code snippet with a JSON object formatted in the following schema:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"query\": string \\ text string to compare to document contents\n",
    "    \"filter\": string \\ logical condition statement for filtering documents\n",
    "}\n",
    "```\n",
    "\n",
    "The query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\n",
    "\n",
    "A logical condition statement is composed of one or more comparison and logical operation statements.\n",
    "\n",
    "A comparison statement takes the form: `comp(attr, val)`:\n",
    "- `comp` (eq | gt | lt | gte | lte): comparator\n",
    "- `attr` (string):  name of attribute to apply the comparison to\n",
    "- `val` (string): is the comparison value\n",
    "\n",
    "A logical operation statement takes the form `op(statement1, statement2, ...)`:\n",
    "- `op` (and | or): logical operator\n",
    "- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\n",
    "\n",
    "Make sure that you only use the comparators and logical operators listed above and no others.\n",
    "Make sure that filters only refer to attributes that exist in the data source.\n",
    "Make sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\n",
    "Make sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\n",
    "\n",
    "<< Example 1. >>\n",
    "Data Source:\n",
    "```json\n",
    "{\n",
    "    \"content\": \"Lyrics of a song\",\n",
    "    \"attributes\": {\n",
    "        \"artist\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Name of the song artist\"\n",
    "        },\n",
    "        \"length\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"Length of the song in seconds\"\n",
    "        },\n",
    "        \"genre\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "User Query:\n",
    "What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre\n",
    "\n",
    "Structured Request:\n",
    "```json\n",
    "{\n",
    "    \"query\": \"teenager love\",\n",
    "    \"filter\": \"and(or(eq(\\\"artist\\\", \\\"Taylor Swift\\\"), eq(\\\"artist\\\", \\\"Katy Perry\\\")), lt(\\\"length\\\", 180), eq(\\\"genre\\\", \\\"pop\\\"))\"\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "<< Example 2. >>\n",
    "Data Source:\n",
    "```json\n",
    "{\n",
    "    \"content\": \"Lyrics of a song\",\n",
    "    \"attributes\": {\n",
    "        \"artist\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Name of the song artist\"\n",
    "        },\n",
    "        \"length\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"Length of the song in seconds\"\n",
    "        },\n",
    "        \"genre\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "User Query:\n",
    "What are songs that were not published on Spotify\n",
    "\n",
    "Structured Request:\n",
    "```json\n",
    "{\n",
    "    \"query\": \"\",\n",
    "    \"filter\": \"NO_FILTER\"\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "<< Example 3. >>\n",
    "Data Source:\n",
    "```json\n",
    "{\n",
    "    \"content\": \"The full text of the research paper.\",\n",
    "    \"attributes\": {\n",
    "    \"title\": {\n",
    "        \"description\": \"The title of the research paper\",\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"publication_date\": {\n",
    "        \"description\": \"The date the paper was published\",\n",
    "        \"type\": \"date\"\n",
    "    },\n",
    "    \"arxiv_id\": {\n",
    "        \"description\": \"The arxiv id of the paper\",\n",
    "        \"type\": \"string\"\n",
    "    }\n",
    "}\n",
    "}\n",
    "```\n",
    "\n",
    "User Query:\n",
    "What is a seed lexicon in the context of the papaer titled 'A Survey of the Usages of Deep Learning for Natural Language Processing'?\n",
    "\n",
    "Structured Request:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json back into memory\n",
    "import json\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from typing import Any, List, Mapping, Optional\n",
    "from enum import Enum\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "  from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "  from langchain.llms.base import LLM\n",
    "\n",
    "  answer = \"\"\n",
    "\n",
    "  @property\n",
    "  def _llm_type(self) -> str:\n",
    "    return \"custom\"\n",
    "  \n",
    "  def _call(\n",
    "    self,\n",
    "    prompt: str,\n",
    "    stop: Optional[List[str]] = None,\n",
    "    run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "  ) -> str:\n",
    "    import os\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    if stop is not None:\n",
    "      raise ValueError(\"stop kwargs are not permitted.\")\n",
    "    answer = \"\"\n",
    "\n",
    "    system_prompt = \"You are a model trained on diverse datasets, you have the ability to provide insights on a wide range of topics, including machine learning.\"\n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer pk-SCfIRSxcfoewLTsUagmpHJMVFwVbPjHDrNeVJAbagnnEjzLD\",\n",
    "      \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    messages = [\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "      }\n",
    "    ]\n",
    "    payload = {\n",
    "      \"model\": \"gpt-3.5-turbo\",\n",
    "      \"max_tokens\": 256,\n",
    "      \"messages\": messages,\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.pawan.krd/v1/chat/completions\", headers=headers, json=payload)\n",
    "    if response.status_code != 200:\n",
    "      try:\n",
    "          error_message = response.json()\n",
    "      except ValueError:  # includes simplejson.decoder.JSONDecodeError\n",
    "          error_message = response.text\n",
    "      raise Exception(f\"PawanGPT ERROR: {error_message} \\n\\n {prompt}\")\n",
    "    answer = response.json()['choices'][0]['message']['content']\n",
    "\n",
    "    self.answer = answer\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "from langchain.chains.query_constructor.ir import (\n",
    "    Comparator,\n",
    "    Comparison,\n",
    "    Operation,\n",
    "    Operator,\n",
    "    StructuredQuery,\n",
    "    Visitor,\n",
    ")\n",
    "from langchain.chains.query_constructor.base import load_query_constructor_chain, AttributeInfo\n",
    "from langchain.chains.query_constructor.parser import QueryTransformer\n",
    "from typing import Any, Dict, List, Optional, Type, cast\n",
    "\n",
    "query = \"In the context of papers published before 2019, what is the most popular way of evluating the perfomance of question answering systems?\"\n",
    "\n",
    "llm = CustomLLM()\n",
    "\n",
    "structured_query_translator: Visitor = ChromaTranslator()\n",
    "chain_kwargs = {\n",
    "    \"allowed_comparators\": structured_query_translator.allowed_comparators,\n",
    "    \"allowed_operators\": structured_query_translator.allowed_operators,\n",
    "}\n",
    "metadata_field_info=[\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title of the research paper\", \n",
    "        type=\"string\", \n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"publication_date\",\n",
    "        description=\"The date the paper was published\", \n",
    "        type=\"date\", \n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"arxiv_id\",\n",
    "        description=\"The arxiv id of the paper\", \n",
    "        type=\"string\", \n",
    "    ),\n",
    "]\n",
    "document_content_description = \"The full text of the research paper.\"\n",
    "\n",
    "# print(QueryTransformer)\n",
    "\n",
    "\n",
    "# transformer = QueryTransformer(\n",
    "#     allowed_comparators=chain_kwargs[\"allowed_comparators\"],\n",
    "#     allowed_operators=chain_kwargs[\"allowed_operators\"],\n",
    "# )\n",
    "\n",
    "llm_chain = load_query_constructor_chain(\n",
    "      llm, document_content_description, metadata_field_info, **chain_kwargs\n",
    ")\n",
    "\n",
    "inputs = llm_chain.prep_inputs(query)\n",
    "\n",
    "structured_query = cast(\n",
    "    StructuredQuery, llm_chain.predict_and_parse(callbacks=None, **inputs)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: question answering system performance evaluation\n",
      "Filters:\n",
      "  ('comparator', <Comparator.LT: 'lt'>)\n",
      "  ('attribute', 'publication_date')\n",
      "  ('value', '2019-01-01')\n"
     ]
    }
   ],
   "source": [
    "# print structured_query in a nice format\n",
    "print(f\"Query: {structured_query.query}\")\n",
    "print(f\"Filters:\")\n",
    "for f in structured_query.filter:\n",
    "  print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Query: question answering system performance evaluation\n",
      "Search Kwargs: {'filter': {'publication_date': {'$lt': '2019-01-01'}}}\n"
     ]
    }
   ],
   "source": [
    "new_query, new_kwargs = structured_query_translator.visit_structured_query(structured_query=structured_query)\n",
    "search_kwargs = {**new_kwargs}\n",
    "\n",
    "print(f\"New Query: {new_query}\")\n",
    "print(f\"Search Kwargs: {search_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CustomLLM()\n",
    "response = llm(new_query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
